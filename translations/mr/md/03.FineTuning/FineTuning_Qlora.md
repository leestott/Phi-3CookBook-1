**Phi-3 चे QLoRA सह फाइन-ट्यूनिंग**

[QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora) वापरून Microsoft च्या Phi-3 Mini भाषा मॉडेलचे फाइन-ट्यूनिंग. 

QLoRA संवाद समजून घेणे आणि प्रतिसाद निर्माण करणे यामध्ये सुधारणा करण्यात मदत करेल. 

transformers आणि bitsandbytes सह 4bits मध्ये मॉडेल्स लोड करण्यासाठी, तुम्हाला accelerate आणि transformers सोर्समधून इंस्टॉल करावे लागतील आणि bitsandbytes लायब्ररीची नवीनतम आवृत्ती असल्याची खात्री करावी लागेल.

**उदाहरणे**
- [या नमुना नोटबुकसह अधिक जाणून घ्या](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python फाइन-ट्यूनिंगचे उदाहरण](../../../../code/03.Finetuning/FineTrainingScript.py)
- [LORA सह Hugging Face Hub फाइन-ट्यूनिंगचे उदाहरण](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [QLORA सह Hugging Face Hub फाइन-ट्यूनिंगचे उदाहरण](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**अस्वीकरण**:  
हा दस्तऐवज मशीन-आधारित AI अनुवाद सेवांचा वापर करून अनुवादित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित अनुवादांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा प्राधिकृत स्रोत मानावा. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानवी अनुवादाची शिफारस केली जाते. या अनुवादाचा वापर करून उद्भवलेल्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.