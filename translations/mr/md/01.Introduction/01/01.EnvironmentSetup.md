# Phi-3 स्थानिक पातळीवर सुरू करा

हा मार्गदर्शक तुम्हाला Phi-3 मॉडेल Ollama वापरून स्थानिक वातावरणात सेटअप करण्यास मदत करेल. तुम्ही हे मॉडेल वेगवेगळ्या पद्धतींनी चालवू शकता, जसे की GitHub Codespaces, VS Code Dev Containers, किंवा तुमच्या स्थानिक वातावरणात.

## वातावरण सेटअप

### GitHub Codespaces

तुम्ही GitHub Codespaces वापरून हे टेम्पलेट आभासी स्वरूपात चालवू शकता. हे बटण तुमच्या ब्राउझरमध्ये वेब-आधारित VS Code उदाहरण उघडेल:

1. टेम्पलेट उघडा (यास काही मिनिटे लागू शकतात):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. टर्मिनल विंडो उघडा

### VS Code Dev Containers

⚠️ हा पर्याय फक्त तेव्हाच काम करेल, जेव्हा तुमच्या Docker Desktop ला किमान 16 GB RAM वाटप केलेले असेल. जर तुमच्याकडे 16 GB पेक्षा कमी RAM असेल, तर तुम्ही [GitHub Codespaces पर्याय](../../../../../md/01.Introduction/01) वापरून पाहू शकता किंवा [स्थानिक पातळीवर सेटअप करू शकता](../../../../../md/01.Introduction/01).

एक संबंधित पर्याय म्हणजे VS Code Dev Containers, जो [Dev Containers विस्तार](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) वापरून प्रकल्प तुमच्या स्थानिक VS Code मध्ये उघडेल:

1. Docker Desktop सुरू करा (जर आधीपासून स्थापित नसेल तर ते स्थापित करा)
2. प्रकल्प उघडा:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. जेव्हा VS Code विंडो उघडते आणि प्रकल्प फायली दिसायला लागतात (यास काही मिनिटे लागू शकतात), तेव्हा टर्मिनल विंडो उघडा.
4. [डिप्लॉयमेंट पायऱ्या](../../../../../md/01.Introduction/01) सुरू ठेवा.

### स्थानिक वातावरण

1. खालील साधने स्थापित असल्याची खात्री करा:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## मॉडेल चाचणी करा

1. Ollama ला phi3:mini मॉडेल डाउनलोड आणि चालविण्यास सांगा:

    ```shell
    ollama run phi3:mini
    ```

    मॉडेल डाउनलोड होण्यासाठी काही मिनिटे लागतील.

2. एकदा आउटपुटमध्ये "यशस्वी" दिसले की, तुम्ही त्या मॉडेलला प्रॉम्प्टमधून संदेश पाठवू शकता.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. काही सेकंदांनंतर, तुम्हाला मॉडेलकडून प्रतिसाद प्रवाहित होताना दिसेल.

4. भाषा मॉडेल्ससह वापरल्या जाणाऱ्या वेगवेगळ्या तंत्रांबद्दल शिकण्यासाठी, Python नोटबुक [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) उघडा आणि प्रत्येक सेल चालवा. जर तुम्ही 'phi3:mini' वगळता इतर कोणतेही मॉडेल वापरले असेल, तर फाईलच्या वरच्या भागात `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` आवश्यकतेनुसार बदला, आणि तुम्ही सिस्टम मेसेज बदलू शकता किंवा हवे असल्यास काही उदाहरणे देखील जोडू शकता.

**अस्वीकरण**:  
हे दस्तऐवज मशीन-आधारित AI भाषांतर सेवांचा वापर करून भाषांतरित करण्यात आले आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरे चुका किंवा अचूकतेचा अभाव असू शकतात. मूळ भाषेतील मूळ दस्तऐवज हा प्राधिकृत स्रोत मानला पाहिजे. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानव भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे होणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.