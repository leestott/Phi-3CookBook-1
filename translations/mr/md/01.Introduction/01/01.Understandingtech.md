# उल्लेखनीय तंत्रज्ञान

1. [DirectML](https://learn.microsoft.com/windows/ai/directml/dml?WT.mc_id=aiml-138114-kinfeylo) - DirectX 12 वर आधारित हार्डवेअर-अक्षरशः मशीन लर्निंगसाठी कमी-स्तरीय API.
2. [CUDA](https://blogs.nvidia.com/blog/what-is-cuda-2/) - Nvidia ने विकसित केलेले समांतर संगणन प्लॅटफॉर्म आणि API मॉडेल, GPU वर सामान्य-उद्देशीय प्रक्रिया सक्षम करते.
3. [ONNX](https://onnx.ai/) (ओपन न्यूरल नेटवर्क एक्सचेंज) - मशीन लर्निंग मॉडेल्सचे प्रतिनिधित्व करण्यासाठी डिझाइन केलेला खुला स्वरूप, ज्यामुळे वेगवेगळ्या ML फ्रेमवर्क्समध्ये इंटरऑपरेबिलिटी मिळते.
4. [GGUF](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md) (जनरिक ग्राफ अपडेट फॉरमॅट) - मशीन लर्निंग मॉडेल्सचे प्रतिनिधित्व आणि अद्यतन करण्यासाठी वापरला जाणारा फॉरमॅट, विशेषतः लहान भाषा मॉडेल्ससाठी उपयुक्त जो CPUs वर 4-8 बिट क्वांटायझेशनसह प्रभावीपणे चालतो.

## DirectML

DirectML हा एक कमी-स्तरीय API आहे जो हार्डवेअर-अक्षरशः मशीन लर्निंग सक्षम करतो. तो GPU प्रवेग वापरण्यासाठी DirectX 12 वर आधारित आहे आणि विक्रेता-निरपेक्ष आहे, म्हणजे तो वेगवेगळ्या GPU विक्रेत्यांवर कोड बदलाशिवाय कार्य करू शकतो. प्रामुख्याने GPU वर मॉडेल प्रशिक्षण आणि अनुमानासाठी वापरला जातो.

हार्डवेअर समर्थनाच्या बाबतीत, DirectML विविध GPUs सह कार्य करण्यासाठी डिझाइन केले गेले आहे, ज्यामध्ये AMD इंटिग्रेटेड आणि डिस्क्रीट GPUs, Intel इंटिग्रेटेड GPUs आणि NVIDIA डिस्क्रीट GPUs यांचा समावेश आहे. हे Windows AI प्लॅटफॉर्मचा भाग आहे आणि Windows 10 आणि 11 वर समर्थित आहे, ज्यामुळे कोणत्याही Windows डिव्हाइसवर मॉडेल प्रशिक्षण आणि अनुमान करता येते.

DirectML संबंधित अनेक अद्ययावत गोष्टी आणि संधी उपलब्ध आहेत, जसे की 150 पर्यंत ONNX ऑपरेटरसाठी समर्थन आणि ONNX रनटाइम आणि WinML द्वारे वापरण्यात येणे. हे प्रमुख हार्डवेअर विक्रेत्यांनी (IHVs) समर्थित आहे, ज्यांनी विविध मेटाकमांड्स लागू केले आहेत.

## CUDA

CUDA, ज्याचा अर्थ Compute Unified Device Architecture आहे, हा Nvidia ने तयार केलेला समांतर संगणन प्लॅटफॉर्म आणि API मॉडेल आहे. हे सॉफ्टवेअर डेव्हलपरना CUDA-सक्षम GPU सामान्य उद्देशीय प्रक्रिया (GPGPU) साठी वापरण्याची परवानगी देते. CUDA हे Nvidia च्या GPU प्रवेगाचे एक मुख्य घटक आहे आणि मशीन लर्निंग, वैज्ञानिक संगणन आणि व्हिडिओ प्रक्रिया यासारख्या विविध क्षेत्रांमध्ये मोठ्या प्रमाणावर वापरले जाते.

CUDA चे हार्डवेअर समर्थन केवळ Nvidia च्या GPUs पुरते मर्यादित आहे, कारण ते Nvidia द्वारे विकसित केलेले मालकीचे तंत्रज्ञान आहे. प्रत्येक आर्किटेक्चर विशिष्ट CUDA टूलकिट आवृत्त्यांचे समर्थन करते, जे डेव्हलपरना CUDA अॅप्लिकेशन्स तयार आणि चालवण्यासाठी आवश्यक लायब्ररी आणि साधने प्रदान करते.

## ONNX

ONNX (ओपन न्यूरल नेटवर्क एक्सचेंज) हा एक खुला स्वरूप आहे जो मशीन लर्निंग मॉडेल्सचे प्रतिनिधित्व करण्यासाठी डिझाइन केला आहे. तो एक विस्तारनीय संगणन ग्राफ मॉडेलची व्याख्या, तसेच अंतर्गत ऑपरेटर आणि मानक डेटा प्रकारांची व्याख्या प्रदान करतो. ONNX डेव्हलपरना वेगवेगळ्या ML फ्रेमवर्क्स दरम्यान मॉडेल हलविण्याची परवानगी देतो, ज्यामुळे इंटरऑपरेबिलिटी मिळते आणि AI अॅप्लिकेशन्स तयार व तैनात करणे सोपे होते.

Phi3 mini ONNX Runtime सह CPU आणि GPU वर चालवता येतो, ज्यामध्ये सर्व्हर प्लॅटफॉर्म्स, Windows, Linux आणि Mac डेस्कटॉप्स, तसेच मोबाइल CPUs यांचा समावेश आहे. आम्ही जोडलेल्या ऑप्टिमाइझ्ड कॉन्फिगरेशन्स खालीलप्रमाणे आहेत:

- int4 DML साठी ONNX मॉडेल: AWQ द्वारे int4 मध्ये क्वांटायझेशन
- fp16 CUDA साठी ONNX मॉडेल
- int4 CUDA साठी ONNX मॉडेल: RTN द्वारे int4 मध्ये क्वांटायझेशन
- int4 CPU आणि मोबाइलसाठी ONNX मॉडेल: RTN द्वारे int4 मध्ये क्वांटायझेशन

## Llama.cpp

Llama.cpp हे C++ मध्ये लिहिलेले एक ओपन-सोर्स सॉफ्टवेअर लायब्ररी आहे. हे Llama सह विविध मोठ्या भाषा मॉडेल्स (LLMs) वर अनुमान करते. ggml लायब्ररी (एक सामान्य-उद्देशीय टेन्सर लायब्ररी) सोबत विकसित केलेले, llama.cpp मूळ Python अंमलबजावणीच्या तुलनेत जलद अनुमान आणि कमी मेमरी वापर प्रदान करण्याचे उद्दिष्ट ठेवते. हे हार्डवेअर ऑप्टिमायझेशन, क्वांटायझेशन समर्थन करते आणि एक साधा API आणि उदाहरणे प्रदान करते. कार्यक्षम LLM अनुमानामध्ये स्वारस्य असल्यास, llama.cpp शोधण्यासारखे आहे, कारण Phi3 Llama.cpp चालवू शकतो.

## GGUF

GGUF (जनरिक ग्राफ अपडेट फॉरमॅट) हा मशीन लर्निंग मॉडेल्सचे प्रतिनिधित्व आणि अद्यतन करण्यासाठी वापरला जाणारा फॉरमॅट आहे. हा विशेषतः लहान भाषा मॉडेल्ससाठी उपयुक्त आहे, जे 4-8 बिट क्वांटायझेशनसह CPUs वर प्रभावीपणे चालतात. GGUF जलद प्रोटोटाइपिंगसाठी आणि एज डिव्हाइसेस किंवा CI/CD पाईपलाइन्ससारख्या बॅच जॉब्सवर मॉडेल्स चालवण्यासाठी फायदेशीर आहे.

**अस्वीकरण**:  
हा दस्तऐवज मशीन-आधारित एआय अनुवाद सेवांचा वापर करून अनुवादित केला गेला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित अनुवादांमध्ये त्रुटी किंवा अशुद्धता असू शकते. मूळ भाषेतील मूळ दस्तऐवज अधिकृत स्रोत मानावा. महत्त्वाच्या माहितीसाठी, व्यावसायिक मानवी अनुवादाची शिफारस केली जाते. या अनुवादाच्या वापरामुळे उद्भवणाऱ्या कोणत्याही गैरसमजुतींसाठी किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.