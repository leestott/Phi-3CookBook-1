# इंटरएक्टिव फाई 3 मिनी 4K इंस्ट्रक्ट चॅटबॉट विथ व्हिस्पर

## आढावा

इंटरएक्टिव फाई 3 मिनी 4K इंस्ट्रक्ट चॅटबॉट हे एक साधन आहे जे वापरकर्त्यांना Microsoft Phi 3 Mini 4K इंस्ट्रक्ट डेमोशी मजकूर किंवा ऑडिओ इनपुटद्वारे संवाद साधण्याची परवानगी देते. हा चॅटबॉट अनुवाद, हवामान अद्यतने आणि सामान्य माहिती गोळा करण्यासारख्या विविध कामांसाठी वापरला जाऊ शकतो.

### सुरुवात कशी करावी

हा चॅटबॉट वापरण्यासाठी खालील सूचना पाळा:

1. नवीन [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) उघडा.
2. नोटबुकच्या मुख्य विंडोमध्ये, तुम्हाला एक चॅटबॉक्स इंटरफेस दिसेल ज्यामध्ये मजकूर इनपुट बॉक्स आणि "Send" बटण असेल.
3. मजकूर आधारित चॅटबॉट वापरण्यासाठी, फक्त तुमचा संदेश मजकूर इनपुट बॉक्समध्ये टाइप करा आणि "Send" बटणावर क्लिक करा. चॅटबॉट प्रतिसाद म्हणून एक ऑडिओ फाइल प्रदान करेल, जी थेट नोटबुकमधून प्ले केली जाऊ शकते.

**टीप**: या साधनासाठी GPU आणि Microsoft Phi-3 आणि OpenAI Whisper मॉडेल्सची आवश्यकता आहे, जे भाषण ओळख आणि भाषांतरासाठी वापरले जाते.

### GPU आवश्यकता

हा डेमो चालवण्यासाठी तुम्हाला 12GB GPU मेमरीची आवश्यकता आहे.

**Microsoft-Phi-3-Mini-4K इंस्ट्रक्ट** डेमो GPU वर चालवण्यासाठी आवश्यक GPU मेमरी इनपुट डेटाच्या (ऑडिओ किंवा मजकूर) आकारावर, भाषांतरासाठी वापरल्या जाणाऱ्या भाषेवर, मॉडेलच्या गतीवर आणि GPU वर उपलब्ध मेमरीवर अवलंबून असते.

सामान्यतः, Whisper मॉडेल GPU वर चालवण्यासाठी डिझाइन केले आहे. Whisper मॉडेल चालवण्यासाठी शिफारस केलेली किमान GPU मेमरी 8 GB आहे, परंतु आवश्यक असल्यास ती जास्त मेमरी हाताळू शकते.

लक्षात ठेवा की मोठ्या प्रमाणात डेटा किंवा मॉडेलवरील विनंत्यांचा उच्च प्रमाणात वापर GPU मेमरीसाठी जास्त आवश्यकता निर्माण करू शकतो आणि/किंवा कार्यक्षमतेवर परिणाम करू शकतो. तुमच्या विशिष्ट गरजांसाठी योग्य सेटिंग्ज निर्धारित करण्यासाठी विविध कॉन्फिगरेशनसह तुमचा वापर प्रकरण चाचणी करण्याची आणि मेमरी वापराचे निरीक्षण करण्याची शिफारस केली जाते.

## E2E सॅम्पल: इंटरएक्टिव फाई 3 मिनी 4K इंस्ट्रक्ट चॅटबॉट विथ व्हिस्पर

[Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) नावाच्या जुपिटर नोटबुकमध्ये ऑडिओ किंवा मजकूर इनपुटमधून मजकूर तयार करण्यासाठी Microsoft Phi 3 Mini 4K इंस्ट्रक्ट डेमो कसा वापरायचा हे दाखवले आहे. नोटबुकमध्ये खालील फंक्शन्स परिभाषित केल्या आहेत:

1. `tts_file_name(text)`: हा फंक्शन इनपुट मजकूरावर आधारित तयार केलेल्या ऑडिओ फाइलसाठी फाइल नाव तयार करतो.
1. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: हा फंक्शन Edge TTS API वापरून इनपुट मजकूराच्या चंक्सवरून ऑडिओ फाइल तयार करतो. इनपुट पॅरामीटर्समध्ये चंक्सची यादी, स्पीच रेट, व्हॉइस नेम आणि ऑडिओ फाइल सेव्ह करण्यासाठी आउटपुट पथ यांचा समावेश आहे.
1. `talk(input_text)`: हा फंक्शन Edge TTS API वापरून ऑडिओ फाइल तयार करतो आणि ती /content/audio डिरेक्टरीमध्ये रँडम फाइल नावाने सेव्ह करतो. इनपुट पॅरामीटर म्हणजे भाषणात रूपांतर करण्यासाठीचा मजकूर आहे.
1. `run_text_prompt(message, chat_history)`: हा फंक्शन Microsoft Phi 3 Mini 4K इंस्ट्रक्ट डेमो वापरून इनपुट संदेशावरून ऑडिओ फाइल तयार करतो आणि ती चॅट इतिहासात जोडतो.
1. `run_audio_prompt(audio, chat_history)`: हा फंक्शन Whisper मॉडेल API वापरून ऑडिओ फाइलचा मजकूरात रूपांतर करतो आणि तो `run_text_prompt()` फंक्शनला पास करतो.
1. कोड Gradio अॅप लाँच करतो जो वापरकर्त्यांना Phi 3 Mini 4K इंस्ट्रक्ट डेमोशी संवाद साधण्याची परवानगी देतो, जिथे ते संदेश टाइप करू शकतात किंवा ऑडिओ फाइल्स अपलोड करू शकतात. आउटपुट अॅपमध्ये मजकूर संदेश म्हणून प्रदर्शित होते.

## अडचणी सोडवणे

Cuda GPU ड्रायव्हर्स इन्स्टॉल करणे

1. तुमच्या Linux अॅप्लिकेशन्स अपडेट असल्याची खात्री करा

    ```bash
    sudo apt update
    ```

1. Cuda ड्रायव्हर्स इन्स्टॉल करा

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

1. Cuda ड्रायव्हर स्थान नोंदणी करा

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

1. Nvidia GPU मेमरी आकार तपासा (12GB GPU मेमरी आवश्यक)

    ```bash
    nvidia-smi
    ```

1. Cache रिकामी करा: जर तुम्ही PyTorch वापरत असाल, तर torch.cuda.empty_cache() कॉल करून सर्व न वापरलेली कॅश मेमरी रिलीज करू शकता, ज्यामुळे इतर GPU अॅप्लिकेशन्ससाठी ती उपलब्ध होईल.

    ```python
    torch.cuda.empty_cache() 
    ```

1. Nvidia Cuda तपासा

    ```bash
    nvcc --version
    ```

1. Hugging Face टोकन तयार करण्यासाठी खालील कार्ये करा:

    - [Hugging Face Token Settings page](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo) वर जा.
    - **New token** निवडा.
    - तुम्हाला वापरायचे असलेल्या प्रकल्पाचे **Name** टाका.
    - **Type** **Write** म्हणून निवडा.

> **टीप**
>
> जर तुम्हाला खालील त्रुटी आली:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> हे सोडवण्यासाठी, तुमच्या टर्मिनलमध्ये खालील कमांड टाइप करा:
>
> ```bash
> sudo ldconfig
> ```

**अस्वीकरण**:  
हा दस्तऐवज मशीन-आधारित एआय भाषांतर सेवा वापरून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी कृपया लक्षात घ्या की स्वयंचलित भाषांतरे त्रुटी किंवा अचूकतेच्या कमतरता असू शकतात. मूळ भाषेतील मूळ दस्तऐवज प्राधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीकरिता व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर करून निर्माण होणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थाबद्दल आम्ही जबाबदार राहणार नाही.