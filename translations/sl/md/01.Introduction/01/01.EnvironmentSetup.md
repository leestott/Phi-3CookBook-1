# Začnite z modelom Phi-3 lokalno

Ta vodič vam bo pomagal nastaviti lokalno okolje za zagon modela Phi-3 z uporabo Ollama. Model lahko zaženete na več načinov, vključno z uporabo GitHub Codespaces, VS Code Dev Containers ali vašega lokalnega okolja.

## Nastavitev okolja

### GitHub Codespaces

Model lahko zaženete virtualno z uporabo GitHub Codespaces. Gumb bo odprl spletno različico VS Code v vašem brskalniku:

1. Odprite predlogo (to lahko traja nekaj minut):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Odprite terminalsko okno.

### VS Code Dev Containers

⚠️ Ta možnost bo delovala le, če ima vaš Docker Desktop dodeljenih vsaj 16 GB RAM-a. Če imate manj kot 16 GB RAM-a, lahko poskusite [možnost GitHub Codespaces](../../../../../md/01.Introduction/01) ali [nastavitev lokalnega okolja](../../../../../md/01.Introduction/01).

Sorodna možnost je VS Code Dev Containers, ki bo projekt odprla v lokalnem VS Code z uporabo razširitve [Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Zaženite Docker Desktop (namestite ga, če še ni nameščen).
2. Odprite projekt:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Ko se v oknu VS Code prikažejo datoteke projekta (to lahko traja nekaj minut), odprite terminalsko okno.
4. Nadaljujte z [koraki za uvedbo](../../../../../md/01.Introduction/01).

### Lokalno okolje

1. Prepričajte se, da so nameščena naslednja orodja:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testiranje modela

1. Z ukazom v Ollama prenesite in zaženite model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Prenos modela bo trajal nekaj minut.

2. Ko v izhodu vidite "success", lahko modelu pošljete sporočilo iz ukazne vrstice.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Po nekaj sekundah bi morali videti, kako model začne vračati odgovor.

4. Če želite izvedeti več o različnih tehnikah, ki se uporabljajo z jezikovnimi modeli, odprite Python beležnico [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) in zaženite vsako celico. Če ste uporabili drug model kot 'phi3:mini', spremenite `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` na vrhu datoteke po potrebi. Prav tako lahko prilagodite sistemsko sporočilo ali dodate primere z več primeri, če želite.

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitev strojnega prevajanja na osnovi umetne inteligence. Čeprav si prizadevamo za natančnost, vas prosimo, da se zavedate, da lahko avtomatizirani prevodi vsebujejo napake ali netočnosti. Izvirni dokument v njegovem maternem jeziku naj se šteje za avtoritativni vir. Za ključne informacije je priporočljivo uporabiti strokovni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napačne interpretacije, ki izhajajo iz uporabe tega prevoda.