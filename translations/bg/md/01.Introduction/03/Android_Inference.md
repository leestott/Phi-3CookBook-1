# **Извършване на инференция с Phi-3 на Android**

Нека разгледаме как можете да извършвате инференция с Phi-3-mini на устройства с Android. Phi-3-mini е нова серия модели от Microsoft, която позволява внедряване на големи езикови модели (LLMs) на крайни устройства и IoT устройства.

## Semantic Kernel и инференция

[Semantic Kernel](https://github.com/microsoft/semantic-kernel) е рамка за създаване на приложения, която ви позволява да изграждате приложения, съвместими с Azure OpenAI Service, OpenAI модели и дори локални модели. Ако сте нови в Semantic Kernel, препоръчваме да разгледате [Semantic Kernel Cookbook](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo).

### Достъп до Phi-3-mini чрез Semantic Kernel

Можете да го комбинирате с Hugging Face Connector в Semantic Kernel. Вижте този [примерен код](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo).

По подразбиране той съответства на идентификатора на модела в Hugging Face. Въпреки това, можете също да се свържете с локално изграден сървър за модела Phi-3-mini.

### Извикване на квантовани модели с Ollama или LlamaEdge

Много потребители предпочитат да използват квантовани модели, за да стартират модели локално. [Ollama](https://ollama.com/) и [LlamaEdge](https://llamaedge.com) позволяват на отделните потребители да извикват различни квантовани модели:

#### Ollama

Можете директно да стартирате `ollama run Phi-3` или да го конфигурирате офлайн, като създадете `Modelfile` с пътя към вашия файл `.gguf`.

```gguf
FROM {Add your gguf file path}
TEMPLATE \"\"\"<|user|> .Prompt<|end|> <|assistant|>\"\"\"
PARAMETER stop <|end|>
PARAMETER num_ctx 4096
```

[Примерен код](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)

#### LlamaEdge

Ако искате да използвате `.gguf` файлове както в облака, така и на крайни устройства едновременно, LlamaEdge е чудесен избор. Можете да се обърнете към този [примерен код](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo), за да започнете.

### Инсталиране и стартиране на Android телефони

1. **Изтеглете приложението MLC Chat** (безплатно) за Android телефони.
2. Изтеглете APK файла (148MB) и го инсталирайте на устройството си.
3. Стартирайте приложението MLC Chat. Ще видите списък с AI модели, включително Phi-3-mini.

В обобщение, Phi-3-mini отваря вълнуващи възможности за генеративен AI на крайни устройства, и можете да започнете да изследвате неговите възможности на Android.

**Отказ от отговорност**:  
Този документ е преведен с помощта на услуги за машинен превод с изкуствен интелект. Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи могат да съдържат грешки или неточности. Оригиналният документ на неговия изходен език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален превод от човек. Не носим отговорност за каквито и да било недоразумения или погрешни интерпретации, произтичащи от използването на този превод.