# Започнете работа с Phi-3 локално

Това ръководство ще ви помогне да настроите локалната си среда, за да стартирате модела Phi-3 с помощта на Ollama. Моделът може да се стартира по няколко начина, включително чрез GitHub Codespaces, VS Code Dev Containers или локалната ви среда.

## Настройка на средата

### GitHub Codespaces

Можете да стартирате този шаблон виртуално, като използвате GitHub Codespaces. Бутонът ще отвори уеб-базирана версия на VS Code във вашия браузър:

1. Отворете шаблона (това може да отнеме няколко минути):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Отворете терминален прозорец.

### VS Code Dev Containers

⚠️ Тази опция ще работи само ако на Docker Desktop са разпределени поне 16 GB RAM. Ако разполагате с по-малко от 16 GB RAM, можете да опитате [опцията за GitHub Codespaces](../../../../../md/01.Introduction/01) или [да го настроите локално](../../../../../md/01.Introduction/01).

Свързана опция е VS Code Dev Containers, която ще отвори проекта във вашия локален VS Code с помощта на [разширението Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Стартирайте Docker Desktop (инсталирайте го, ако още не е инсталиран).
2. Отворете проекта:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. В прозореца на VS Code, който се отваря, след като файловете на проекта се заредят (това може да отнеме няколко минути), отворете терминален прозорец.
4. Продължете с [стъпките за внедряване](../../../../../md/01.Introduction/01).

### Локална среда

1. Уверете се, че са инсталирани следните инструменти:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Тествайте модела

1. Помолете Ollama да изтегли и стартира модела phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Това ще отнеме няколко минути за изтегляне на модела.

2. След като видите "success" в изхода, можете да изпратите съобщение до този модел от подканата.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. След няколко секунди трябва да видите поток отговори от модела.

4. За да научите повече за различни техники, използвани с езикови модели, отворете Python тетрадката [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) и изпълнете всяка клетка. Ако сте използвали модел, различен от 'phi3:mini', променете `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` в горната част на файла според нуждите, а също така можете да модифицирате системното съобщение или да добавите примери за few-shot, ако желаете.

**Отказ от отговорност**:  
Този документ е преведен с помощта на машинни AI услуги за превод. Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия оригинален език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за каквито и да е недоразумения или погрешни тълкувания, произтичащи от използването на този превод.