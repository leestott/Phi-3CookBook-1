# **Lab 2 - Kør Prompt flow med Phi-3-mini i AIPC**

## **Hvad er Prompt flow**

Prompt flow er et sæt udviklingsværktøjer designet til at forenkle hele udviklingscyklussen for AI-applikationer baseret på LLM, fra idéudvikling, prototyping, test, evaluering til produktion og overvågning. Det gør prompt engineering meget lettere og giver dig mulighed for at bygge LLM-apps i produktionskvalitet.

Med prompt flow kan du:

- Oprette flows, der forbinder LLM'er, prompts, Python-kode og andre værktøjer i en eksekverbar arbejdsgang.

- Fejlsøge og iterere dine flows, især interaktionen med LLM'er, med lethed.

- Evaluere dine flows og beregne kvalitets- og præstationsmålinger med større datasæt.

- Integrere test og evaluering i dit CI/CD-system for at sikre kvaliteten af dit flow.

- Udrulle dine flows til den serverplatform, du vælger, eller nemt integrere dem i din apps kodebase.

- (Valgfrit, men stærkt anbefalet) Samarbejde med dit team ved at bruge skyversionen af Prompt flow i Azure AI.

## **Hvad er AIPC**

En AI PC har en CPU, en GPU og en NPU, hver med specifikke AI-accelerationsmuligheder. En NPU, eller neural processing unit, er en specialiseret accelerator, der håndterer kunstig intelligens (AI) og maskinlæring (ML) opgaver direkte på din PC i stedet for at sende data til behandling i skyen. GPU'en og CPU'en kan også behandle disse arbejdsbyrder, men NPU'en er særligt god til AI-beregninger med lavt strømforbrug. AI PC'en repræsenterer et fundamentalt skift i, hvordan vores computere fungerer. Det er ikke en løsning på et problem, der ikke eksisterede før. I stedet lover det at være en enorm forbedring for hverdagsbrug af PC'er.

Hvordan fungerer det? Sammenlignet med generativ AI og de massive store sprogmodeller (LLM'er), der er trænet på enorme mængder offentlige data, er AI'en, der vil finde sted på din PC, mere tilgængelig på stort set alle niveauer. Konceptet er lettere at forstå, og fordi det er trænet på dine data uden behov for at få adgang til skyen, er fordelene mere umiddelbart tiltalende for en bredere befolkning.

På kort sigt involverer AI PC-verdenen personlige assistenter og mindre AI-modeller, der kører direkte på din PC, bruger dine data til at tilbyde personlige, private og mere sikre AI-forbedringer til ting, du allerede gør hver dag – tage mødenotater, organisere en fantasy football-liga, automatisere forbedringer til foto- og videoredigering eller planlægge den perfekte rejseplan for en familiefest baseret på alles ankomst- og afrejsetider.

## **Bygning af genereringskode-flows på AIPC**

***Note***: Hvis du ikke har gennemført miljøinstallationen, bedes du besøge [Lab 0 - Installationer](./01.Installations.md)

1. Åbn Prompt flow Extension i Visual Studio Code og opret et tomt flow-projekt.

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.da.png)

2. Tilføj input- og output-parametre, og tilføj Python-kode som et nyt flow.

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.da.png)

Du kan referere til denne struktur (flow.dag.yaml) for at konstruere dit flow:

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. Tilføj kode i ***Chat_With_Phi3.py***:

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Du kan teste flowet fra Debug eller Run for at kontrollere, om genereringskoden fungerer korrekt.

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.da.png)

5. Kør flowet som en udviklings-API i terminalen:

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Du kan teste det i Postman / Thunder Client.

### **Bemærk**

1. Den første kørsel tager lang tid. Det anbefales at downloade Phi-3-modellen fra Hugging Face CLI.

2. På grund af den begrænsede regnekraft i Intel NPU anbefales det at bruge Phi-3-mini-4k-instruct.

3. Vi bruger Intel NPU Acceleration til at kvantisere INT4-konvertering, men hvis du genstarter tjenesten, skal du slette cache- og nc_workshop-mapperne.

## **Ressourcer**

1. Lær Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Lær Intel NPU Acceleration [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Eksempelkode, download [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC)

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hjælp af AI-baserede maskinoversættelsestjenester. Selvom vi bestræber os på at sikre nøjagtighed, skal det bemærkes, at automatiserede oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig oversættelse. Vi påtager os ikke ansvar for misforståelser eller fejltolkninger, der opstår som følge af brugen af denne oversættelse.