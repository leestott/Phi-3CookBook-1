## Phi-familien i NVIDIA NIM

NVIDIA NIM er et sæt brugervenlige mikrotjenester designet til at accelerere implementeringen af generative AI-modeller på tværs af cloud, datacenter og arbejdsstationer. NIM'er er kategoriseret efter modelfamilie og på modelbasis. For eksempel bringer NVIDIA NIM for store sprogmodeller (LLMs) kraften fra avancerede LLM'er til virksomhedsapplikationer og leverer uovertrufne muligheder inden for naturlig sprogbehandling og forståelse.

NIM gør det nemt for IT- og DevOps-teams at selvhoste store sprogmodeller (LLMs) i deres egne administrerede miljøer, samtidig med at udviklere får adgang til industristandard-API'er, der giver dem mulighed for at bygge kraftfulde copiloter, chatbots og AI-assistenter, som kan transformere deres forretning. Ved at udnytte NVIDIAs avancerede GPU-acceleration og skalerbare implementering tilbyder NIM den hurtigste vej til inferens med uovertruffen ydeevne.

Du kan bruge NVIDIA NIM til at lave inferens med Phi-familiemodeller.

![nim](../../../../../translated_images/Phi-NIM.45af94d89220fbbbc85f8da0379150a29cc88c3dd8ec417b1d3b7237bbe1c58a.da.png)

### **Eksempler - Phi-3-Vision i NVIDIA NIM**

Forestil dig, at du har et billede (`demo.png`), og du ønsker at generere Python-kode, der behandler dette billede og gemmer en ny version af det (`phi-3-vision.jpg`).

Koden ovenfor automatiserer denne proces ved at:

1. Opsætte miljøet og nødvendige konfigurationer.
2. Oprette en prompt, der instruerer modellen til at generere den nødvendige Python-kode.
3. Sende prompten til modellen og indsamle den genererede kode.
4. Udtrække og køre den genererede kode.
5. Vise det originale og behandlede billede.

Denne tilgang udnytter AI's kraft til at automatisere billedbehandlingsopgaver, hvilket gør det lettere og hurtigere at nå dine mål.

[Eksempelkodeløsning](../../../../../code/06.E2E/E2E_Nvidia_NIM_Phi3_Vision.ipynb)

Lad os gennemgå, hvad hele koden gør trin for trin:

1. **Installer nødvendige pakker**:
    ```python
    !pip install langchain_nvidia_ai_endpoints -U
    ```
    Denne kommando installerer pakken `langchain_nvidia_ai_endpoints` og sikrer, at det er den nyeste version.

2. **Importer nødvendige moduler**:
    ```python
    from langchain_nvidia_ai_endpoints import ChatNVIDIA
    import getpass
    import os
    import base64
    ```
    Disse imports henter de nødvendige moduler til at interagere med NVIDIA AI-endpoints, håndtere adgangskoder sikkert, interagere med operativsystemet og kode/dekode data i base64-format.

3. **Opsæt API-nøgle**:
    ```python
    if not os.getenv("NVIDIA_API_KEY"):
        os.environ["NVIDIA_API_KEY"] = getpass.getpass("Enter your NVIDIA API key: ")
    ```
    Denne kode tjekker, om miljøvariablen `NVIDIA_API_KEY` er sat. Hvis ikke, beder den brugeren om at indtaste deres API-nøgle sikkert.

4. **Definer model og billedsti**:
    ```python
    model = 'microsoft/phi-3-vision-128k-instruct'
    chat = ChatNVIDIA(model=model)
    img_path = './imgs/demo.png'
    ```
    Dette sætter den model, der skal bruges, opretter en instans af `ChatNVIDIA` med den angivne model og definerer stien til billedfilen.

5. **Opret tekstprompt**:
    ```python
    text = "Please create Python code for image, and use plt to save the new picture under imgs/ and name it phi-3-vision.jpg."
    ```
    Denne prompt instruerer modellen til at generere Python-kode til at behandle et billede.

6. **Kod billede i Base64**:
    ```python
    with open(img_path, "rb") as f:
        image_b64 = base64.b64encode(f.read()).decode()
    image = f'<img src="data:image/png;base64,{image_b64}" />'
    ```
    Denne kode læser billedfilen, koder den i base64 og opretter et HTML-billedtag med de kodede data.

7. **Kombiner tekst og billede til prompt**:
    ```python
    prompt = f"{text} {image}"
    ```
    Dette kombinerer tekstprompten og HTML-billedtagget til en enkelt streng.

8. **Generer kode ved hjælp af ChatNVIDIA**:
    ```python
    code = ""
    for chunk in chat.stream(prompt):
        print(chunk.content, end="")
        code += chunk.content
    ```
    Denne kode sender prompten til `ChatNVIDIA` model and collects the generated code in chunks, printing and appending each chunk to the `code`-strengen.

9. **Udtræk Python-kode fra genereret indhold**:
    ```python
    begin = code.index('```python') + 9
    code = code[begin:]
    end = code.index('```')
    code = code[:end]
    ```
    Dette udtrækker den faktiske Python-kode fra det genererede indhold ved at fjerne markdown-formateringen.

10. **Kør den genererede kode**:
    ```python
    import subprocess
    result = subprocess.run(["python", "-c", code], capture_output=True)
    ```
    Denne kode kører den udtrukne Python-kode som en subprocess og fanger dens output.

11. **Vis billeder**:
    ```python
    from IPython.display import Image, display
    display(Image(filename='./imgs/phi-3-vision.jpg'))
    display(Image(filename='./imgs/demo.png'))
    ```
    Disse linjer viser billederne ved hjælp af modulet `IPython.display`.

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hjælp af AI-baserede maskinoversættelsestjenester. Selvom vi bestræber os på nøjagtighed, skal det bemærkes, at automatiserede oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der måtte opstå som følge af brugen af denne oversættelse.