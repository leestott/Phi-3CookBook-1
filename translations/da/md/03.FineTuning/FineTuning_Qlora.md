**Finjustering af Phi-3 med QLoRA**

Finjustering af Microsofts Phi-3 Mini sprogmodel ved hjælp af [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA vil hjælpe med at forbedre forståelsen af samtaler og genereringen af svar.

For at indlæse modeller i 4 bits med transformers og bitsandbytes, skal du installere accelerate og transformers fra kildekoden og sikre dig, at du har den nyeste version af bitsandbytes-biblioteket.

**Eksempler**
- [Lær mere med denne eksempelsnotebook](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Eksempel på Python finjusteringsscript](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Eksempel på finjustering med LORA på Hugging Face Hub](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Eksempel på finjustering med QLORA på Hugging Face Hub](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hjælp af maskinbaserede AI-oversættelsestjenester. Selvom vi bestræber os på nøjagtighed, skal du være opmærksom på, at automatiserede oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der måtte opstå som følge af brugen af denne oversættelse.