# ਕੁੰਜੀ ਤਕਨਾਲੋਜੀਆਂ ਵਿੱਚ ਸ਼ਾਮਲ ਹਨ

1. [DirectML](https://learn.microsoft.com/windows/ai/directml/dml?WT.mc_id=aiml-138114-kinfeylo) - DirectX 12 ਦੇ ਉੱਪਰ ਬਣਾਈ ਗਈ ਹਾਰਡਵੇਅਰ-ਤੇਜ਼ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਲਈ ਇੱਕ ਨੀਚਲੇ ਪੱਧਰ ਦੀ API।
2. [CUDA](https://blogs.nvidia.com/blog/what-is-cuda-2/) - Nvidia ਦੁਆਰਾ ਵਿਕਸਿਤ ਇੱਕ ਪੈਰਲੇਲ ਕੰਪਿਊਟਿੰਗ ਪਲੇਟਫਾਰਮ ਅਤੇ ਐਪਲੀਕੇਸ਼ਨ ਪ੍ਰੋਗ੍ਰਾਮਿੰਗ ਇੰਟਰਫੇਸ (API) ਮਾਡਲ, ਜੋ ਗ੍ਰਾਫਿਕਸ ਪ੍ਰੋਸੈਸਿੰਗ ਯੂਨਿਟਸ (GPUs) 'ਤੇ ਜਨਰਲ-ਪਰਪਜ਼ ਪ੍ਰੋਸੈਸਿੰਗ ਨੂੰ ਯੋਗ ਬਣਾਉਂਦਾ ਹੈ।
3. [ONNX](https://onnx.ai/) (ਓਪਨ ਨਿਊਰਲ ਨੈਟਵਰਕ ਐਕਸਚੇਂਜ) - ਇੱਕ ਖੁੱਲ੍ਹਾ ਫਾਰਮੈਟ ਜੋ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲਾਂ ਦਾ ਪ੍ਰਤੀਨਿਧਿਤਾ ਕਰਨ ਲਈ ਤਿਆਰ ਕੀਤਾ ਗਿਆ ਹੈ ਅਤੇ ਵੱਖ-ਵੱਖ ML ਫਰੇਮਵਰਕਾਂ ਦੇ ਵਿਚਕਾਰ ਅੰਤਰਕ੍ਰਿਆਸ਼ੀਲਤਾ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ।
4. [GGUF](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md) (ਜਨਰਲ ਗ੍ਰਾਫ ਅੱਪਡੇਟ ਫਾਰਮੈਟ) - ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲਾਂ ਨੂੰ ਪ੍ਰਤੀਨਿਧਿਤ ਅਤੇ ਅੱਪਡੇਟ ਕਰਨ ਲਈ ਵਰਤਿਆ ਜਾਣ ਵਾਲਾ ਫਾਰਮੈਟ, ਖਾਸ ਤੌਰ 'ਤੇ ਛੋਟੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ ਲਈ ਲਾਭਦਾਇਕ ਹੈ ਜੋ CPUs 'ਤੇ 4-8bit ਕੁਆੰਟਾਈਜ਼ੇਸ਼ਨ ਨਾਲ ਪ੍ਰਭਾਵਸ਼ਾਲੀ ਤਰੀਕੇ ਨਾਲ ਚਲ ਸਕਦੇ ਹਨ।

## DirectML

DirectML ਇੱਕ ਨੀਚਲੇ ਪੱਧਰ ਦੀ API ਹੈ ਜੋ ਹਾਰਡਵੇਅਰ-ਤੇਜ਼ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਨੂੰ ਯੋਗ ਬਣਾਉਂਦੀ ਹੈ। ਇਹ DirectX 12 ਦੇ ਉੱਪਰ ਬਣਾਈ ਗਈ ਹੈ ਤਾਂ ਜੋ GPU ਤੇਜ਼ੀ ਦਾ ਪੂਰਾ ਫਾਇਦਾ ਲਿਆ ਜਾ ਸਕੇ ਅਤੇ ਇਹ ਵੈਂਡਰ-ਅਗਨਾਸਟਿਕ ਹੈ, ਜਿਸਦਾ ਮਤਲਬ ਹੈ ਕਿ ਇਹ ਵੱਖ-ਵੱਖ GPU ਵੈਂਡਰਾਂ ਦੇ ਮਸ਼ੀਨਾਂ 'ਤੇ ਬਿਨਾਂ ਕੋਡ ਬਦਲਾਅ ਦੇ ਕੰਮ ਕਰ ਸਕਦੀ ਹੈ। ਇਹ ਮੁੱਖ ਤੌਰ 'ਤੇ ਮਾਡਲ ਟ੍ਰੇਨਿੰਗ ਅਤੇ ਇੰਫਰੈਂਸਿੰਗ ਵਰਕਲੋਡਾਂ ਲਈ ਵਰਤੀ ਜਾਂਦੀ ਹੈ।

ਹਾਰਡਵੇਅਰ ਸਹਾਇਤਾ ਦੇ ਹਿਸਾਬ ਨਾਲ, DirectML ਵੱਖ-ਵੱਖ GPUs ਦੇ ਨਾਲ ਕੰਮ ਕਰਨ ਲਈ ਤਿਆਰ ਕੀਤੀ ਗਈ ਹੈ, ਜਿਵੇਂ ਕਿ AMD ਇੰਟੇਗ੍ਰੇਟਡ ਅਤੇ ਡਿਸਕ੍ਰੀਟ GPUs, Intel ਇੰਟੇਗ੍ਰੇਟਡ GPUs, ਅਤੇ NVIDIA ਡਿਸਕ੍ਰੀਟ GPUs। ਇਹ Windows AI ਪਲੇਟਫਾਰਮ ਦਾ ਹਿੱਸਾ ਹੈ ਅਤੇ Windows 10 ਅਤੇ 11 ਤੇ ਸਪੋਰਟ ਕੀਤੀ ਜਾਂਦੀ ਹੈ, ਜਿਸ ਨਾਲ ਕਿਸੇ ਵੀ Windows ਡਿਵਾਈਸ 'ਤੇ ਮਾਡਲ ਟ੍ਰੇਨਿੰਗ ਅਤੇ ਇੰਫਰੈਂਸਿੰਗ ਸੰਭਵ ਹੁੰਦੀ ਹੈ।

DirectML ਨਾਲ ਸੰਬੰਧਤ ਅਪਡੇਟ ਅਤੇ ਮੌਕੇ ਵੀ ਰਹੇ ਹਨ, ਜਿਵੇਂ ਕਿ 150 ਤੱਕ ONNX ਓਪਰੇਟਰਾਂ ਨੂੰ ਸਪੋਰਟ ਕਰਨਾ ਅਤੇ ONNX ਰੰਟਾਈਮ ਅਤੇ WinML ਦੁਆਰਾ ਵਰਤਿਆ ਜਾਣਾ। ਇਹ ਵੱਡੇ ਇੰਟੇਗ੍ਰੇਟਡ ਹਾਰਡਵੇਅਰ ਵੈਂਡਰਾਂ (IHVs) ਦੁਆਰਾ ਸਹਾਇਤਾ ਪ੍ਰਾਪਤ ਕਰਦਾ ਹੈ, ਜਿਨ੍ਹਾਂ ਨੇ ਵੱਖ-ਵੱਖ ਮੈਟਾਕਮਾਂਡਾਂ ਨੂੰ ਲਾਗੂ ਕੀਤਾ ਹੈ।

## CUDA

CUDA, ਜਿਸਦਾ ਪੂਰਾ ਨਾਮ Compute Unified Device Architecture ਹੈ, Nvidia ਦੁਆਰਾ ਬਣਾਇਆ ਗਿਆ ਇੱਕ ਪੈਰਲੇਲ ਕੰਪਿਊਟਿੰਗ ਪਲੇਟਫਾਰਮ ਅਤੇ ਐਪਲੀਕੇਸ਼ਨ ਪ੍ਰੋਗ੍ਰਾਮਿੰਗ ਇੰਟਰਫੇਸ (API) ਮਾਡਲ ਹੈ। ਇਹ ਸੌਫਟਵੇਅਰ ਡਿਵੈਲਪਰਾਂ ਨੂੰ CUDA-ਯੋਗ ਗ੍ਰਾਫਿਕਸ ਪ੍ਰੋਸੈਸਿੰਗ ਯੂਨਿਟ (GPU) ਨੂੰ ਜਨਰਲ ਪਰਪਜ਼ ਪ੍ਰੋਸੈਸਿੰਗ ਲਈ ਵਰਤਣ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ - ਜਿਸਨੂੰ GPGPU (General-Purpose computing on Graphics Processing Units) ਕਿਹਾ ਜਾਂਦਾ ਹੈ। CUDA Nvidia ਦੇ GPU ਐਕਸਲੇਰੇਸ਼ਨ ਦਾ ਇੱਕ ਮੁੱਖ ਯੋਗਕਾਰਕ ਹੈ ਅਤੇ ਇਹ ਮਸ਼ੀਨ ਲਰਨਿੰਗ, ਵਿਗਿਆਨਕ ਕੰਪਿਊਟਿੰਗ ਅਤੇ ਵੀਡੀਓ ਪ੍ਰੋਸੈਸਿੰਗ ਸਮੇਤ ਕਈ ਖੇਤਰਾਂ ਵਿੱਚ ਵਿਆਪਕ ਤੌਰ 'ਤੇ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ।

CUDA ਲਈ ਹਾਰਡਵੇਅਰ ਸਹਾਇਤਾ ਖਾਸ ਤੌਰ 'ਤੇ Nvidia ਦੇ GPUs ਲਈ ਹੈ, ਕਿਉਂਕਿ ਇਹ Nvidia ਦੁਆਰਾ ਵਿਕਸਿਤ ਇੱਕ ਮਲਕੀਅਤ ਤਕਨਾਲੋਜੀ ਹੈ। ਹਰ ਆਰਕੀਟੈਕਚਰ CUDA ਟੂਲਕਿਟ ਦੇ ਖਾਸ ਵਰਜਨਾਂ ਦਾ ਸਮਰਥਨ ਕਰਦਾ ਹੈ, ਜੋ ਡਿਵੈਲਪਰਾਂ ਨੂੰ CUDA ਐਪਲੀਕੇਸ਼ਨਾਂ ਨੂੰ ਬਣਾਉਣ ਅਤੇ ਚਲਾਉਣ ਲਈ ਲੋੜੀਂਦੇ ਲਾਇਬ੍ਰੇਰੀਆਂ ਅਤੇ ਟੂਲ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ।

## ONNX

ONNX (ਓਪਨ ਨਿਊਰਲ ਨੈਟਵਰਕ ਐਕਸਚੇਂਜ) ਇੱਕ ਖੁੱਲ੍ਹਾ ਫਾਰਮੈਟ ਹੈ ਜੋ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲਾਂ ਨੂੰ ਪ੍ਰਤੀਨਿਧਿਤ ਕਰਨ ਲਈ ਤਿਆਰ ਕੀਤਾ ਗਿਆ ਹੈ। ਇਹ ਇੱਕ ਵਧਾਏ ਜਾ ਸਕਣ ਵਾਲੇ ਕੰਪਿਊਟੇਸ਼ਨ ਗ੍ਰਾਫ ਮਾਡਲ ਦੀ ਪਰਿਭਾਸ਼ਾ ਪ੍ਰਦਾਨ ਕਰਦਾ ਹੈ, ਨਾਲ ਹੀ ਬਿਲਟ-ਇਨ ਓਪਰੇਟਰਾਂ ਅਤੇ ਮਿਆਰੀ ਡੇਟਾ ਪ੍ਰਕਾਰਾਂ ਦੀਆਂ ਪਰਿਭਾਸ਼ਾਵਾਂ। ONNX ਡਿਵੈਲਪਰਾਂ ਨੂੰ ਵੱਖ-ਵੱਖ ML ਫਰੇਮਵਰਕਾਂ ਦੇ ਵਿਚਕਾਰ ਮਾਡਲਾਂ ਨੂੰ ਹਿਲਾਉਣ ਦੀ ਆਗਿਆ ਦਿੰਦਾ ਹੈ, ਜਿਸ ਨਾਲ ਅੰਤਰਕ੍ਰਿਆਸ਼ੀਲਤਾ ਯੋਗ ਬਣਦੀ ਹੈ ਅਤੇ AI ਐਪਲੀਕੇਸ਼ਨਾਂ ਨੂੰ ਬਣਾਉਣ ਅਤੇ ਡਿਪਲੌਇ ਕਰਨ ਵਿੱਚ ਆਸਾਨੀ ਹੁੰਦੀ ਹੈ।

Phi3 mini ONNX Runtime ਦੀ ਵਰਤੋਂ ਕਰਕੇ CPU ਅਤੇ GPU ਉੱਪਰ ਚਲ ਸਕਦਾ ਹੈ, ਜੋ ਸਰਵਰ ਪਲੇਟਫਾਰਮ, Windows, Linux ਅਤੇ Mac ਡੈਸਕਟਾਪ, ਅਤੇ ਮੋਬਾਇਲ CPUs 'ਤੇ ਕੰਮ ਕਰਦਾ ਹੈ। ਅਸੀਂ ਜੋ ਅਪਟਿਮਾਈਜ਼ਡ ਕਨਫਿਗਰੇਸ਼ਨ ਸ਼ਾਮਲ ਕੀਤੇ ਹਨ, ਉਹ ਹਨ:

- int4 DML ਲਈ ONNX ਮਾਡਲ: AWQ ਰਾਹੀਂ int4 ਵਿੱਚ ਕੁਆੰਟਾਈਜ਼ ਕੀਤਾ ਗਿਆ
- fp16 CUDA ਲਈ ONNX ਮਾਡਲ
- int4 CUDA ਲਈ ONNX ਮਾਡਲ: RTN ਰਾਹੀਂ int4 ਵਿੱਚ ਕੁਆੰਟਾਈਜ਼ ਕੀਤਾ ਗਿਆ
- int4 CPU ਅਤੇ ਮੋਬਾਇਲ ਲਈ ONNX ਮਾਡਲ: RTN ਰਾਹੀਂ int4 ਵਿੱਚ ਕੁਆੰਟਾਈਜ਼ ਕੀਤਾ ਗਿਆ

## Llama.cpp

Llama.cpp ਇੱਕ ਖੁੱਲ੍ਹੇ ਸਰੋਤ ਵਾਲੀ ਸੌਫਟਵੇਅਰ ਲਾਇਬ੍ਰੇਰੀ ਹੈ ਜੋ C++ ਵਿੱਚ ਲਿਖੀ ਗਈ ਹੈ। ਇਹ ਵੱਖ-ਵੱਖ ਵੱਡੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ (LLMs), ਜਿਵੇਂ ਕਿ Llama, 'ਤੇ ਇੰਫਰੈਂਸ ਕਰਦੀ ਹੈ। ggml ਲਾਇਬ੍ਰੇਰੀ (ਇੱਕ ਜਨਰਲ-ਪਰਪਜ਼ ਟੈਂਸਰ ਲਾਇਬ੍ਰੇਰੀ) ਦੇ ਨਾਲ ਵਿਕਸਿਤ, llama.cpp ਮੂਲ Python ਇੰਪਲੀਮੈਂਟੇਸ਼ਨ ਨਾਲੋਂ ਤੇਜ਼ ਇੰਫਰੈਂਸ ਅਤੇ ਘੱਟ ਮੈਮੋਰੀ ਦੀ ਵਰਤੋਂ ਪ੍ਰਦਾਨ ਕਰਨ ਦਾ ਉਦੇਸ਼ ਰੱਖਦੀ ਹੈ। ਇਹ ਹਾਰਡਵੇਅਰ ਅਪਟਿਮਾਈਜ਼ੇਸ਼ਨ, ਕੁਆੰਟਾਈਜ਼ੇਸ਼ਨ, ਅਤੇ ਇੱਕ ਸਧਾਰਣ API ਅਤੇ ਉਦਾਹਰਣਾਂ ਦੀ ਸਹੂਲਤ ਦਿੰਦੀ ਹੈ। ਜੇ ਤੁਸੀਂ ਪ੍ਰਭਾਵਸ਼ਾਲੀ LLM ਇੰਫਰੈਂਸ ਵਿੱਚ ਰੁਚੀ ਰੱਖਦੇ ਹੋ, ਤਾਂ llama.cpp ਦੀ ਖੋਜ ਕਰਨ ਵਾਲਾ ਹੈ ਕਿਉਂਕਿ Phi3 Llama.cpp ਚਲਾ ਸਕਦਾ ਹੈ।

## GGUF

GGUF (ਜਨਰਲ ਗ੍ਰਾਫ ਅੱਪਡੇਟ ਫਾਰਮੈਟ) ਇੱਕ ਫਾਰਮੈਟ ਹੈ ਜੋ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲਾਂ ਨੂੰ ਪ੍ਰਤੀਨਿਧਿਤ ਅਤੇ ਅੱਪਡੇਟ ਕਰਨ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ। ਇਹ ਖਾਸ ਤੌਰ 'ਤੇ ਛੋਟੇ ਭਾਸ਼ਾ ਮਾਡਲਾਂ (SLMs) ਲਈ ਲਾਭਦਾਇਕ ਹੈ ਜੋ CPUs 'ਤੇ 4-8bit ਕੁਆੰਟਾਈਜ਼ੇਸ਼ਨ ਨਾਲ ਪ੍ਰਭਾਵਸ਼ਾਲੀ ਤਰੀਕੇ ਨਾਲ ਚਲ ਸਕਦੇ ਹਨ। GGUF ਤੇਜ਼ ਪ੍ਰੋਟੋਟਾਈਪਿੰਗ ਅਤੇ ਐਜ ਡਿਵਾਈਸਾਂ 'ਤੇ ਜਾਂ CI/CD ਪਾਈਪਲਾਈਨਾਂ ਵਰਗੇ ਬੈਚ ਜੌਬਜ਼ ਵਿੱਚ ਮਾਡਲ ਚਲਾਉਣ ਲਈ ਲਾਭਦਾਇਕ ਹੈ।

**ਅਸਵੀਕਾਰਨਾ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ ਮਸ਼ੀਨ-ਅਧਾਰਿਤ AI ਅਨੁਵਾਦ ਸੇਵਾਵਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਅਸੀਂ ਸਹੀ ਹੋਣ ਲਈ ਯਤਨਸ਼ੀਲ ਹਾਂ, ਪਰ ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚੱਜੇਪਣ ਹੋ ਸਕਦੇ ਹਨ। ਇਸ ਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੌਜੂਦ ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਿਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੇ ਉਪਯੋਗ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੀਆਂ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀਆਂ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆਵਾਂ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।