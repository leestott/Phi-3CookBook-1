# ਫ਼ਾਈ-3 ਨੂੰ ਲੋਕਲ ਤੌਰ 'ਤੇ ਸ਼ੁਰੂ ਕਰੋ

ਇਹ ਗਾਈਡ ਤੁਹਾਨੂੰ ਆਪਣੇ ਲੋਕਲ ਇਨਵਾਇਰਨਮੈਂਟ ਨੂੰ Ollama ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਫ਼ਾਈ-3 ਮਾਡਲ ਚਲਾਉਣ ਲਈ ਸੈਟਅੱਪ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰੇਗੀ। ਤੁਸੀਂ ਇਹ ਮਾਡਲ ਕਈ ਤਰੀਕਿਆਂ ਨਾਲ ਚਲਾ ਸਕਦੇ ਹੋ, ਜਿਵੇਂ ਕਿ GitHub Codespaces, VS Code Dev Containers, ਜਾਂ ਆਪਣਾ ਲੋਕਲ ਇਨਵਾਇਰਨਮੈਂਟ।

## ਇਨਵਾਇਰਨਮੈਂਟ ਸੈਟਅੱਪ

### GitHub Codespaces

ਤੁਸੀਂ GitHub Codespaces ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਇਸ ਟੈਂਪਲੇਟ ਨੂੰ ਵਰਚੁਅਲ ਤਰੀਕੇ ਨਾਲ ਚਲਾ ਸਕਦੇ ਹੋ। ਬਟਨ ਤੁਹਾਡੇ ਬਰਾਊਜ਼ਰ ਵਿੱਚ ਇੱਕ ਵੈੱਬ-ਅਧਾਰਤ VS Code ਇੰਸਟੈਂਸ ਖੋਲ੍ਹੇਗਾ:

1. ਟੈਂਪਲੇਟ ਖੋਲ੍ਹੋ (ਇਸ ਵਿੱਚ ਕੁਝ ਮਿੰਟ ਲੱਗ ਸਕਦੇ ਹਨ):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. ਟਰਮੀਨਲ ਵਿੰਡੋ ਖੋਲ੍ਹੋ

### VS Code Dev Containers

⚠️ ਇਹ ਵਿਕਲਪ ਤਦ ਹੀ ਕੰਮ ਕਰੇਗਾ ਜੇਕਰ ਤੁਹਾਡਾ Docker Desktop ਘੱਟੋ-ਘੱਟ 16 GB RAM ਨੂੰ ਐਲੋਕੇਟ ਕੀਤਾ ਗਿਆ ਹੋਵੇ। ਜੇਕਰ ਤੁਹਾਡੇ ਕੋਲ 16 GB RAM ਤੋਂ ਘੱਟ ਹੈ, ਤਾਂ ਤੁਸੀਂ [GitHub Codespaces ਵਿਕਲਪ](../../../../../md/01.Introduction/01) ਜਾਂ [ਲੋਕਲ ਤੌਰ 'ਤੇ ਸੈਟਅੱਪ](../../../../../md/01.Introduction/01) ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰ ਸਕਦੇ ਹੋ।

ਇਕ ਹੋਰ ਸਮੀਪਤਾ VS Code Dev Containers ਹੈ, ਜੋ ਪ੍ਰੋਜੈਕਟ ਨੂੰ ਤੁਹਾਡੇ ਲੋਕਲ VS Code ਵਿੱਚ [Dev Containers ਐਕਸਟੈਂਸ਼ਨ](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਖੋਲ੍ਹੇਗਾ:

1. Docker Desktop ਸ਼ੁਰੂ ਕਰੋ (ਜੇਕਰ ਇੰਸਟਾਲ ਨਹੀਂ ਹੈ ਤਾਂ ਇਸਨੂੰ ਇੰਸਟਾਲ ਕਰੋ)
2. ਪ੍ਰੋਜੈਕਟ ਖੋਲ੍ਹੋ:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. VS Code ਵਿੰਡੋ ਵਿੱਚ ਜੋ ਖੁਲ੍ਹੇਗੀ, ਜਦੋਂ ਪ੍ਰੋਜੈਕਟ ਫਾਈਲਾਂ ਦਿਖਾਈ ਦੇਣ ਲੱਗਣ (ਇਸ ਵਿੱਚ ਕੁਝ ਮਿੰਟ ਲੱਗ ਸਕਦੇ ਹਨ), ਟਰਮੀਨਲ ਵਿੰਡੋ ਖੋਲ੍ਹੋ।
4. [ਡਿਪਲੌਇਮੈਂਟ ਸਟੈਪਸ](../../../../../md/01.Introduction/01) ਨਾਲ ਜਾਰੀ ਰੱਖੋ।

### ਲੋਕਲ ਇਨਵਾਇਰਨਮੈਂਟ

1. ਯਕੀਨੀ ਬਣਾਓ ਕਿ ਹੇਠਾਂ ਦਿੱਤੇ ਟੂਲ ਇੰਸਟਾਲ ਹਨ:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## ਮਾਡਲ ਦੀ ਟੈਸਟਿੰਗ ਕਰੋ

1. Ollama ਨੂੰ phi3:mini ਮਾਡਲ ਡਾਊਨਲੋਡ ਅਤੇ ਚਲਾਉਣ ਲਈ ਕਹੋ:

    ```shell
    ollama run phi3:mini
    ```

    ਇਸਨੂੰ ਮਾਡਲ ਡਾਊਨਲੋਡ ਕਰਨ ਵਿੱਚ ਕੁਝ ਮਿੰਟ ਲੱਗਣਗੇ।

2. ਜਦੋਂ ਆਉਟਪੁੱਟ ਵਿੱਚ "success" ਦਿਖਾਈ ਦੇਵੇ, ਤਾਂ ਤੁਸੀਂ ਪ੍ਰੌਮਪਟ ਤੋਂ ਉਸ ਮਾਡਲ ਨੂੰ ਸੁਨੇਹਾ ਭੇਜ ਸਕਦੇ ਹੋ।

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. ਕੁਝ ਸਕਿੰਟਾਂ ਬਾਅਦ, ਤੁਹਾਨੂੰ ਮਾਡਲ ਤੋਂ ਇੱਕ ਰਿਸਪਾਂਸ ਸਟ੍ਰੀਮ ਦਿਖਾਈ ਦੇਵੇਗਾ।

4. ਵੱਖ-ਵੱਖ ਭਾਸ਼ਾ ਮਾਡਲ ਤਕਨੀਕਾਂ ਬਾਰੇ ਜਾਣਨ ਲਈ, Python ਨੋਟਬੁੱਕ [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) ਖੋਲ੍ਹੋ ਅਤੇ ਹਰ ਸੈੱਲ ਚਲਾਓ। ਜੇਕਰ ਤੁਸੀਂ 'phi3:mini' ਤੋਂ ਇਲਾਵਾ ਕੋਈ ਹੋਰ ਮਾਡਲ ਵਰਤਿਆ ਹੈ, ਤਾਂ ਫਾਈਲ ਦੇ ਉਪਰਲੇ ਹਿੱਸੇ ਵਿੱਚ `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` ਨੂੰ ਲੋੜ ਅਨੁਸਾਰ ਬਦਲੋ, ਅਤੇ ਤੁਸੀਂ ਸਿਸਟਮ ਸੁਨੇਹਾ ਜਾਂ ਫਿਊ-ਸ਼ਾਟ ਉਦਾਹਰਣਾਂ ਨੂੰ ਵੀ ਸੋਧ ਸਕਦੇ ਹੋ।

**ਅਸਵੀਕਰਤੀ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ ਮਸ਼ੀਨ ਅਧਾਰਿਤ AI ਅਨੁਵਾਦ ਸੇਵਾਵਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਅਸੀਂ ਸਹੀ ਹੋਣ ਲਈ ਪ੍ਰਯਤਨਸ਼ੀਲ ਹਾਂ, ਪਰ ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਵਿਧਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਇਸ ਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੌਜੂਦ ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਅਧਿਕਾਰਕ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੇ ਪ੍ਰਯੋਗ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।