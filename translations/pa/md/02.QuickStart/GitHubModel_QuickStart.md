## ਗਿਟਹੱਬ ਮਾਡਲਜ਼ - ਸੀਮਿਤ ਜਨਤਕ ਬੀਟਾ

[ਗਿਟਹੱਬ ਮਾਡਲਜ਼](https://github.com/marketplace/models) ਵਿੱਚ ਤੁਹਾਡਾ ਸਵਾਗਤ ਹੈ! ਅਸੀਂ ਤੁਹਾਡੇ ਲਈ ਐਜ਼ਰ ਏਆਈ 'ਤੇ ਹੋਸਟ ਕੀਤੇ ਗਏ ਐਆਈ ਮਾਡਲਜ਼ ਦੀ ਖੋਜ ਕਰਨ ਲਈ ਸਭ ਕੁਝ ਤਿਆਰ ਰੱਖਿਆ ਹੈ।

![GitHubModel](../../../../translated_images/GitHub_ModelCatalog.4fc858ab26afe64c43f5e423ad0c5c733878bb536fdb027a5bcf1f80c41b0633.pa.png)

ਗਿਟਹੱਬ ਮਾਡਲਜ਼ ਉਪਲਬਧ ਮਾਡਲਜ਼ ਬਾਰੇ ਹੋਰ ਜਾਣਕਾਰੀ ਲਈ, [ਗਿਟਹੱਬ ਮਾਡਲ ਮਾਰਕੀਟਪਲੇਸ](https://github.com/marketplace/models) ਵੇਖੋ।

## ਉਪਲਬਧ ਮਾਡਲ

ਹਰ ਮਾਡਲ ਲਈ ਇੱਕ ਵੱਖਰਾ ਖੇਡ ਮੈਦਾਨ ਅਤੇ ਨਮੂਨਾ ਕੋਡ ਹੈ। 

![Phi-3Model_Github](../../../../imgs/01/02/02/GitHub_ModelPlay.png)

### ਗਿਟਹੱਬ ਮਾਡਲ ਕੈਟਾਲਾਗ ਵਿੱਚ ਫਾਈ-3 ਮਾਡਲ

[Phi-3-Medium-128k-Instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-128k-instruct)

[Phi-3-medium-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-medium-4k-instruct)

[Phi-3-mini-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-128k-instruct)

[Phi-3-mini-4k-instruct](https://github.com/marketplace/models/azureml/Phi-3-mini-4k-instruct)

[Phi-3-small-128k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-128k-instruct)

[Phi-3-small-8k-instruct](https://github.com/marketplace/models/azureml/Phi-3-small-8k-instruct)

## ਸ਼ੁਰੂਆਤ ਕਰਨਾ

ਕੁਝ ਮੁੱਢਲੇ ਉਦਾਹਰਣ ਹਨ ਜੋ ਚਲਾਉਣ ਲਈ ਤਿਆਰ ਹਨ। ਤੁਸੀਂ ਇਨ੍ਹਾਂ ਨੂੰ ਸੈਂਪਲ ਡਾਇਰੈਕਟਰੀ ਵਿੱਚ ਲੱਭ ਸਕਦੇ ਹੋ। ਜੇ ਤੁਸੀਂ ਸਿੱਧੇ ਆਪਣੇ ਮਨਪਸੰਦ ਭਾਸ਼ਾ 'ਤੇ ਜਾਣਾ ਚਾਹੁੰਦੇ ਹੋ, ਤਾਂ ਤੁਸੀਂ ਹੇਠ ਲਿਖੀਆਂ ਭਾਸ਼ਾਵਾਂ ਵਿੱਚ ਉਦਾਹਰਣ ਲੱਭ ਸਕਦੇ ਹੋ:

- Python  
- JavaScript  
- cURL  

ਸੈਂਪਲ ਅਤੇ ਮਾਡਲ ਚਲਾਉਣ ਲਈ ਇੱਕ ਖਾਸ ਕੋਡਸਪੇਸਸ ਵਾਤਾਵਰਣ ਵੀ ਉਪਲਬਧ ਹੈ।  

![Getting Started](../../../../translated_images/GitHub_ModelGetStarted.b4b839a081583da39bc976c2f0d8ac4603d3b8c23194b16cc9e0a1014f5611d0.pa.png)

## ਨਮੂਨਾ ਕੋਡ  

ਹੇਠਾਂ ਕੁਝ ਵਰਤੋਂ ਦੇ ਮਾਮਲਿਆਂ ਲਈ ਉਦਾਹਰਣ ਕੋਡ ਦਿੱਤੇ ਗਏ ਹਨ। ਐਜ਼ਰ ਏਆਈ ਇਨਫਰੈਂਸ SDK ਬਾਰੇ ਹੋਰ ਜਾਣਕਾਰੀ ਲਈ, ਪੂਰੀ ਦਸਤਾਵੇਜ਼ੀ ਅਤੇ ਸੈਂਪਲ ਵੇਖੋ।  

## ਸੈਟਅਪ  

1. ਇੱਕ ਪੈਰਸਨਲ ਐਕਸੈਸ ਟੋਕਨ ਬਣਾਓ  
ਤੁਹਾਨੂੰ ਟੋਕਨ ਨੂੰ ਕੋਈ ਪਰਮਿਸ਼ਨ ਦੇਣ ਦੀ ਲੋੜ ਨਹੀਂ ਹੈ। ਧਿਆਨ ਦਿਓ ਕਿ ਟੋਕਨ ਇੱਕ ਮਾਈਕ੍ਰੋਸਾਫਟ ਸੇਵਾ ਨੂੰ ਭੇਜਿਆ ਜਾਵੇਗਾ।  

ਹੇਠਾਂ ਦਿੱਤੇ ਕੋਡ ਟੁਕੜਿਆਂ ਦੀ ਵਰਤੋਂ ਕਰਨ ਲਈ, ਇੱਕ ਵਾਤਾਵਰਣ ਵੈਰੀਏਬਲ ਬਣਾਓ ਅਤੇ ਆਪਣੇ ਟੋਕਨ ਨੂੰ ਕਲਾਇੰਟ ਕੋਡ ਲਈ ਕੁੰਜੀ ਵਜੋਂ ਸੈੱਟ ਕਰੋ।  

ਜੇ ਤੁਸੀਂ ਬੈਸ਼ ਵਰਤ ਰਹੇ ਹੋ:  
```
export GITHUB_TOKEN="<your-github-token-goes-here>"
```  
ਜੇ ਤੁਸੀਂ ਪਾਵਰਸ਼ੈੱਲ ਵਿੱਚ ਹੋ:  

```
$Env:GITHUB_TOKEN="<your-github-token-goes-here>"
```  

ਜੇ ਤੁਸੀਂ ਵਿੰਡੋਜ਼ ਕਮਾਂਡ ਪ੍ਰਾਂਪਟ ਵਰਤ ਰਹੇ ਹੋ:  

```
set GITHUB_TOKEN=<your-github-token-goes-here>
```  

## ਪਾਇਥਨ ਸੈਂਪਲ  

### ਡਿਪੈਂਡੇੰਸੀਜ਼ ਇੰਸਟਾਲ ਕਰੋ  
pip ਦੀ ਵਰਤੋਂ ਕਰਕੇ Azure AI Inference SDK ਇੰਸਟਾਲ ਕਰੋ (ਲੋੜ ਹੈ: Python >=3.8):  

```
pip install azure-ai-inference
```  

### ਇੱਕ ਬੁਨਿਆਦੀ ਕੋਡ ਸੈਂਪਲ ਚਲਾਓ  

ਇਹ ਸੈਂਪਲ ਚੈਟ ਕਮਪਲੀਸ਼ਨ API ਨੂੰ ਬੁਨਿਆਦੀ ਕਾਲ ਦਿਖਾਉਂਦਾ ਹੈ। ਇਹ ਗਿਟਹੱਬ ਏਆਈ ਮਾਡਲ ਇਨਫਰੈਂਸ ਐਂਡਪੌਇੰਟ ਅਤੇ ਤੁਹਾਡੇ ਗਿਟਹੱਬ ਟੋਕਨ ਦੀ ਵਰਤੋਂ ਕਰ ਰਿਹਾ ਹੈ। ਕਾਲ ਸਿੰਕ੍ਰੋਨਸ ਹੈ।  

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name 
model_name = "Phi-3-small-8k-instruct"
token = os.environ["GITHUB_TOKEN"]

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="What is the capital of France?"),
    ],
    model=model_name,
    temperature=1.,
    max_tokens=1000,
    top_p=1.
)

print(response.choices[0].message.content)
```  

### ਬਹੁ-ਮੋੜ ਗੱਲਬਾਤ ਚਲਾਓ  

ਇਹ ਸੈਂਪਲ ਚੈਟ ਕਮਪਲੀਸ਼ਨ API ਨਾਲ ਇੱਕ ਬਹੁ-ਮੋੜ ਗੱਲਬਾਤ ਦਿਖਾਉਂਦਾ ਹੈ। ਜਦੋਂ ਤੁਸੀਂ ਚੈਟ ਐਪਲੀਕੇਸ਼ਨ ਲਈ ਮਾਡਲ ਦੀ ਵਰਤੋਂ ਕਰਦੇ ਹੋ, ਤਾਂ ਤੁਹਾਨੂੰ ਉਸ ਗੱਲਬਾਤ ਦੇ ਇਤਿਹਾਸ ਨੂੰ ਸੰਭਾਲਣ ਦੀ ਲੋੜ ਹੋਵੇਗੀ ਅਤੇ ਮਾਡਲ ਨੂੰ ਨਵੀਨਤਮ ਸੁਨੇਹੇ ਭੇਜਣ ਦੀ ਲੋੜ ਹੋਵੇਗੀ।  

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-3-small-8k-instruct"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

messages = [
    SystemMessage(content="You are a helpful assistant."),
    UserMessage(content="What is the capital of France?"),
    AssistantMessage(content="The capital of France is Paris."),
    UserMessage(content="What about Spain?"),
]

response = client.complete(messages=messages, model=model_name)

print(response.choices[0].message.content)
```  

### ਆਉਟਪੁਟ ਸਟ੍ਰੀਮ ਕਰੋ  

ਵਧੀਆ ਯੂਜ਼ਰ ਅਨੁਭਵ ਲਈ, ਤੁਸੀਂ ਮਾਡਲ ਦੇ ਜਵਾਬ ਨੂੰ ਸਟ੍ਰੀਮ ਕਰਨਾ ਚਾਹੋਗੇ ਤਾਂ ਜੋ ਪਹਿਲਾ ਟੋਕਨ ਜਲਦੀ ਦਿਖਾਈ ਦੇਵੇ ਅਤੇ ਲੰਬੇ ਜਵਾਬਾਂ ਦੀ ਉਡੀਕ ਕਰਨ ਤੋਂ ਬਚਿਆ ਜਾ ਸਕੇ।  

```
import os
from azure.ai.inference import ChatCompletionsClient
from azure.ai.inference.models import SystemMessage, UserMessage
from azure.core.credentials import AzureKeyCredential

token = os.environ["GITHUB_TOKEN"]
endpoint = "https://models.inference.ai.azure.com"
# Replace Model_Name
model_name = "Phi-3-small-8k-instruct"

client = ChatCompletionsClient(
    endpoint=endpoint,
    credential=AzureKeyCredential(token),
)

response = client.complete(
    stream=True,
    messages=[
        SystemMessage(content="You are a helpful assistant."),
        UserMessage(content="Give me 5 good reasons why I should exercise every day."),
    ],
    model=model_name,
)

for update in response:
    if update.choices:
        print(update.choices[0].delta.content or "", end="")

client.close()
```  

## ਜਾਵਾਸਕ੍ਰਿਪਟ  

### ਡਿਪੈਂਡੇੰਸੀਜ਼ ਇੰਸਟਾਲ ਕਰੋ  

Node.js ਇੰਸਟਾਲ ਕਰੋ।  

ਹੇਠਾਂ ਦਿੱਤੀਆਂ ਲਾਈਨਾਂ ਨੂੰ ਕਾਪੀ ਕਰੋ ਅਤੇ ਆਪਣੇ ਫੋਲਡਰ ਦੇ ਅੰਦਰ ਇੱਕ ਫਾਈਲ package.json ਵਜੋਂ ਸੇਵ ਕਰੋ।  

```
{
  "type": "module",
  "dependencies": {
    "@azure-rest/ai-inference": "latest",
    "@azure/core-auth": "latest",
    "@azure/core-sse": "latest"
  }
}
```  

ਨੋਟ: @azure/core-sse ਸਿਰਫ ਉਸ ਸਮੇਂ ਲੋੜੀਂਦਾ ਹੈ ਜਦੋਂ ਤੁਸੀਂ ਚੈਟ ਕਮਪਲੀਸ਼ਨ ਜਵਾਬ ਸਟ੍ਰੀਮ ਕਰਦੇ ਹੋ।  

ਇਸ ਫੋਲਡਰ ਵਿੱਚ ਇੱਕ ਟਰਮੀਨਲ ਵਿੰਡੋ ਖੋਲ੍ਹੋ ਅਤੇ npm install ਚਲਾਓ।  

ਹੇਠਾਂ ਦਿੱਤੇ ਕੋਡ ਟੁਕੜਿਆਂ ਲਈ, ਸਮੱਗਰੀ ਨੂੰ ਇੱਕ ਫਾਈਲ sample.js ਵਿੱਚ ਕਾਪੀ ਕਰੋ ਅਤੇ node sample.js ਨਾਲ ਚਲਾਓ।  

### ਇੱਕ ਬੁਨਿਆਦੀ ਕੋਡ ਸੈਂਪਲ ਚਲਾਓ  

ਇਹ ਸੈਂਪਲ ਚੈਟ ਕਮਪਲੀਸ਼ਨ API ਨੂੰ ਬੁਨਿਆਦੀ ਕਾਲ ਦਿਖਾਉਂਦਾ ਹੈ। ਇਹ ਗਿਟਹੱਬ ਏਆਈ ਮਾਡਲ ਇਨਫਰੈਂਸ ਐਂਡਪੌਇੰਟ ਅਤੇ ਤੁਹਾਡੇ ਗਿਟਹੱਬ ਟੋਕਨ ਦੀ ਵਰਤੋਂ ਕਰ ਰਿਹਾ ਹੈ। ਕਾਲ ਸਿੰਕ੍ਰੋਨਸ ਹੈ।  

```
import ModelClient from "@azure-rest/ai-inference";
import { AzureKeyCredential } from "@azure/core-auth";

const token = process.env["GITHUB_TOKEN"];
const endpoint = "https://models.inference.ai.azure.com";
// Update your modelname
const modelName = "Phi-3-small-8k-instruct";

export async function main() {

  const client = new ModelClient(endpoint, new AzureKeyCredential(token));

  const response = await client.path("/chat/completions").post({
    body: {
      messages: [
        { role:"system", content: "You are a helpful assistant." },
        { role:"user", content: "What is the capital of France?" }
      ],
      model: modelName,
      temperature: 1.,
      max_tokens: 1000,
      top_p: 1.
    }
  });

  if (response.status !== "200") {
    throw response.body.error;
  }
  console.log(response.body.choices[0].message.content);
}

main().catch((err) => {
  console.error("The sample encountered an error:", err);
});
```  

### ਬਹੁ-ਮੋੜ ਗੱਲਬਾਤ ਚਲਾਓ  

ਇਹ ਸੈਂਪਲ ਚੈਟ ਕਮਪਲੀਸ਼ਨ API ਨਾਲ ਇੱਕ ਬਹੁ-ਮੋੜ ਗੱਲਬਾਤ ਦਿਖਾਉਂਦਾ ਹੈ। ਜਦੋਂ ਤੁਸੀਂ ਚੈਟ ਐਪਲੀਕੇਸ਼ਨ ਲਈ ਮਾਡਲ ਦੀ ਵਰਤੋਂ ਕਰਦੇ ਹੋ, ਤਾਂ ਤੁਹਾਨੂੰ ਉਸ ਗੱਲਬਾਤ ਦੇ ਇਤਿਹਾਸ ਨੂੰ ਸੰਭਾਲਣ ਦੀ ਲੋੜ ਹੋਵੇਗੀ ਅਤੇ ਮਾਡਲ ਨੂੰ ਨਵੀਨਤਮ ਸੁਨੇਹੇ ਭੇਜਣ ਦੀ ਲੋੜ ਹੋਵੇਗੀ।  

```
import ModelClient from "@azure-rest/ai-inference";
import { AzureKeyCredential } from "@azure/core-auth";

const token = process.env["GITHUB_TOKEN"];
const endpoint = "https://models.inference.ai.azure.com";
// Update your modelname
const modelName = "Phi-3-small-8k-instruct";

export async function main() {

  const client = new ModelClient(endpoint, new AzureKeyCredential(token));

  const response = await client.path("/chat/completions").post({
    body: {
      messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: "What is the capital of France?" },
        { role: "assistant", content: "The capital of France is Paris." },
        { role: "user", content: "What about Spain?" },
      ],
      model: modelName,
    }
  });

  if (response.status !== "200") {
    throw response.body.error;
  }

  for (const choice of response.body.choices) {
    console.log(choice.message.content);
  }
}

main().catch((err) => {
  console.error("The sample encountered an error:", err);
});
```  

### ਆਉਟਪੁਟ ਸਟ੍ਰੀਮ ਕਰੋ  
ਵਧੀਆ ਯੂਜ਼ਰ ਅਨੁਭਵ ਲਈ, ਤੁਸੀਂ ਮਾਡਲ ਦੇ ਜਵਾਬ ਨੂੰ ਸਟ੍ਰੀਮ ਕਰਨਾ ਚਾਹੋਗੇ ਤਾਂ ਜੋ ਪਹਿਲਾ ਟੋਕਨ ਜਲਦੀ ਦਿਖਾਈ ਦੇਵੇ ਅਤੇ ਲੰਬੇ ਜਵਾਬਾਂ ਦੀ ਉਡੀਕ ਕਰਨ ਤੋਂ ਬਚਿਆ ਜਾ ਸਕੇ।  

```
import ModelClient from "@azure-rest/ai-inference";
import { AzureKeyCredential } from "@azure/core-auth";
import { createSseStream } from "@azure/core-sse";

const token = process.env["GITHUB_TOKEN"];
const endpoint = "https://models.inference.ai.azure.com";
// Update your modelname
const modelName = "Phi-3-small-8k-instruct";

export async function main() {

  const client = new ModelClient(endpoint, new AzureKeyCredential(token));

  const response = await client.path("/chat/completions").post({
    body: {
      messages: [
        { role: "system", content: "You are a helpful assistant." },
        { role: "user", content: "Give me 5 good reasons why I should exercise every day." },
      ],
      model: modelName,
      stream: true
    }
  }).asNodeStream();

  const stream = response.body;
  if (!stream) {
    throw new Error("The response stream is undefined");
  }

  if (response.status !== "200") {
    stream.destroy();
    throw new Error(`Failed to get chat completions, http operation failed with ${response.status} code`);
  }

  const sseStream = createSseStream(stream);

  for await (const event of sseStream) {
    if (event.data === "[DONE]") {
      return;
    }
    for (const choice of (JSON.parse(event.data)).choices) {
        process.stdout.write(choice.delta?.content ?? ``);
    }
  }
}

main().catch((err) => {
  console.error("The sample encountered an error:", err);
});
```  

## REST  

### ਇੱਕ ਬੁਨਿਆਦੀ ਕੋਡ ਸੈਂਪਲ ਚਲਾਓ  

ਹੇਠਾਂ ਦਿੱਤੇ ਨੂੰ ਇੱਕ ਸ਼ੈੱਲ ਵਿੱਚ ਪੇਸਟ ਕਰੋ:  

```
curl -X POST "https://models.inference.ai.azure.com/chat/completions" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $GITHUB_TOKEN" \
    -d '{
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful assistant."
            },
            {
                "role": "user",
                "content": "What is the capital of France?"
            }
        ],
        "model": "Phi-3-small-8k-instruct"
    }'
```  

### ਬਹੁ-ਮੋੜ ਗੱਲਬਾਤ ਚਲਾਓ  

ਚੈਟ ਕਮਪਲੀਸ਼ਨ API ਨੂੰ ਕਾਲ ਕਰੋ ਅਤੇ ਚੈਟ ਇਤਿਹਾਸ ਪਾਸ ਕਰੋ:  

```
curl -X POST "https://models.inference.ai.azure.com/chat/completions" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $GITHUB_TOKEN" \
    -d '{
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful assistant."
            },
            {
                "role": "user",
                "content": "What is the capital of France?"
            },
            {
                "role": "assistant",
                "content": "The capital of France is Paris."
            },
            {
                "role": "user",
                "content": "What about Spain?"
            }
        ],
        "model": "Phi-3-small-8k-instruct"
    }'
```  

### ਆਉਟਪੁਟ ਸਟ੍ਰੀਮ ਕਰੋ  

ਇਹ ਐਂਡਪੌਇੰਟ ਨੂੰ ਕਾਲ ਕਰਨ ਅਤੇ ਜਵਾਬ ਸਟ੍ਰੀਮ ਕਰਨ ਦਾ ਉਦਾਹਰਣ ਹੈ।  

```
curl -X POST "https://models.inference.ai.azure.com/chat/completions" \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $GITHUB_TOKEN" \
    -d '{
        "messages": [
            {
                "role": "system",
                "content": "You are a helpful assistant."
            },
            {
                "role": "user",
                "content": "Give me 5 good reasons why I should exercise every day."
            }
        ],
        "stream": true,
        "model": "Phi-3-small-8k-instruct"
    }'
```  

## ਮੁਫ਼ਤ ਵਰਤੋਂ ਅਤੇ ਗਿਟਹੱਬ ਮਾਡਲਜ਼ ਲਈ ਦਰਾਂ ਦੀਆਂ ਸੀਮਾਵਾਂ  

![Model Catalog](../../../../translated_images/GitHub_Model.0c2abb992151c5407046e2b763af51505ff709f04c0950785e0300fdc8c55a0c.pa.png)

[ਪਲੇਗਰਾਊਂਡ ਅਤੇ ਮੁਫ਼ਤ API ਵਰਤੋਂ ਲਈ ਦਰਾਂ ਦੀਆਂ ਸੀਮਾਵਾਂ](https://docs.github.com/en/github-models/prototyping-with-ai-models#rate-limits) ਤੁਹਾਨੂੰ ਮਾਡਲਜ਼ ਨਾਲ ਪ੍ਰਯੋਗ ਕਰਨ ਅਤੇ ਆਪਣੀ ਐਆਈ ਐਪਲੀਕੇਸ਼ਨ ਪ੍ਰੋਟੋਟਾਈਪ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰਨ ਲਈ ਤਿਆਰ ਕੀਤੀਆਂ ਗਈਆਂ ਹਨ। ਇਨ੍ਹਾਂ ਸੀਮਾਵਾਂ ਤੋਂ ਬਾਹਰ ਵਰਤੋਂ ਲਈ, ਅਤੇ ਆਪਣੀ ਐਪਲੀਕੇਸ਼ਨ ਨੂੰ ਸਕੇਲ 'ਤੇ ਲਿਆਉਣ ਲਈ, ਤੁਹਾਨੂੰ ਇੱਕ ਐਜ਼ਰ ਖਾਤੇ ਤੋਂ ਸਰੋਤ ਪ੍ਰਦਾਨ ਕਰਨੇ ਹੋਣਗੇ ਅਤੇ ਉੱਥੋਂ ਪ੍ਰਮਾਣਿਕਤਾ ਕਰਨੀ ਪਵੇਗੀ ਬਜਾਏ ਆਪਣੇ ਗਿਟਹੱਬ ਪੈਰਸਨਲ ਐਕਸੈਸ ਟੋਕਨ ਦੇ। ਤੁਹਾਨੂੰ ਆਪਣੇ ਕੋਡ ਵਿੱਚ ਹੋਰ ਕੁਝ ਬਦਲਣ ਦੀ ਲੋੜ ਨਹੀਂ ਹੈ। ਮੁਫ਼ਤ ਟੀਅਰ ਦੀਆਂ ਸੀਮਾਵਾਂ ਤੋਂ ਅੱਗੇ ਜਾਣ ਲਈ, ਇਸ ਲਿੰਕ ਦੀ ਵਰਤੋਂ ਕਰੋ ਅਤੇ ਐਜ਼ਰ ਏਆਈ ਵਿੱਚ ਹੋਰ ਪਤਾ ਲਗਾਓ।  

### ਖੁਲਾਸੇ  

ਯਾਦ ਰੱਖੋ ਜਦੋਂ ਤੁਸੀਂ ਮਾਡਲ ਨਾਲ ਗੱਲਬਾਤ ਕਰ ਰਹੇ ਹੋ ਤਾਂ ਤੁਸੀਂ ਐਆਈ ਨਾਲ ਪ੍ਰਯੋਗ ਕਰ ਰਹੇ ਹੋ, ਇਸ ਲਈ ਸਮੱਗਰੀ ਵਿੱਚ ਗਲਤੀਆਂ ਹੋ ਸਕਦੀਆਂ ਹਨ।  

ਫੀਚਰ ਵੱਖ-ਵੱਖ ਸੀਮਾਵਾਂ (ਜਿਵੇਂ ਕਿ ਮਿੰਟ ਵਿੱਚ ਕਾਲਾਂ, ਦਿਨ ਵਿੱਚ ਕਾਲਾਂ, ਪ੍ਰਤੀ ਕਾਲ ਟੋਕਨ, ਅਤੇ ਸਮਕਾਲੀ ਕਾਲਾਂ) ਦੇ ਅਧੀਨ ਹੈ ਅਤੇ ਇਹ ਉਤਪਾਦਨ ਦੇਸਾਂ ਲਈ ਤਿਆਰ ਨਹੀਂ ਹੈ।  

ਗਿਟਹੱਬ ਮਾਡਲਜ਼ ਐਜ਼ਰ ਏਆਈ ਕੰਟੈਂਟ ਸੇਫ਼ਟੀ ਦੀ ਵਰਤੋਂ ਕਰਦਾ ਹੈ। ਗਿਟਹੱਬ ਮਾਡਲਜ਼ ਅਨੁਭਵ ਦੇ ਹਿੱਸੇ ਵਜੋਂ ਇਹ ਫਿਲਟਰ ਬੰਦ ਨਹੀਂ ਕੀਤੇ ਜਾ ਸਕਦੇ। ਜੇ ਤੁਸੀਂ ਸੇਵਾ ਦੀ ਭੁਗਤਾਨ ਕੀਤੀ ਵਰਤੋਂ ਦੀ ਚੋਣ ਕਰਦੇ ਹੋ, ਤਾਂ ਕਿਰਪਾ ਕਰਕੇ ਆਪਣੇ ਕੰਟੈਂਟ ਫਿਲਟਰਾਂ ਨੂੰ ਆਪਣੇ ਲੋੜਾਂ ਅਨੁਸਾਰ ਸੰਰਚਿਤ ਕਰੋ।  

ਇਹ ਸੇਵਾ ਗਿਟਹੱਬ ਦੇ ਪ੍ਰੀ-ਰਿਲੀਜ਼ ਸ਼ਰਤਾਂ ਦੇ ਅਧੀਨ ਹੈ।  

**ਅਸਵੀਕਰਤੀ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ ਮਸ਼ੀਨ-ਅਧਾਰਿਤ AI ਅਨੁਵਾਦ ਸੇਵਾਵਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀ ਹੋਣ ਦਾ ਯਤਨ ਕਰਦੇ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚੱਜੇ ਪਾਸੇ ਹੋ ਸਕਦੇ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਅਧਿਕਾਰਕ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਅਸੀਂ ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੀਆਂ ਕਿਸੇ ਵੀ ਗਲਤਫਹਮੀਆਂ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆਵਾਂ ਲਈ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।