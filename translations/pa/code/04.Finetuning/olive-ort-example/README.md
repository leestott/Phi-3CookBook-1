# Olive ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®®‡®æ‡®≤ Phi3 ‡®®‡©Ç‡©∞ Fine-tune ‡®ï‡®∞‡©ã

‡®á‡®∏ ‡®â‡®¶‡®æ‡®π‡®∞‡®£ ‡®µ‡®ø‡©±‡®ö ‡®§‡©Å‡®∏‡©Ä‡®Ç Olive ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®¶‡©á ‡®π‡©ã:

1. ‡®á‡©±‡®ï LoRA ‡®Ö‡®°‡®æ‡®™‡®ü‡®∞ ‡®®‡©Ç‡©∞ Fine-tune ‡®ï‡®∞‡®® ‡®≤‡®à, ‡®ú‡©ã ‡®µ‡®æ‡®ï‡®æ‡®Ç ‡®®‡©Ç‡©∞ Sad, Joy, Fear, Surprise ‡®µ‡®ø‡©±‡®ö ‡®µ‡®∞‡®ó‡®¨‡©±‡®ß ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§
1. ‡®Ö‡®°‡®æ‡®™‡®ü‡®∞ ‡®¶‡©á ‡®≠‡®æ‡®∞‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©Ç‡®≤ ‡®Æ‡®æ‡®°‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®Æ‡®ø‡®≤‡®æ‡®ì‡•§
1. ‡®Æ‡®æ‡®°‡®≤ ‡®®‡©Ç‡©∞ `int4` ‡®µ‡®ø‡©±‡®ö Optimize ‡®Ö‡®§‡©á Quantize ‡®ï‡®∞‡©ã‡•§

‡®Ö‡®∏‡©Ä‡®Ç ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®á‡®π ‡®µ‡©Ä ‡®¶‡®ø‡®ñ‡®æ‡®µ‡®æ‡®Ç‡®ó‡©á ‡®ï‡®ø ONNX Runtime (ORT) Generate API ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á Fine-tuned ‡®Æ‡®æ‡®°‡®≤ ‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®µ‡©á‡®Ç inference ‡®ï‡®∞‡®®‡®æ ‡®π‡©à‡•§

> **‚ö†Ô∏è Fine-tuning ‡®≤‡®à, ‡®§‡©Å‡®π‡®æ‡®°‡©á ‡®ï‡©ã‡®≤ ‡®á‡©±‡®ï ‡®â‡®ö‡®ø‡®§ GPU ‡®â‡®™‡®≤‡®¨‡®ß ‡®π‡©ã‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à - ‡®â‡®¶‡®æ‡®π‡®∞‡®£ ‡®≤‡®à, A10, V100, A100‡•§**

## üíæ ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã

‡®®‡®µ‡®æ‡®Ç Python ‡®µ‡®∞‡®ö‡©Å‡®Ö‡®≤ ‡®á‡®®‡®µ‡®æ‡®á‡®∞‡®®‡®Æ‡©à‡®Ç‡®ü ‡®¨‡®£‡®æ‡®ì (‡®â‡®¶‡®æ‡®π‡®∞‡®£ ‡®≤‡®à, `conda` ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

‡®´‡®ø‡®∞, Olive ‡®Ö‡®§‡©á Fine-tuning workflow ‡®≤‡®à dependencies ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Olive ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®®‡®æ‡®≤ Phi3 ‡®®‡©Ç‡©∞ Fine-tune ‡®ï‡®∞‡©ã
[Olive configuration file](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) ‡®µ‡®ø‡©±‡®ö ‡®á‡©±‡®ï *workflow* ‡®π‡©à ‡®ú‡®ø‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®π‡©á‡®†‡®≤‡©á *passes* ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®π‡®®:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

‡®á‡®∏ workflow ‡®¶‡®æ ‡®â‡©±‡®ö-‡®™‡©±‡®ß‡®∞‡©Ä ‡®µ‡©á‡®∞‡®µ‡®æ:

1. Phi3 ‡®®‡©Ç‡©∞ Fine-tune ‡®ï‡®∞‡©ã (150 steps ‡®≤‡®à, ‡®ú‡®ø‡®®‡©ç‡®π‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®¨‡®¶‡®≤ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã) [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json) ‡®°‡®æ‡®ü‡®æ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á‡•§
1. LoRA ‡®Ö‡®°‡®æ‡®™‡®ü‡®∞ ‡®¶‡©á ‡®≠‡®æ‡®∞‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®Æ‡©Ç‡®≤ ‡®Æ‡®æ‡®°‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®Æ‡®ø‡®≤‡®æ‡®ì‡•§ ‡®á‡®∏ ‡®®‡®æ‡®≤ ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ONNX ‡®´‡®æ‡®∞‡®Æ‡©à‡®ü ‡®µ‡®ø‡©±‡®ö ‡®á‡©±‡®ï ‡®∏‡®ø‡©∞‡®ó‡®≤ ‡®Æ‡®æ‡®°‡®≤ artifact ‡®Æ‡®ø‡®≤‡©á‡®ó‡®æ‡•§
1. Model Builder ‡®Æ‡®æ‡®°‡®≤ ‡®®‡©Ç‡©∞ ONNX runtime ‡®≤‡®à Optimize ‡®Ö‡®§‡©á `int4` ‡®µ‡®ø‡©±‡®ö Quantize ‡®ï‡®∞‡©á‡®ó‡®æ‡•§

workflow ‡®ö‡®≤‡®æ‡®â‡®£ ‡®≤‡®à, ‡®á‡®π ‡®ö‡®≤‡®æ‡®ì:

```bash
olive run --config phrase-classification.json
```

‡®ú‡®¶‡©ã‡®Ç Olive ‡®Æ‡©Å‡®ï‡©∞‡®Æ‡®≤ ‡®π‡©ã ‡®ú‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à, ‡®§‡®æ‡®Ç ‡®§‡©Å‡®π‡®æ‡®°‡®æ optimized `int4` Fine-tuned Phi3 ‡®Æ‡®æ‡®°‡®≤ ‡®á‡®∏ ‡®•‡®æ‡®Ç ‡®â‡®™‡®≤‡®¨‡®ß ‡®π‡©Å‡©∞‡®¶‡®æ ‡®π‡©à: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`‡•§

## üßë‚Äçüíª Fine-tuned Phi3 ‡®®‡©Ç‡©∞ ‡®Ü‡®™‡®£‡©á ‡®ê‡®™‡®≤‡©Ä‡®ï‡©á‡®∏‡®º‡®® ‡®µ‡®ø‡©±‡®ö ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®ï‡®∞‡©ã

‡®ê‡®™ ‡®ö‡®≤‡®æ‡®â‡®£ ‡®≤‡®à:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

‡®á‡®∏ ‡®¶‡®æ ‡®ú‡®µ‡®æ‡®¨ ‡®µ‡®æ‡®ï ‡®¶‡®æ ‡®∏‡®ø‡®∞‡®´ ‡®á‡©±‡®ï ‡®∏‡®º‡®¨‡®¶ ‡®µ‡®ø‡©±‡®ö ‡®µ‡®∞‡®ó‡®¨‡©±‡®ß ‡®π‡©ã‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à (Sad/Joy/Fear/Surprise)‡•§

**‡®Ö‡®∏‡®µ‡©Ä‡®ï‡®æ‡®∞‡®®‡®æ**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®Æ‡®∏‡®º‡©Ä‡®®-‡®Ö‡®ß‡®æ‡®∞‡®ø‡®§ AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ‡®µ‡®æ‡®Ç ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®ú‡®¶‡©ã‡®Ç ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä ‡®π‡©ã‡®£ ‡®¶‡®æ ‡®Ø‡®§‡®® ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡®ì ‡®ï‡®ø ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ø‡®§ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Å‡®ö‡©±‡®ú‡©á ‡®π‡©ã‡®£ ‡®¶‡©Ä ‡®∏‡©∞‡®≠‡®æ‡®µ‡®®‡®æ ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä ‡®π‡©à‡•§ ‡®Æ‡©Ç‡®≤ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º ‡®®‡©Ç‡©∞ ‡®á‡®∏ ‡®¶‡©Ä ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®ï ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®ø‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®§‡©ã‡®Ç ‡®™‡©à‡®¶‡®æ ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©Ä‡®Ü‡®Ç ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§ ‡®´‡®π‡®ø‡®Æ‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®ó‡®≤‡®§ ‡®µ‡®ø‡®Ü‡®ñ‡®ø‡®Ü‡®µ‡®æ‡®Ç ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§