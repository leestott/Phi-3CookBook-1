في سياق Phi-3-mini، يشير الاستدلال إلى عملية استخدام النموذج لتقديم توقعات أو إنتاج مخرجات بناءً على بيانات الإدخال. دعني أوضح لك المزيد من التفاصيل حول Phi-3-mini وقدراته في الاستدلال.

Phi-3-mini هو جزء من سلسلة نماذج Phi-3 التي أصدرتها Microsoft. تم تصميم هذه النماذج لإعادة تعريف الإمكانيات مع النماذج اللغوية الصغيرة (SLMs).

إليك بعض النقاط الرئيسية حول Phi-3-mini وقدراته في الاستدلال:

## **نظرة عامة على Phi-3-mini:**
- يحتوي Phi-3-mini على حجم معلمات يبلغ 3.8 مليار.
- يمكن تشغيله ليس فقط على الأجهزة الحاسوبية التقليدية، بل أيضًا على الأجهزة الطرفية مثل الأجهزة المحمولة وأجهزة إنترنت الأشياء.
- يتيح إصدار Phi-3-mini للأفراد والمؤسسات نشر النماذج اللغوية الصغيرة على أجهزة مختلفة، خاصة في البيئات ذات الموارد المحدودة.
- يدعم تنسيقات نماذج متعددة، بما في ذلك تنسيق PyTorch التقليدي، والإصدار الكمّي من تنسيق gguf، والإصدار الكمّي المستند إلى ONNX.

## **الوصول إلى Phi-3-mini:**
للوصول إلى Phi-3-mini، يمكنك استخدام [Semantic Kernel](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) في تطبيق Copilot. يتوافق Semantic Kernel بشكل عام مع خدمة Azure OpenAI، والنماذج مفتوحة المصدر على Hugging Face، والنماذج المحلية.  
يمكنك أيضًا استخدام [Ollama](https://ollama.com) أو [LlamaEdge](https://llamaedge.com) لاستدعاء النماذج الكمّية. يتيح Ollama للمستخدمين الأفراد استدعاء نماذج كمّية مختلفة، بينما يوفر LlamaEdge توفرًا عبر المنصات لنماذج GGUF.

## **النماذج الكمّية:**
يفضل العديد من المستخدمين استخدام النماذج الكمّية للاستدلال المحلي. على سبيل المثال، يمكنك تشغيل Ollama مباشرة لتشغيل Phi-3 أو تكوينه دون اتصال باستخدام Modelfile. يحدد Modelfile مسار ملف GGUF وصيغة التنبيه.

## **إمكانات الذكاء الاصطناعي التوليدي:**
يتيح الجمع بين النماذج اللغوية الصغيرة مثل Phi-3-mini إمكانيات جديدة للذكاء الاصطناعي التوليدي. الاستدلال هو مجرد الخطوة الأولى؛ يمكن استخدام هذه النماذج لمهام متعددة في سيناريوهات مقيدة بالموارد أو الكلفة أو زمن الاستجابة.

## **إطلاق العنان للذكاء الاصطناعي التوليدي باستخدام Phi-3-mini: دليل للاستدلال والنشر**  
تعرف على كيفية استخدام Semantic Kernel، Ollama/LlamaEdge، وONNX Runtime للوصول إلى نماذج Phi-3-mini والاستدلال بها، واستكشف إمكانيات الذكاء الاصطناعي التوليدي في سيناريوهات تطبيق متنوعة.

**الميزات**  
الاستدلال باستخدام نموذج phi3-mini في:

- [Semantic Kernel](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo)  
- [Ollama](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)  
- [LlamaEdge WASM](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo)  
- [ONNX Runtime](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/onnx?WT.mc_id=aiml-138114-kinfeylo)  
- [iOS](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ios?WT.mc_id=aiml-138114-kinfeylo)  

باختصار، يتيح Phi-3-mini للمطورين استكشاف تنسيقات نماذج مختلفة والاستفادة من الذكاء الاصطناعي التوليدي في سيناريوهات تطبيق متنوعة.

**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمات الترجمة الآلية بالذكاء الاصطناعي. بينما نسعى لتحقيق الدقة، يُرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للحصول على معلومات حاسمة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.