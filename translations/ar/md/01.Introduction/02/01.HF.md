# **استخدام عائلة Phi في Hugging Face**

[Hugging Face](https://huggingface.co/) هي مجتمع ذكاء اصطناعي شهير يحتوي على بيانات غنية وموارد نماذج مفتوحة المصدر. تقوم شركات مختلفة بإصدار نماذج LLM وSLM مفتوحة المصدر عبر Hugging Face، مثل Microsoft، Meta، Mistral، Apple، Google، وغيرها.

تم إصدار عائلة Microsoft Phi على Hugging Face. يمكن للمطورين تحميل نموذج عائلة Phi المناسب بناءً على السيناريوهات والاحتياجات. بالإضافة إلى نشر نماذج Phi Pytorch على Hugging Face، قمنا أيضًا بإصدار نماذج مكممة باستخدام تنسيقات GGUF وONNX لتوفير خيارات للمستخدمين النهائيين.

## **تحميل النماذج من Hugging Face**

يمكنك تحميل نموذج عائلة Phi باستخدام هذا الرابط:

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

يمكنك تحميل النموذج بطرق مختلفة، مثل تثبيت ***Hugging Face CLI SDK*** أو استخدام ***git clone***.

### **استخدام Hugging Face CLI لتحميل نموذج عائلة Phi**

- تثبيت Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- تسجيل الدخول باستخدام huggingface-cli

قم بتسجيل الدخول إلى Hugging Face باستخدام [User Access Token](https://huggingface.co/docs/hub/security-tokens) من [صفحة الإعدادات](https://huggingface.co/settings/tokens).

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- التحميل 

يمكنك تحميل النموذج وحفظه في ذاكرة التخزين المؤقت

```bash

huggingface-cli download microsoft/phi-4

```

يمكنك تحديد موقع الحفظ في مكان مخصص

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **استخدام git clone لتحميل نموذج عائلة Phi**

يمكنك أيضًا استخدام ***git clone*** لتحميل النموذج

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **أمثلة - استنتاج Microsoft Phi-4**

- **تثبيت مكتبة transformers**

```bash

pip install transformers -U

```

- **تشغيل هذا الكود في VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمات الترجمة الآلية بالذكاء الاصطناعي. بينما نسعى لتحقيق الدقة، يُرجى العلم بأن الترجمات الآلية قد تحتوي على أخطاء أو معلومات غير دقيقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للحصول على معلومات حساسة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.