# Affiner Phi3 avec Olive

Dans cet exemple, vous utiliserez Olive pour :

1. Affiner un adaptateur LoRA pour classifier des phrases en Tristesse, Joie, Peur, Surprise.
1. Fusionner les poids de l'adaptateur avec le mod√®le de base.
1. Optimiser et quantifier le mod√®le dans `int4`.

Nous vous montrerons √©galement comment effectuer une inf√©rence avec le mod√®le affin√© en utilisant l'API Generate d'ONNX Runtime (ORT).

> **‚ö†Ô∏è Pour l'affinement, vous aurez besoin d'un GPU adapt√© - par exemple, un A10, V100, A100.**

## üíæ Installation

Cr√©ez un nouvel environnement virtuel Python (par exemple, en utilisant `conda`)¬†:

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ensuite, installez Olive et les d√©pendances n√©cessaires pour un flux de travail d'affinement¬†:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Affiner Phi3 avec Olive
Le [fichier de configuration Olive](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) contient un *flux de travail* avec les *√©tapes* suivantes¬†:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

√Ä un niveau √©lev√©, ce flux de travail effectuera¬†:

1. L'affinement de Phi3 (pour 150 √©tapes, que vous pouvez modifier) en utilisant les donn√©es du fichier [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).
1. La fusion des poids de l'adaptateur LoRA avec le mod√®le de base. Cela produira un seul artefact de mod√®le au format ONNX.
1. Le Model Builder optimisera le mod√®le pour ONNX Runtime *et* quantifiera le mod√®le dans `int4`.

Pour ex√©cuter le flux de travail, lancez¬†:

```bash
olive run --config phrase-classification.json
```

Une fois Olive termin√©, votre mod√®le Phi3 affin√© et optimis√© dans `int4` sera disponible ici : `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Int√©grer le mod√®le Phi3 affin√© dans votre application 

Pour ex√©cuter l'application¬†:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Cette r√©ponse devrait √™tre une classification en un mot de la phrase (Tristesse/Joie/Peur/Surprise).

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'intelligence artificielle. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle effectu√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es d√©coulant de l'utilisation de cette traduction.