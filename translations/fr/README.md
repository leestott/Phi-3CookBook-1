# Phi Cookbook : Exemples pratiques avec les mod√®les Phi de Microsoft

[![Ouvrir et utiliser les exemples dans GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phicookbook)  
[![Ouvrir dans Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phicookbook)

[![Contributeurs GitHub](https://img.shields.io/github/contributors/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/graphs/contributors/?WT.mc_id=aiml-137032-kinfeylo)  
[![Probl√®mes GitHub](https://img.shields.io/github/issues/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/issues/?WT.mc_id=aiml-137032-kinfeylo)  
[![Demandes de tirage GitHub](https://img.shields.io/github/issues-pr/microsoft/phicookbook.svg)](https://GitHub.com/microsoft/phicookbook/pulls/?WT.mc_id=aiml-137032-kinfeylo)  
[![PRs Bienvenues](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat-square)](http://makeapullrequest.com?WT.mc_id=aiml-137032-kinfeylo)

[![Observateurs GitHub](https://img.shields.io/github/watchers/microsoft/phicookbook.svg?style=social&label=Watch)](https://GitHub.com/microsoft/phicookbook/watchers/?WT.mc_id=aiml-137032-kinfeylo)  
[![Forks GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)  
[![√âtoiles GitHub](https://img.shields.io/github/stars/microsoft/phicookbook?style=social&label=Star)](https://GitHub.com/microsoft/phicookbook/stargazers/?WT.mc_id=aiml-137032-kinfeylo)

[![Communaut√© Discord Azure AI](https://dcbadge.vercel.app/api/server/ByRwuEEgH4)](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

Phi est une s√©rie de mod√®les d'IA open source d√©velopp√©e par Microsoft.

Phi est actuellement le mod√®le de langage compact (SLM) le plus puissant et le plus √©conomique, avec d'excellents r√©sultats dans des domaines tels que les langues multiples, le raisonnement, la g√©n√©ration de texte/chat, le codage, les images, l'audio et bien d'autres sc√©narios.

Vous pouvez d√©ployer Phi dans le cloud ou sur des appareils p√©riph√©riques, et cr√©er facilement des applications d'IA g√©n√©rative avec des ressources informatiques limit√©es.

Suivez ces √©tapes pour commencer √† utiliser ces ressources :
1. **Forkez le d√©p√¥t** : Cliquez [![Forks GitHub](https://img.shields.io/github/forks/microsoft/phicookbook.svg?style=social&label=Fork)](https://GitHub.com/microsoft/phicookbook/network/?WT.mc_id=aiml-137032-kinfeylo)  
2. **Clonez le d√©p√¥t** :   `git clone https://github.com/microsoft/PhiCookBook.git`  
3. [**Rejoignez la communaut√© Discord Microsoft AI et √©changez avec des experts et d'autres d√©veloppeurs**](https://discord.com/invite/ByRwuEEgH4?WT.mc_id=aiml-137032-kinfeylo)

![cover](../../translated_images/cover.2595d43b382944c601aebf88583314636768eece3d94e8e4448e03a4e5bedef4.fr.png)

## Table des mati√®res

- Introduction  
  - [Bienvenue dans la famille Phi](./md/01.Introduction/01/01.PhiFamily.md)  
  - [Configuration de votre environnement](./md/01.Introduction/01/01.EnvironmentSetup.md)  
  - [Comprendre les technologies cl√©s](./md/01.Introduction/01/01.Understandingtech.md)  
  - [S√©curit√© de l'IA pour les mod√®les Phi](./md/01.Introduction/01/01.AISafety.md)  
  - [Support mat√©riel pour Phi](./md/01.Introduction/01/01.Hardwaresupport.md)  
  - [Mod√®les Phi et disponibilit√© sur diff√©rentes plateformes](./md/01.Introduction/01/01.Edgeandcloud.md)  
  - [Utilisation de Guidance-ai et Phi](./md/01.Introduction/01/01.Guidance.md)  
  - [Mod√®les sur GitHub Marketplace](https://github.com/marketplace/models)  
  - [Catalogue de mod√®les Azure AI](https://ai.azure.com)  

- Inf√©rence de Phi dans diff√©rents environnements  
    - [Hugging Face](./md/01.Introduction/02/01.HF.md)  
    - [Mod√®les GitHub](./md/01.Introduction/02/02.GitHubModel.md)  
    - [Catalogue de mod√®les Azure AI Foundry](./md/01.Introduction/02/03.AzureAIFoundry.md)  
    - [Ollama](./md/01.Introduction/02/04.Ollama.md)  
    - [AI Toolkit VSCode (AITK)](./md/01.Introduction/02/05.AITK.md)  
    - [NVIDIA NIM](./md/01.Introduction/02/06.NVIDIA.md)  

- Inf√©rence de la famille Phi  
    - [Inf√©rence Phi sur iOS](./md/01.Introduction/03/iOS_Inference.md)  
    - [Inf√©rence Phi sur Android](./md/01.Introduction/03/Android_Inference.md)  
- [Inf√©rence Phi sur Jetson](./md/01.Introduction/03/Jetson_Inference.md)
    - [Inf√©rence Phi sur un PC AI](./md/01.Introduction/03/AIPC_Inference.md)
    - [Inf√©rence Phi avec le framework Apple MLX](./md/01.Introduction/03/MLX_Inference.md)
    - [Inf√©rence Phi sur un serveur local](./md/01.Introduction/03/Local_Server_Inference.md)
    - [Inf√©rence Phi sur un serveur distant avec l'outil AI Toolkit](./md/01.Introduction/03/Remote_Interence.md)
    - [Inf√©rence Phi avec Rust](./md/01.Introduction/03/Rust_Inference.md)
    - [Inf√©rence Phi--Vision en local](./md/01.Introduction/03/Vision_Inference.md)
    - [Inf√©rence Phi avec Kaito AKS, conteneurs Azure (support officiel)](./md/01.Introduction/03/Kaito_Inference.md)
- [Quantification de la famille Phi](./md/01.Introduction/04/QuantifyingPhi.md)
    - [Quantification de Phi-3.5 / 4 avec llama.cpp](./md/01.Introduction/04/UsingLlamacppQuantifyingPhi.md)
    - [Quantification de Phi-3.5 / 4 avec des extensions d'IA g√©n√©rative pour onnxruntime](./md/01.Introduction/04/UsingORTGenAIQuantifyingPhi.md)
    - [Quantification de Phi-3.5 / 4 avec Intel OpenVINO](./md/01.Introduction/04/UsingIntelOpenVINOQuantifyingPhi.md)
    - [Quantification de Phi-3.5 / 4 avec le framework Apple MLX](./md/01.Introduction/04/UsingAppleMLXQuantifyingPhi.md)

- √âvaluation de Phi
    - [IA Responsable](./md/01.Introduction/05/ResponsibleAI.md)
    - [Azure AI Foundry pour l'√©valuation](./md/01.Introduction/05/AIFoundry.md)
    - [Utilisation de Promptflow pour l'√©valuation](./md/01.Introduction/05/Promptflow.md)

- RAG avec Azure AI Search
    - [Comment utiliser Phi-4-mini et Phi-4-multimodal (RAG) avec Azure AI Search](https://github.com/microsoft/PhiCookBook/blob/main/code/06.E2E/E2E_Phi-4-RAG-Azure-AI-Search.ipynb)

- Exemples de d√©veloppement d'applications Phi
  - Applications Textuelles et de Chat
    - Exemples Phi-4 üÜï
      - [üìì] [Chat avec le mod√®le ONNX Phi-4-mini](./md/02.Application/01.TextAndChat/Phi4/ChatWithPhi4ONNX/README.md)
      - [Chat avec le mod√®le ONNX Phi-4 local en .NET](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-01OnnxRuntime)
      - [Application console .NET de chat avec Phi-4 ONNX en utilisant Semantic Kernel](../../md/04.HOL/dotnet/src/LabsPhi4-Chat-02SK)
    - Exemples Phi-3 / 3.5
      - [Chatbot local dans le navigateur avec Phi3, ONNX Runtime Web et WebGPU](https://github.com/microsoft/onnxruntime-inference-examples/tree/main/js/chat)
      - [Chat OpenVINO](./md/02.Application/01.TextAndChat/Phi3/E2E_OpenVino_Chat.md)
      - [Mod√®le multi-usage - Interaction entre Phi-3-mini et OpenAI Whisper](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-mini_with_whisper.md)
      - [MLFlow - Cr√©ation d'un wrapper et utilisation de Phi-3 avec MLFlow](./md//02.Application/01.TextAndChat/Phi3/E2E_Phi-3-MLflow.md)
      - [Optimisation du mod√®le - Comment optimiser le mod√®le Phi-3-min pour ONNX Runtime Web avec Olive](https://github.com/microsoft/Olive/tree/main/examples/phi3)
      - [Application WinUI3 avec Phi-3 mini-4k-instruct-onnx](https://github.com/microsoft/Phi3-Chat-WinUI3-Sample/)
      - [Exemple d'application de notes aliment√©e par l'IA avec WinUI3 et plusieurs mod√®les](https://github.com/microsoft/ai-powered-notes-winui3-sample)
      - [Ajuster et int√©grer des mod√®les personnalis√©s Phi-3 avec Prompt flow](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration.md)
      - [Ajuster et int√©grer des mod√®les personnalis√©s Phi-3 avec Prompt flow dans Azure AI Foundry](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-FineTuning_PromptFlow_Integration_AIFoundry.md)
      - [√âvaluer le mod√®le Phi-3 / Phi-3.5 ajust√© dans Azure AI Foundry en mettant l'accent sur les principes d'IA Responsable de Microsoft](./md/02.Application/01.TextAndChat/Phi3/E2E_Phi-3-Evaluation_AIFoundry.md)
- [üìì] [Exemple de pr√©diction linguistique Phi-3.5-mini-instruct (Chinois/Anglais)](../../md/02.Application/01.TextAndChat/Phi3/phi3-instruct-demo.ipynb)  
      - [Chatbot RAG WebGPU avec Phi-3.5-Instruct](./md/02.Application/01.TextAndChat/Phi3/WebGPUWithPhi35Readme.md)  
      - [Utilisation du GPU Windows pour cr√©er une solution Prompt Flow avec Phi-3.5-Instruct ONNX](./md/02.Application/01.TextAndChat/Phi3/UsingPromptFlowWithONNX.md)  
      - [Utilisation de Microsoft Phi-3.5 tflite pour cr√©er une application Android](./md/02.Application/01.TextAndChat/Phi3/UsingPhi35TFLiteCreateAndroidApp.md)  
      - [Exemple de Q&R .NET utilisant le mod√®le local ONNX Phi-3 avec Microsoft.ML.OnnxRuntime](../../md/04.HOL/dotnet/src/LabsPhi301)  
      - [Application console .NET pour le chat avec Semantic Kernel et Phi-3](../../md/04.HOL/dotnet/src/LabsPhi302)  

  - Exemples de code SDK Azure AI Inference  
    - Exemples Phi-4 üÜï  
      - [üìì] [G√©n√©rer du code de projet avec Phi-4-multimodal](./md/02.Application/02.Code/Phi4/GenProjectCode/README.md)  
    - Exemples Phi-3 / 3.5  
      - [Cr√©er votre propre Copilot Chat Visual Studio Code avec Microsoft Phi-3 Family](./md/02.Application/02.Code/Phi3/VSCodeExt/README.md)  
      - [Cr√©er votre propre agent Copilot Chat Visual Studio Code avec Phi-3.5 via les mod√®les GitHub](/md/02.Application/02.Code/Phi3/CreateVSCodeChatAgentWithGitHubModels.md)  

  - Exemples de raisonnement avanc√©  
    - Exemples Phi-4 üÜï  
      - [üìì] [Exemples de raisonnement Phi-4-mini](./md/02.Application/03.AdvancedReasoning/Phi4/AdvancedResoningPhi4mini/README.md)  

  - D√©mos  
      - [D√©mos Phi-4-mini h√©berg√©es sur Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-mini?WT.mc_id=aiml-137032-kinfeylo)  
      - [D√©mos Phi-4-multimodal h√©berg√©es sur Hugging Face Spaces](https://huggingface.co/spaces/microsoft/phi-4-multimodal?WT.mc_id=aiml-137032-kinfeylo)  

  - Exemples de vision  
    - Exemples Phi-4 üÜï  
      - [üìì] [Utiliser Phi-4-multimodal pour lire des images et g√©n√©rer du code](./md/02.Application/04.Vision/Phi4/CreateFrontend/README.md)  
    - Exemples Phi-3 / 3.5  
      - [üìì][Phi-3-vision - Texte d'image √† texte](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)  
      - [Phi-3-vision-ONNX](https://onnxruntime.ai/docs/genai/tutorials/phi3-v.html)  
      - [üìì][Phi-3-vision - Int√©gration CLIP](../../md/02.Application/04.Vision/Phi3/E2E_Phi-3-vision-image-text-to-text-online-endpoint.ipynb)  
      - [DEMO : Phi-3 Recycling](https://github.com/jennifermarsman/PhiRecycling/)  
      - [Phi-3-vision - Assistant visuel linguistique - avec Phi3-Vision et OpenVINO](https://docs.openvino.ai/nightly/notebooks/phi-3-vision-with-output.html)  
      - [Phi-3 Vision Nvidia NIM](./md/02.Application/04.Vision/Phi3/E2E_Nvidia_NIM_Vision.md)  
      - [Phi-3 Vision OpenVino](./md/02.Application/04.Vision/Phi3/E2E_OpenVino_Phi3Vision.md)  
      - [üìì][Exemple multi-image ou multi-cadre Phi-3.5 Vision](../../md/02.Application/04.Vision/Phi3/phi3-vision-demo.ipynb)  
      - [Mod√®le local ONNX Phi-3 Vision utilisant Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi303)  
      - [Mod√®le local ONNX Phi-3 Vision bas√© sur un menu utilisant Microsoft.ML.OnnxRuntime .NET](../../md/04.HOL/dotnet/src/LabsPhi304)  

  - Exemples audio  
    - Exemples Phi-4 üÜï  
      - [üìì] [Extraction de transcriptions audio avec Phi-4-multimodal](./md/02.Application/05.Audio/Phi4/Transciption/README.md)  
      - [üìì] [Exemple audio Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Siri/demo.ipynb)  
      - [üìì] [Exemple de traduction vocale Phi-4-multimodal](../../md/02.Application/05.Audio/Phi4/Translate/demo.ipynb)  
      - [Application console .NET utilisant Phi-4-multimodal Audio pour analyser un fichier audio et g√©n√©rer une transcription](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-02Audio)  

  - Exemples MOE  
    - Exemples Phi-3 / 3.5  
      - [üìì] [Exemple de mod√®les Mixture of Experts (MoEs) Phi-3.5 pour les r√©seaux sociaux](../../md/02.Application/06.MoE/Phi3/phi3_moe_demo.ipynb)  
      - [üìì] [Construire un pipeline de g√©n√©ration augment√©e par r√©cup√©ration (RAG) avec NVIDIA NIM Phi-3 MOE, Azure AI Search et LlamaIndex](../../md/02.Application/06.MoE/Phi3/azure-ai-search-nvidia-rag.ipynb)  

  - Exemples d'appel de fonctions  
    - Exemples Phi-4 üÜï  
      - [üìì] [Utilisation des appels de fonctions avec Phi-4-mini](./md/02.Application/07.FunctionCalling/Phi4/FunctionCallingBasic/README.md)  

  - Exemples de m√©lange multimodal  
    - Exemples Phi-4 üÜï  
-  [üìì] [Utiliser Phi-4-multimodal en tant que journaliste technologique](../../md/02.Application/08.Multimodel/Phi4/TechJournalist/phi_4_mm_audio_text_publish_news.ipynb)
      - [Application console .NET utilisant Phi-4-multimodal pour analyser des images](../../md/04.HOL/dotnet/src/LabsPhi4-MultiModal-01Images)

- Affiner les √©chantillons Phi
  - [Sc√©narios d'affinage](./md/03.FineTuning/FineTuning_Scenarios.md)
  - [Affinage vs RAG](./md/03.FineTuning/FineTuning_vs_RAG.md)
  - [Affinage : Faire de Phi-3 un expert industriel](./md/03.FineTuning/LetPhi3gotoIndustriy.md)
  - [Affiner Phi-3 avec AI Toolkit pour VS Code](./md/03.FineTuning/Finetuning_VSCodeaitoolkit.md)
  - [Affiner Phi-3 avec Azure Machine Learning Service](./md/03.FineTuning/Introduce_AzureML.md)
  - [Affiner Phi-3 avec Lora](./md/03.FineTuning/FineTuning_Lora.md)
  - [Affiner Phi-3 avec QLora](./md/03.FineTuning/FineTuning_Qlora.md)
  - [Affiner Phi-3 avec Azure AI Foundry](./md/03.FineTuning/FineTuning_AIFoundry.md)
  - [Affiner Phi-3 avec Azure ML CLI/SDK](./md/03.FineTuning/FineTuning_MLSDK.md)
  - [Affiner avec Microsoft Olive](./md/03.FineTuning/FineTuning_MicrosoftOlive.md)
  - [Affiner avec le laboratoire pratique de Microsoft Olive](./md/03.FineTuning/olive-lab/readme.md)
  - [Affiner Phi-3-vision avec Weights and Bias](./md/03.FineTuning/FineTuning_Phi-3-visionWandB.md)
  - [Affiner Phi-3 avec le framework Apple MLX](./md/03.FineTuning/FineTuning_MLX.md)
  - [Affiner Phi-3-vision (support officiel)](./md/03.FineTuning/FineTuning_Vision.md)
  - [Affiner Phi-3 avec Kaito AKS, Azure Containers (support officiel)](./md/03.FineTuning/FineTuning_Kaito.md)
  - [Affiner Phi-3 et 3.5 Vision](https://github.com/2U1/Phi3-Vision-Finetune)

- Laboratoire pratique
  - [Explorer les mod√®les de pointe : LLMs, SLMs, d√©veloppement local et plus](https://github.com/microsoft/aitour-exploring-cutting-edge-models)
  - [Lib√©rer le potentiel NLP : Affinage avec Microsoft Olive](https://github.com/azure/Ignite_FineTuning_workshop)

- Articles de recherche acad√©mique et publications
  - [Les manuels sont tout ce dont vous avez besoin II : rapport technique phi-1.5](https://arxiv.org/abs/2309.05463)
  - [Rapport technique Phi-3 : Un mod√®le de langage tr√®s performant localement sur votre t√©l√©phone](https://arxiv.org/abs/2404.14219)
  - [Rapport technique Phi-4](https://arxiv.org/abs/2412.08905)
  - [Optimisation des petits mod√®les de langage pour l'appel de fonctions embarqu√©es](https://arxiv.org/abs/2501.02342)
  - [(WhyPHI) Affiner PHI-3 pour r√©pondre √† des questions √† choix multiples : m√©thodologie, r√©sultats et d√©fis](https://arxiv.org/abs/2501.01588)

## Utiliser les mod√®les Phi

### Phi sur Azure AI Foundry

Vous pouvez apprendre √† utiliser Microsoft Phi et √† construire des solutions de bout en bout sur diff√©rents dispositifs mat√©riels. Pour d√©couvrir Phi par vous-m√™me, commencez par tester les mod√®les et personnaliser Phi pour vos sc√©narios √† l'aide du‚ÄØ[Catalogue de mod√®les Azure AI Foundry](https://aka.ms/phi3-azure-ai). Vous pouvez en apprendre davantage dans la section D√©marrage rapide avec [Azure AI Foundry](/md/02.QuickStart/AzureAIFoundry_QuickStart.md).

**Playground**  
Chaque mod√®le dispose d'un espace d√©di√© pour tester le mod√®le [Azure AI Playground](https://aka.ms/try-phi3).

### Phi sur les mod√®les GitHub

Vous pouvez apprendre √† utiliser Microsoft Phi et √† construire des solutions de bout en bout sur diff√©rents dispositifs mat√©riels. Pour d√©couvrir Phi par vous-m√™me, commencez par tester le mod√®le et personnaliser Phi pour vos sc√©narios √† l'aide du‚ÄØ[Catalogue de mod√®les GitHub](https://github.com/marketplace/models?WT.mc_id=aiml-137032-kinfeylo). Vous pouvez en apprendre davantage dans la section D√©marrage rapide avec [Catalogue de mod√®les GitHub](/md/02.QuickStart/GitHubModel_QuickStart.md).

**Playground**
Chaque mod√®le dispose d‚Äôun [espace de test d√©di√© pour exp√©rimenter le mod√®le](/md/02.QuickStart/GitHubModel_QuickStart.md).

### Phi sur Hugging Face

Vous pouvez √©galement trouver le mod√®le sur [Hugging Face](https://huggingface.co/microsoft)

**Espace de test**  
 [Espace de test Hugging Chat](https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct)

## IA Responsable 

Microsoft s‚Äôengage √† aider ses clients √† utiliser ses produits d‚ÄôIA de mani√®re responsable, √† partager ses apprentissages et √† construire des partenariats bas√©s sur la confiance gr√¢ce √† des outils tels que les Notes de Transparence et les √âvaluations d‚ÄôImpact. Bon nombre de ces ressources sont disponibles √† l‚Äôadresse [https://aka.ms/RAI](https://aka.ms/RAI).  
L‚Äôapproche de Microsoft en mati√®re d‚ÄôIA responsable repose sur nos principes d‚Äô√©quit√©, de fiabilit√© et de s√©curit√©, de confidentialit√© et de protection, d‚Äôinclusivit√©, de transparence et de responsabilit√©.

Les mod√®les √† grande √©chelle de langage naturel, d‚Äôimage et de voix - comme ceux utilis√©s dans cet exemple - peuvent potentiellement se comporter de mani√®re injuste, peu fiable ou offensante, ce qui peut entra√Æner des pr√©judices. Veuillez consulter la [Note de Transparence du service Azure OpenAI](https://learn.microsoft.com/legal/cognitive-services/openai/transparency-note?tabs=text) pour √™tre inform√© des risques et limitations.

L‚Äôapproche recommand√©e pour att√©nuer ces risques consiste √† inclure un syst√®me de s√©curit√© dans votre architecture, capable de d√©tecter et pr√©venir les comportements nuisibles. [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview) offre une couche de protection ind√©pendante, capable de d√©tecter du contenu nuisible g√©n√©r√© par les utilisateurs ou par l‚ÄôIA dans les applications et services. Azure AI Content Safety inclut des API pour le texte et les images qui permettent de d√©tecter du contenu pr√©judiciable. Dans Azure AI Foundry, le service Content Safety vous permet de visualiser, explorer et tester des exemples de code pour d√©tecter du contenu nuisible dans diff√©rents formats. La [documentation de d√©marrage rapide](https://learn.microsoft.com/azure/ai-services/content-safety/quickstart-text?tabs=visual-studio%2Clinux&pivots=programming-language-rest) vous guide dans l‚Äôenvoi de requ√™tes √† ce service.

Un autre aspect √† consid√©rer est la performance globale de l‚Äôapplication. Pour les applications multi-modales et multi-mod√®les, la performance signifie que le syst√®me fonctionne comme vous et vos utilisateurs l‚Äôattendez, y compris en √©vitant de g√©n√©rer des r√©sultats nuisibles. Il est important d‚Äô√©valuer la performance globale de votre application en utilisant les [√©valuateurs de Performance et Qualit√© et de Risques et S√©curit√©](https://learn.microsoft.com/azure/ai-studio/concepts/evaluation-metrics-built-in). Vous avez √©galement la possibilit√© de cr√©er et d‚Äô√©valuer avec des [√©valuateurs personnalis√©s](https://learn.microsoft.com/azure/ai-studio/how-to/develop/evaluate-sdk#custom-evaluators).

Vous pouvez √©valuer votre application d‚ÄôIA dans votre environnement de d√©veloppement en utilisant le [SDK d‚Äô√âvaluation Azure AI](https://microsoft.github.io/promptflow/index.html). √Ä partir d‚Äôun jeu de donn√©es de test ou d‚Äôun objectif, les r√©sultats g√©n√©r√©s par votre application d‚ÄôIA g√©n√©rative sont mesur√©s quantitativement avec des √©valuateurs int√©gr√©s ou personnalis√©s selon votre choix. Pour commencer avec le SDK d‚Äô√©valuation Azure AI et √©valuer votre syst√®me, vous pouvez suivre le [guide de d√©marrage rapide](https://learn.microsoft.com/azure/ai-studio/how-to/develop/flow-evaluate-sdk). Une fois une √©valuation effectu√©e, vous pouvez [visualiser les r√©sultats dans Azure AI Foundry](https://learn.microsoft.com/azure/ai-studio/how-to/evaluate-flow-results). 

## Marques

Ce projet peut contenir des marques ou des logos pour des projets, produits ou services. L‚Äôutilisation autoris√©e des marques ou logos de Microsoft est soumise et doit respecter les [Directives de Marque et d‚ÄôUsage de Microsoft](https://www.microsoft.com/legal/intellectualproperty/trademarks/usage/general).  
L‚Äôutilisation des marques ou logos de Microsoft dans des versions modifi√©es de ce projet ne doit pas pr√™ter √† confusion ou laisser entendre un parrainage de la part de Microsoft. Toute utilisation de marques ou logos tiers est soumise aux politiques de ces tiers.

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatis√©e bas√©s sur l'intelligence artificielle. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.