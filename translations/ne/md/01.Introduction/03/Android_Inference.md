# **एन्ड्रोइडमा Phi-3 को इन्फरेन्स**

एन्ड्रोइड उपकरणहरूमा Phi-3-mini को इन्फरेन्स कसरी गर्न सकिन्छ भनेर हेरौँ। Phi-3-mini माइक्रोसफ्टको नयाँ मोडेल श्रृंखला हो, जसले ठूलो भाषा मोडेलहरू (LLMs) लाई एज डिभाइसहरू र IoT डिभाइसहरूमा डिप्लोय गर्न सक्षम बनाउँछ।

## सेमान्टिक कर्नेल र इन्फरेन्स

[सेमान्टिक कर्नेल](https://github.com/microsoft/semantic-kernel) एउटा एप्लिकेसन फ्रेमवर्क हो, जसले Azure OpenAI Service, OpenAI मोडेलहरू, र स्थानीय मोडेलहरूसँग मिल्ने एप्लिकेसनहरू बनाउन सहयोग पुर्‍याउँछ। यदि तपाईं सेमान्टिक कर्नेलका लागि नयाँ हुनुहुन्छ भने, [सेमान्टिक कर्नेल कुकबुक](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) हेर्न सिफारिस गरिन्छ।

### सेमान्टिक कर्नेल प्रयोग गरेर Phi-3-mini पहुँच गर्न

यसलाई सेमान्टिक कर्नेलमा रहेको Hugging Face Connector सँग मिलाउन सकिन्छ। यो [नमूना कोड](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo) हेर्नुहोस्।

डिफल्ट रूपमा, यो Hugging Face मा रहेको मोडेल ID सँग मेल खान्छ। तर, तपाईंले स्थानीय रूपमा बनाइएको Phi-3-mini मोडेल सर्भरसँग पनि जडान गर्न सक्नुहुन्छ।

### Ollama वा LlamaEdge प्रयोग गरेर क्वान्टाइज्ड मोडेलहरू चलाउने

धेरै प्रयोगकर्ताहरूले मोडेलहरूलाई स्थानीय रूपमा चलाउन क्वान्टाइज्ड मोडेलहरू प्रयोग गर्न रुचाउँछन्। [Ollama](https://ollama.com/) र [LlamaEdge](https://llamaedge.com) ले व्यक्तिगत प्रयोगकर्ताहरूलाई विभिन्न क्वान्टाइज्ड मोडेलहरू प्रयोग गर्न अनुमति दिन्छ:

#### Ollama

तपाईंले `ollama run Phi-3` सिधै चलाउन सक्नुहुन्छ वा आफ्नो `.gguf` फाइलको पथ सहित `Modelfile` बनाएर यसलाई अफलाइन कन्फिगर गर्न सक्नुहुन्छ।

```gguf
FROM {Add your gguf file path}
TEMPLATE \"\"\"<|user|> .Prompt<|end|> <|assistant|>\"\"\"
PARAMETER stop <|end|>
PARAMETER num_ctx 4096
```

[नमूना कोड](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)

#### LlamaEdge

यदि तपाईंले क्लाउड र एज डिभाइसहरूमा एकै समयमा `.gguf` फाइलहरू प्रयोग गर्न चाहनुहुन्छ भने, LlamaEdge उत्कृष्ट विकल्प हो। सुरु गर्नका लागि यो [नमूना कोड](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo) हेर्न सक्नुहुन्छ।

### एन्ड्रोइड फोनहरूमा इन्स्टल र चलाउने

1. **MLC Chat एप डाउनलोड गर्नुहोस्** (निःशुल्क) एन्ड्रोइड फोनहरूको लागि।
2. APK फाइल (148MB) डाउनलोड गरी आफ्नो उपकरणमा इन्स्टल गर्नुहोस्।
3. MLC Chat एप खोल्नुहोस्। तपाईंले Phi-3-mini सहितका AI मोडेलहरूको सूची देख्नुहुनेछ।

संक्षेपमा, Phi-3-mini ले एज डिभाइसहरूमा जेनेरेटिभ AI का लागि रोमाञ्चक सम्भावनाहरू खोल्छ, र तपाईं एन्ड्रोइडमा यसको क्षमताहरू अन्वेषण गर्न सुरु गर्न सक्नुहुन्छ।

**अस्वीकरण**:  
यो दस्तावेज मेसिन-आधारित एआई अनुवाद सेवाहरू प्रयोग गरेर अनुवाद गरिएको हो। हामी शुद्धताका लागि प्रयास गर्छौं, तर कृपया जानकारी रहनुहोस् कि स्वचालित अनुवादहरूमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छ। मूल भाषामा रहेको मूल दस्तावेजलाई आधिकारिक स्रोत मानिनुपर्छ। महत्वपूर्ण जानकारीका लागि, व्यावसायिक मानव अनुवादको सिफारिस गरिन्छ। यो अनुवाद प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार हुने छैनौं।  