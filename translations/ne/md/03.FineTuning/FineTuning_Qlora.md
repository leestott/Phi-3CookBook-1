**Phi-3 लाई QLoRA प्रयोग गरी फाइन-ट्युनिंग**

Microsoft को Phi-3 Mini भाषा मोडेललाई [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora) प्रयोग गरी फाइन-ट्युन गर्ने प्रक्रिया।

QLoRA ले संवादात्मक बुझाइ र प्रतिक्रिया उत्पादनमा सुधार गर्न सहयोग पुर्‍याउनेछ।

4 बिट्समा transformers र bitsandbytes प्रयोग गरी मोडेल लोड गर्न, तपाईंले accelerate र transformers लाई स्रोतबाट इन्स्टल गर्नुपर्नेछ र bitsandbytes लाइब्रेरीको सबैभन्दा नयाँ संस्करण सुनिश्चित गर्नुपर्नेछ।

**नमूनाहरू**
- [यो नमूना नोटबुकबाट थप जान्नुहोस्](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python FineTuning को नमूना उदाहरण](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Hugging Face Hub को LORA प्रयोग गरी फाइन ट्युनिंगको उदाहरण](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Hugging Face Hub को QLORA प्रयोग गरी फाइन ट्युनिंगको उदाहरण](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**अस्वीकरण**:  
यो दस्तावेज मेसिन-आधारित एआई अनुवाद सेवाहरू प्रयोग गरी अनुवाद गरिएको छ। हामी शुद्धताको लागि प्रयास गर्छौं तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादहरूमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छ। यसको मूल भाषामा रहेको मूल दस्तावेजलाई आधिकारिक स्रोत मानिनुपर्छ। महत्त्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याको लागि हामी जिम्मेवार हुने छैनौं।