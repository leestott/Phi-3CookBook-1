**การปรับแต่ง Phi-3 ด้วย QLoRA**

การปรับแต่งโมเดลภาษา Phi-3 Mini ของ Microsoft โดยใช้ [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora)

QLoRA จะช่วยเพิ่มความเข้าใจในบทสนทนาและการสร้างคำตอบที่ดีขึ้น

ในการโหลดโมเดลในรูปแบบ 4bits ด้วย transformers และ bitsandbytes คุณจำเป็นต้องติดตั้ง accelerate และ transformers จาก source และตรวจสอบให้แน่ใจว่าคุณมีเวอร์ชันล่าสุดของไลบรารี bitsandbytes

**ตัวอย่าง**
- [เรียนรู้เพิ่มเติมด้วยโน้ตบุ๊กตัวอย่างนี้](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [ตัวอย่างการปรับแต่งด้วย Python](../../../../code/03.Finetuning/FineTrainingScript.py)
- [ตัวอย่างการปรับแต่งโมเดลใน Hugging Face Hub ด้วย LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [ตัวอย่างการปรับแต่งโมเดลใน Hugging Face Hub ด้วย QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษาอัตโนมัติด้วย AI แม้ว่าเราจะพยายามอย่างเต็มที่เพื่อให้ได้ความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่แม่นยำ เอกสารต้นฉบับในภาษาต้นทางควรถูกพิจารณาเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลภาษามนุษย์ที่เป็นมืออาชีพ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่คลาดเคลื่อนซึ่งเกิดจากการใช้การแปลนี้