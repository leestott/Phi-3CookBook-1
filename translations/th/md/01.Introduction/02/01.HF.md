# **การใช้งาน Phi Family ใน Hugging Face**

[Hugging Face](https://huggingface.co/) เป็นชุมชน AI ที่ได้รับความนิยมสูง มีข้อมูลและทรัพยากรโมเดลแบบโอเพนซอร์สมากมาย ผู้ผลิตหลายราย เช่น Microsoft, Meta, Mistral, Apple, Google ฯลฯ ได้เผยแพร่ LLM และ SLM แบบโอเพนซอร์สผ่าน Hugging Face

Microsoft ได้เปิดตัว Phi Family บน Hugging Face นักพัฒนาสามารถดาวน์โหลดโมเดลของ Phi Family ตามความเหมาะสมของสถานการณ์และธุรกิจ นอกเหนือจากการปรับใช้โมเดล Phi Pytorch บน Hugging Face แล้ว เรายังได้เผยแพร่โมเดลที่ผ่านการบีบอัดข้อมูลในรูปแบบ GGUF และ ONNX เพื่อให้ผู้ใช้งานปลายทางมีตัวเลือกเพิ่มเติม

## **การดาวน์โหลดโมเดลใน Hugging Face**

คุณสามารถดาวน์โหลดโมเดลของ Phi Family ได้จากลิงก์นี้

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

คุณสามารถดาวน์โหลดโมเดลได้หลากหลายวิธี เช่น การติดตั้ง ***Hugging face CLI SDK*** หรือการใช้ ***git clone***

### **การใช้ Hugging Face CLI เพื่อดาวน์โหลดโมเดล Phi Family**

- ติดตั้ง Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- ใช้ huggingface-cli เพื่อเข้าสู่ระบบ

เข้าสู่ระบบ Hugging Face ด้วย [User Access Token](https://huggingface.co/docs/hub/security-tokens) จาก [หน้าการตั้งค่า](https://huggingface.co/settings/tokens)

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- ดาวน์โหลด

คุณสามารถดาวน์โหลดโมเดลและบันทึกไว้ในแคช

```bash

huggingface-cli download microsoft/phi-4

```

หรือกำหนดตำแหน่งที่จัดเก็บในตำแหน่งพิเศษของคุณ

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **การใช้ git clone เพื่อดาวน์โหลดโมเดล Phi Family**

คุณสามารถใช้ ***git clone*** เพื่อดาวน์โหลดโมเดลได้เช่นกัน

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **ตัวอย่าง - การใช้งาน Microsoft Phi-4 สำหรับการ Inference**

- **ติดตั้งไลบรารี transformers**

```bash

pip install transformers -U

```

- **รันโค้ดนี้ใน VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษาอัตโนมัติด้วย AI แม้ว่าเราจะพยายามอย่างเต็มที่เพื่อความถูกต้อง แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาต้นทางควรถูกพิจารณาเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลสำคัญ ขอแนะนำให้ใช้บริการแปลภาษาจากผู้เชี่ยวชาญที่เป็นมนุษย์ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่ผิดพลาดซึ่งเกิดจากการใช้การแปลนี้