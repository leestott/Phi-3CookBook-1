# 開始在本地使用 Phi-3

本指南將幫助您設置本地環境，以使用 Ollama 運行 Phi-3 模型。您可以通過多種方式運行該模型，包括使用 GitHub Codespaces、VS Code Dev Containers 或本地環境。

## 環境設置

### GitHub Codespaces

您可以使用 GitHub Codespaces 虛擬運行此範本。點擊按鈕即可在瀏覽器中打開基於網頁的 VS Code 實例：

1. 打開範本（這可能需要幾分鐘時間）：

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. 打開終端窗口

### VS Code Dev Containers

⚠️ 此選項僅在您的 Docker Desktop 分配了至少 16 GB RAM 的情況下可用。如果您的 RAM 少於 16 GB，您可以嘗試 [GitHub Codespaces 選項](../../../../../md/01.Introduction/01) 或 [本地設置](../../../../../md/01.Introduction/01)。

另一個相關選項是 VS Code Dev Containers，它將使用 [Dev Containers 擴展](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) 在本地 VS Code 中打開項目：

1. 啟動 Docker Desktop（如果尚未安裝，請先安裝）
2. 打開項目：

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. 在打開的 VS Code 窗口中，當項目文件顯示出來後（這可能需要幾分鐘時間），打開終端窗口。
4. 繼續進行 [部署步驟](../../../../../md/01.Introduction/01)

### 本地環境

1. 確保已安裝以下工具：

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## 測試模型

1. 使用 Ollama 下載並運行 phi3:mini 模型：

    ```shell
    ollama run phi3:mini
    ```

    這將需要幾分鐘來下載模型。

2. 當輸出中顯示 "success" 時，您可以從提示中向該模型發送消息。

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. 幾秒鐘後，您應該會看到模型回傳的響應流。

4. 如需了解語言模型中使用的不同技術，請打開 Python notebook [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) 並運行每個單元格。如果您使用了 'phi3:mini' 以外的模型，請根據需要更改文件頂部的 `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME`，您還可以修改系統消息或添加 few-shot 示例（如果需要）。

**免責聲明**：  
本文件已使用基於機器的人工智慧翻譯服務進行翻譯。儘管我們致力於確保準確性，但請注意，自動翻譯可能包含錯誤或不準確之處。原文檔的母語版本應被視為權威來源。對於關鍵資訊，建議尋求專業人工翻譯。我們對因使用此翻譯而產生的任何誤解或誤讀不承擔責任。