# Počnite s Phi-3 lokalno

Ovaj vodič pomoći će vam da postavite svoje lokalno okruženje za pokretanje modela Phi-3 koristeći Ollama. Model možete pokrenuti na nekoliko različitih načina, uključujući GitHub Codespaces, VS Code Dev Containers ili vaše lokalno okruženje.

## Postavljanje okruženja

### GitHub Codespaces

Možete pokrenuti ovaj predložak virtualno koristeći GitHub Codespaces. Gumb će otvoriti web-verziju VS Code-a u vašem pregledniku:

1. Otvorite predložak (ovo može potrajati nekoliko minuta):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Otvorite terminal prozor

### VS Code Dev Containers

⚠️ Ova opcija će raditi samo ako je vašem Docker Desktopu dodijeljeno najmanje 16 GB RAM-a. Ako imate manje od 16 GB RAM-a, možete isprobati [GitHub Codespaces opciju](../../../../../md/01.Introduction/01) ili [postaviti lokalno](../../../../../md/01.Introduction/01).

Srodna opcija je VS Code Dev Containers, koja će otvoriti projekt u vašem lokalnom VS Code-u koristeći [Dev Containers ekstenziju](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Pokrenite Docker Desktop (instalirajte ga ako već nije instaliran)
2. Otvorite projekt:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. U prozoru VS Code-a koji se otvori, nakon što se prikažu datoteke projekta (ovo može potrajati nekoliko minuta), otvorite terminal prozor.
4. Nastavite s [koracima za implementaciju](../../../../../md/01.Introduction/01)

### Lokalno okruženje

1. Provjerite jesu li instalirani sljedeći alati:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testiranje modela

1. Zatražite od Ollame da preuzme i pokrene model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Ovo će potrajati nekoliko minuta dok se model ne preuzme.

2. Kada u izlazu vidite "success", možete poslati poruku tom modelu iz prompta.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Nakon nekoliko sekundi trebali biste vidjeti odgovor koji model generira.

4. Za više informacija o različitim tehnikama koje se koriste s jezičnim modelima, otvorite Python bilježnicu [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) i pokrenite svaku ćeliju. Ako ste koristili model koji nije 'phi3:mini', promijenite `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` na vrhu datoteke prema potrebi, a također možete prilagoditi sistemsku poruku ili dodati primjere za few-shot učenje ako želite.

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koristeći usluge strojno baziranog AI prevođenja. Iako nastojimo postići točnost, molimo vas da budete svjesni da automatizirani prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na njegovom izvornom jeziku treba smatrati autoritativnim izvorom. Za ključne informacije preporučuje se profesionalni prijevod od strane čovjeka. Ne snosimo odgovornost za bilo kakve nesporazume ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.