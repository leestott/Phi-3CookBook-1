# Phi3 finomhangol√°sa Olive seg√≠ts√©g√©vel

Ebben a p√©ld√°ban az Olive seg√≠ts√©g√©vel:

1. Finomhangolsz egy LoRA adaptert, hogy kifejez√©seket oszt√°lyozz Sad, Joy, Fear, Surprise kateg√≥ri√°kba.
2. Egyes√≠ted az adapter s√∫lyait az alapmodellbe.
3. Optimaliz√°lod √©s kvant√°lod a modellt `int4` form√°tumba.

Megmutatjuk azt is, hogyan v√©gezhetsz k√∂vetkeztet√©st (inference) a finomhangolt modellen az ONNX Runtime (ORT) Generate API haszn√°lat√°val.

> **‚ö†Ô∏è A finomhangol√°shoz megfelel≈ë GPU-ra lesz sz√ºks√©ged - p√©ld√°ul A10, V100, A100.**

## üíæ Telep√≠t√©s

Hozz l√©tre egy √∫j Python virtu√°lis k√∂rnyezetet (p√©ld√°ul `conda` haszn√°lat√°val):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Ezut√°n telep√≠tsd az Olive-ot √©s a finomhangol√°si munkafolyamathoz sz√ºks√©ges f√ºgg≈ës√©geket:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Phi3 finomhangol√°sa Olive seg√≠ts√©g√©vel
Az [Olive konfigur√°ci√≥s f√°jl](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) egy *munkafolyamatot* tartalmaz a k√∂vetkez≈ë *l√©p√©sekkel*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

Magas szinten ez a munkafolyamat a k√∂vetkez≈ëket hajtja v√©gre:

1. Finomhangolja a Phi3 modellt (150 l√©p√©sben, amelyet m√≥dos√≠thatsz) a [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json) adatainak felhaszn√°l√°s√°val.
2. Egyes√≠ti a LoRA adapter s√∫lyait az alapmodellbe. Ez√°ltal egyetlen ONNX form√°tum√∫ modellarifaktot kapsz.
3. A Model Builder optimaliz√°lja a modellt az ONNX runtime sz√°m√°ra *√©s* kvant√°lja a modellt `int4` form√°tumba.

A munkafolyamat futtat√°s√°hoz haszn√°ld a k√∂vetkez≈ë parancsot:

```bash
olive run --config phrase-classification.json
```

Amikor az Olive befejezte, az optimaliz√°lt `int4` finomhangolt Phi3 modell el√©rhet≈ë lesz itt: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª A finomhangolt Phi3 integr√°l√°sa az alkalmaz√°sodba 

Az alkalmaz√°s futtat√°s√°hoz:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

A v√°lasz egyetlen szavas oszt√°lyoz√°s lesz a kifejez√©sre (Sad/Joy/Fear/Surprise).

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum g√©pi AI ford√≠t√°si szolg√°ltat√°sokkal k√©sz√ºlt ford√≠t√°s. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis, emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.