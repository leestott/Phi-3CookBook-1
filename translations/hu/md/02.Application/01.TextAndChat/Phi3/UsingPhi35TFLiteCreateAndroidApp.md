# **Microsoft Phi-3.5 tflite haszn√°lata Android alkalmaz√°s l√©trehoz√°s√°hoz**

Ez egy Android p√©lda, amely Microsoft Phi-3.5 tflite modelleket haszn√°l.

## **üìö Tudnival√≥k**

Az Android LLM Inference API lehet≈ëv√© teszi, hogy nagy nyelvi modelleket (LLM-eket) futtassunk teljes m√©rt√©kben eszk√∂z√∂n bel√ºl Android alkalmaz√°sokhoz. Ez√°ltal sz√°mos feladatot v√©gezhet√ºnk el, p√©ld√°ul sz√∂veg gener√°l√°s√°t, inform√°ci√≥k term√©szetes nyelvi form√°ban t√∂rt√©n≈ë lek√©rdez√©s√©t √©s dokumentumok √∂sszegz√©s√©t. Az API be√©p√≠tett t√°mogat√°st ny√∫jt t√∂bb sz√∂veg-sz√∂veg t√≠pus√∫ nagy nyelvi modellhez, √≠gy a leg√∫jabb generat√≠v mesters√©ges intelligencia modelleket alkalmazhatjuk Android alkalmaz√°sainkban.

A Google AI Edge Torch egy Python k√∂nyvt√°r, amely t√°mogatja a PyTorch modellek .tflite form√°tumba val√≥ konvert√°l√°s√°t, amelyeket ezut√°n TensorFlow Lite-tal √©s MediaPipe-pal futtathatunk. Ez lehet≈ëv√© teszi, hogy Android, iOS √©s IoT alkalmaz√°sok teljesen eszk√∂z√∂n bel√ºl futtathass√°k a modelleket. Az AI Edge Torch sz√©les k√∂r≈± CPU t√°mogat√°st k√≠n√°l, kezdeti GPU √©s NPU t√°mogat√°ssal. Az AI Edge Torch szorosan integr√°l√≥dik a PyTorch-sal, a torch.export() funkci√≥ra √©p√≠tve, √©s j√≥ lefedetts√©get biztos√≠t a Core ATen oper√°torok sz√°m√°ra.

## **ü™¨ √ötmutat√≥**

### **üî• Microsoft Phi-3.5 tflite t√°mogat√°ss√° alak√≠t√°sa**

0. Ez a minta Android 14+ verzi√≥hoz k√©sz√ºlt.

1. Telep√≠tsd a Python 3.10.12 verzi√≥t.

***Javaslat:*** Haszn√°lj conda-t a Python k√∂rnyezeted telep√≠t√©s√©hez.

2. Ubuntu 20.04 / 22.04 (k√©rlek, koncentr√°lj a [google ai-edge-torch](https://github.com/google-ai-edge/ai-edge-torch) projektre).

***Javaslat:*** Haszn√°lj Azure Linux VM-et vagy harmadik f√©l √°ltal biztos√≠tott felh≈ë VM-et a k√∂rnyezeted l√©trehoz√°s√°hoz.

3. L√©pj be a Linux bash-be, √©s telep√≠tsd a Python k√∂nyvt√°rakat:

```bash

git clone https://github.com/google-ai-edge/ai-edge-torch.git

cd ai-edge-torch

pip install -r requirements.txt -U 

pip install tensorflow-cpu -U

pip install -e .

```

4. T√∂ltsd le a Microsoft-3.5-Instruct modellt a Hugging Face-r≈ël:

```bash

git lfs install

git clone  https://huggingface.co/microsoft/Phi-3.5-mini-instruct

```

5. Alak√≠tsd √°t a Microsoft Phi-3.5 modellt tflite form√°tumba:

```bash

python ai-edge-torch/ai_edge_torch/generative/examples/phi/convert_phi3_to_tflite.py --checkpoint_path  Your Microsoft Phi-3.5-mini-instruct path --tflite_path Your Microsoft Phi-3.5-mini-instruct tflite path  --prefill_seq_len 1024 --kv_cache_max_len 1280 --quantize True

```

### **üî• Microsoft Phi-3.5 √°talak√≠t√°sa Android Mediapipe csomagg√°**

El≈ësz√∂r telep√≠tsd a MediaPipe-ot:

```bash

pip install mediapipe

```

Futtasd ezt a k√≥dot a [jegyzetf√ºzetedben](../../../../../../code/09.UpdateSamples/Aug/Android/convert/convert_phi.ipynb):

```python

import mediapipe as mp
from mediapipe.tasks.python.genai import bundler

config = bundler.BundleConfig(
    tflite_model='Your Phi-3.5 tflite model path',
    tokenizer_model='Your Phi-3.5 tokenizer model path',
    start_token='start_token',
    stop_tokens=[STOP_TOKENS],
    output_filename='Your Phi-3.5 task model path',
    enable_bytes_to_unicode_mapping=True or Flase,
)
bundler.create_bundle(config)

```

### **üî• A modell √°tm√°sol√°sa adb push seg√≠ts√©g√©vel az Android eszk√∂z√∂d el√©r√©si √∫tj√°ra**

```bash

adb shell rm -r /data/local/tmp/llm/ # Remove any previously loaded models

adb shell mkdir -p /data/local/tmp/llm/

adb push 'Your Phi-3.5 task model path' /data/local/tmp/llm/phi3.task

```

### **üî• Az Android k√≥d futtat√°sa**

![demo](../../../../../../translated_images/demo.8981711efb5a9cee5dcd835f66b3b31b94b4f3e527300e15a98a0d48863b9fbd.hu.png)

**Felel≈ëss√©gkiz√°r√°s**:  
Ez a dokumentum g√©pi AI ford√≠t√°si szolg√°ltat√°sok seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekinthet≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n javasoljuk a professzion√°lis, emberi ford√≠t√°st. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.