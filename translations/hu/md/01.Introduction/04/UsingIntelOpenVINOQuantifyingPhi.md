# **Phi-3.5 kvant√°l√°sa Intel OpenVINO-val**

Az Intel az egyik legtradicion√°lisabb CPU-gy√°rt√≥, amelynek rengeteg felhaszn√°l√≥ja van. A g√©pi tanul√°s √©s m√©lytanul√°s t√©rnyer√©s√©vel az Intel is csatlakozott az AI-gyors√≠t√°s√©rt folytatott versenyhez. Modellinferencia sor√°n az Intel nemcsak GPU-kat √©s CPU-kat, hanem NPU-kat is haszn√°l.

C√©lunk, hogy a Phi-3.x csal√°dot az eszk√∂zoldalon telep√≠ts√ºk, √©s ezzel az AI PC-k √©s Copilot PC-k legfontosabb r√©sz√©v√© v√°ljunk. Az eszk√∂zoldalon t√∂rt√©n≈ë modellbet√∂lt√©s a k√ºl√∂nb√∂z≈ë hardvergy√°rt√≥k egy√ºttm≈±k√∂d√©s√©n m√∫lik. Ez a fejezet f≈ëk√©nt az Intel OpenVINO mint kvantitat√≠v modell alkalmaz√°si forgat√≥k√∂nyv√©re √∂sszpontos√≠t.

## **Mi az az OpenVINO?**

Az OpenVINO egy ny√≠lt forr√°sk√≥d√∫ eszk√∂zk√©szlet, amely a m√©lytanul√°si modellek optimaliz√°l√°s√°ra √©s telep√≠t√©s√©re szolg√°l, a felh≈ët≈ël az edge-ig. Felgyors√≠tja a m√©lytanul√°si inferenci√°t k√ºl√∂nf√©le felhaszn√°l√°si esetekben, p√©ld√°ul generat√≠v AI, vide√≥, hang √©s nyelv ter√©n, olyan n√©pszer≈± keretrendszerek modelljeivel, mint a PyTorch, TensorFlow, ONNX √©s m√°sok. Konvert√°lja √©s optimaliz√°lja a modelleket, majd telep√≠tse ≈ëket k√ºl√∂nb√∂z≈ë Intel¬Æ hardverekre √©s k√∂rnyezetekbe, helyben vagy eszk√∂zoldalon, b√∂ng√©sz≈ëben vagy felh≈ëben.

Az OpenVINO seg√≠ts√©g√©vel most gyorsan kvant√°lhatja a generat√≠v AI-modellt Intel hardveren, √©s felgyors√≠thatja a modellreferenci√°t.

Az OpenVINO most t√°mogatja a Phi-3.5-Vision √©s a Phi-3.5 Instruct kvant√°l√°si konverzi√≥j√°t.

### **K√∂rnyezet be√°ll√≠t√°sa**

Gy≈ëz≈ëdj√∂n meg r√≥la, hogy a k√∂vetkez≈ë k√∂rnyezeti f√ºgg≈ës√©gek telep√≠tve vannak. Ez a requirement.txt

```txt

--extra-index-url https://download.pytorch.org/whl/cpu
optimum-intel>=1.18.2
nncf>=2.11.0
openvino>=2024.3.0
transformers>=4.40
openvino-genai>=2024.3.0.0

```

### **Phi-3.5-Instruct kvant√°l√°sa OpenVINO-val**

Termin√°lban futtassa a k√∂vetkez≈ë szkriptet:

```bash


export llm_model_id = "microsoft/Phi-3.5-mini-instruct"

export llm_model_path = "your save quantizing Phi-3.5-instruct location"

optimum-cli export openvino --model {llm_model_id} --task text-generation-with-past --weight-format int4 --group-size 128 --ratio 0.6  --sym  --trust-remote-code {llm_model_path}


```

### **Phi-3.5-Vision kvant√°l√°sa OpenVINO-val**

Futtassa a k√∂vetkez≈ë szkriptet Pythonban vagy Jupyter labban:

```python

import requests
from pathlib import Path
from ov_phi3_vision import convert_phi3_model
import nncf

if not Path("ov_phi3_vision.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/ov_phi3_vision.py")
    open("ov_phi3_vision.py", "w").write(r.text)


if not Path("gradio_helper.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/notebooks/phi-3-vision/gradio_helper.py")
    open("gradio_helper.py", "w").write(r.text)

if not Path("notebook_utils.py").exists():
    r = requests.get(url="https://raw.githubusercontent.com/openvinotoolkit/openvino_notebooks/latest/utils/notebook_utils.py")
    open("notebook_utils.py", "w").write(r.text)



model_id = "microsoft/Phi-3.5-vision-instruct"
out_dir = Path("../model/phi-3.5-vision-128k-instruct-ov")
compression_configuration = {
    "mode": nncf.CompressWeightsMode.INT4_SYM,
    "group_size": 64,
    "ratio": 0.6,
}
if not out_dir.exists():
    convert_phi3_model(model_id, out_dir, compression_configuration)

```

### **ü§ñ Mint√°k Phi-3.5-h√∂z Intel OpenVINO-val**

| Laborok    | Bemutat√°s | Ind√≠t√°s |
| -------- | ------- |  ------- |
| üöÄ Lab-Phi-3.5 Instruct bemutat√°sa  | Tanulja meg, hogyan haszn√°lja a Phi-3.5 Instruct-ot az AI PC-j√©n |  [Ind√≠t√°s](../../../../../code/09.UpdateSamples/Aug/intel-phi35-instruct-zh.ipynb)    |
| üöÄ Lab-Phi-3.5 Vision (k√©p) bemutat√°sa | Tanulja meg, hogyan haszn√°lja a Phi-3.5 Vision-t k√©pelemz√©sre az AI PC-j√©n |  [Ind√≠t√°s](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-img.ipynb)    |
| üöÄ Lab-Phi-3.5 Vision (vide√≥) bemutat√°sa   | Tanulja meg, hogyan haszn√°lja a Phi-3.5 Vision-t vide√≥elemz√©sre az AI PC-j√©n |  [Ind√≠t√°s](../../../../../code/09.UpdateSamples/Aug/intel-phi35-vision-video.ipynb)    |

## **Forr√°sok**

1. Tudjon meg t√∂bbet az Intel OpenVINO-r√≥l: [https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html](https://www.intel.com/content/www/us/en/developer/tools/openvino-toolkit/overview.html)

2. Intel OpenVINO GitHub Repo: [https://github.com/openvinotoolkit/openvino.genai](https://github.com/openvinotoolkit/openvino.genai)

**Felel≈ëss√©gkiz√°r√°s**:  
Ez a dokumentum g√©pi AI ford√≠t√°si szolg√°ltat√°sok seg√≠ts√©g√©vel k√©sz√ºlt. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë a hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt a professzion√°lis, emberi ford√≠t√°s ig√©nybev√©tele. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.