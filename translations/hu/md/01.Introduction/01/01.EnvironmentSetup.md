# Kezdje el helyben használni a Phi-3-at

Ez az útmutató segít beállítani a helyi környezetét a Phi-3 modell futtatásához az Ollama segítségével. A modellt többféleképpen futtathatja, például a GitHub Codespaces, a VS Code Dev Containers vagy a helyi környezet használatával.

## Környezet beállítása

### GitHub Codespaces

Virtuálisan futtathatja ezt a sablont a GitHub Codespaces használatával. A gomb megnyit egy böngészőalapú VS Code példányt:

1. Nyissa meg a sablont (ez néhány percet igénybe vehet):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Nyisson meg egy terminálablakot.

### VS Code Dev Containers

⚠️ Ez az opció csak akkor fog működni, ha a Docker Desktop számára legalább 16 GB RAM van kiosztva. Ha kevesebb mint 16 GB RAM áll rendelkezésére, próbálja meg a [GitHub Codespaces opciót](../../../../../md/01.Introduction/01) vagy [állítsa be helyben](../../../../../md/01.Introduction/01).

Egy kapcsolódó lehetőség a VS Code Dev Containers, amely megnyitja a projektet a helyi VS Code-ban a [Dev Containers bővítmény](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers) használatával:

1. Indítsa el a Docker Desktopot (ha még nincs telepítve, telepítse).
2. Nyissa meg a projektet:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. A megnyíló VS Code ablakban, miután a projekt fájljai megjelennek (ez néhány percet igénybe vehet), nyisson meg egy terminálablakot.
4. Folytassa a [telepítési lépésekkel](../../../../../md/01.Introduction/01).

### Helyi környezet

1. Győződjön meg róla, hogy a következő eszközök telepítve vannak:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## A modell tesztelése

1. Kérje meg az Ollama-t, hogy töltse le és futtassa a phi3:mini modellt:

    ```shell
    ollama run phi3:mini
    ```

    Ez néhány percet igénybe vesz, amíg a modell letöltődik.

2. Amint a kimenetben megjelenik a "success" üzenet, küldhet üzenetet a modellnek a promptból.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Néhány másodperc múlva látnia kell, hogy a modell elkezdi a választ streamelni.

4. Ha szeretne többet megtudni a nyelvi modellekkel kapcsolatos különböző technikákról, nyissa meg a [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) Python notebookot, és futtassa az egyes cellákat. Ha nem a 'phi3:mini' modellt használta, módosítsa a fájl tetején található `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` értéket szükség szerint. Emellett módosíthatja a rendszerüzenetet, vagy hozzáadhat néhány példát is, ha szükséges.

**Jogi nyilatkozat**:  
Ez a dokumentum gépi AI fordítószolgáltatások használatával készült fordítás. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelvén tekintendő hiteles forrásnak. Kritikus információk esetén javasoljuk professzionális, emberi fordító igénybevételét. Nem vállalunk felelősséget a fordítás használatából eredő félreértésekért vagy téves értelmezésekért.