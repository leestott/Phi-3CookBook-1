# Bermula dengan Phi-3 secara tempatan

Panduan ini akan membantu anda menyediakan persekitaran tempatan untuk menjalankan model Phi-3 menggunakan Ollama. Anda boleh menjalankan model ini dengan beberapa cara berbeza, termasuk menggunakan GitHub Codespaces, VS Code Dev Containers, atau persekitaran tempatan anda.

## Persediaan Persekitaran

### GitHub Codespaces

Anda boleh menjalankan templat ini secara maya menggunakan GitHub Codespaces. Butang ini akan membuka instance VS Code berasaskan web dalam pelayar anda:

1. Buka templat ini (proses ini mungkin mengambil masa beberapa minit):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Buka tetingkap terminal.

### VS Code Dev Containers

⚠️ Pilihan ini hanya akan berfungsi jika Docker Desktop anda diperuntukkan sekurang-kurangnya 16 GB RAM. Jika anda mempunyai kurang daripada 16 GB RAM, anda boleh mencuba [pilihan GitHub Codespaces](../../../../../md/01.Introduction/01) atau [sediakannya secara tempatan](../../../../../md/01.Introduction/01).

Pilihan berkaitan ialah VS Code Dev Containers, yang akan membuka projek ini dalam VS Code tempatan anda menggunakan [sambungan Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Mulakan Docker Desktop (pasang jika belum dipasang).
2. Buka projek ini:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Dalam tetingkap VS Code yang terbuka, setelah fail projek dipaparkan (proses ini mungkin mengambil masa beberapa minit), buka tetingkap terminal.
4. Teruskan dengan [langkah penyebaran](../../../../../md/01.Introduction/01).

### Persekitaran Tempatan

1. Pastikan alat berikut telah dipasang:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Uji model

1. Minta Ollama untuk memuat turun dan menjalankan model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Proses ini akan mengambil masa beberapa minit untuk memuat turun model tersebut.

2. Setelah anda melihat "success" dalam output, anda boleh menghantar mesej kepada model tersebut dari prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Selepas beberapa saat, anda sepatutnya melihat aliran respons daripada model.

4. Untuk mempelajari teknik-teknik berbeza yang digunakan dengan model bahasa, buka notebook Python [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) dan jalankan setiap sel. Jika anda menggunakan model selain 'phi3:mini', ubah `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` di bahagian atas fail seperti yang diperlukan, dan anda juga boleh mengubah mesej sistem atau menambah contoh few-shot jika diinginkan.

**Penafian**:  
Dokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI berasaskan mesin. Walaupun kami berusaha untuk memastikan ketepatan, sila ambil perhatian bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang berwibawa. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.