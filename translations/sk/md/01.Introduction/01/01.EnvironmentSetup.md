# Začnite s Phi-3 lokálne

Tento sprievodca vám pomôže nastaviť vaše lokálne prostredie na spustenie modelu Phi-3 pomocou Ollama. Model môžete spustiť niekoľkými rôznymi spôsobmi, vrátane použitia GitHub Codespaces, VS Code Dev Containers alebo vášho lokálneho prostredia.

## Nastavenie prostredia

### GitHub Codespaces

Túto šablónu môžete spustiť virtuálne pomocou GitHub Codespaces. Tlačidlo otvorí webovú verziu VS Code vo vašom prehliadači:

1. Otvorte šablónu (môže to trvať niekoľko minút):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Otvorte terminálové okno.

### VS Code Dev Containers

⚠️ Táto možnosť bude fungovať iba v prípade, že váš Docker Desktop má pridelených aspoň 16 GB RAM. Ak máte menej ako 16 GB RAM, môžete skúsiť možnosť [GitHub Codespaces](../../../../../md/01.Introduction/01) alebo [nastaviť to lokálne](../../../../../md/01.Introduction/01).

Alternatívou sú VS Code Dev Containers, ktoré otvoria projekt vo vašom lokálnom VS Code pomocou [rozšírenia Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Spustite Docker Desktop (nainštalujte ho, ak ešte nie je nainštalovaný).
2. Otvorte projekt:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Vo VS Code okne, ktoré sa otvorí, po zobrazení súborov projektu (môže to trvať niekoľko minút), otvorte terminálové okno.
4. Pokračujte podľa [krokov nasadenia](../../../../../md/01.Introduction/01).

### Lokálne prostredie

1. Uistite sa, že máte nainštalované nasledujúce nástroje:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testovanie modelu

1. Požiadajte Ollama, aby stiahol a spustil model phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    To bude trvať niekoľko minút, kým sa model stiahne.

2. Keď v výstupe uvidíte "success", môžete modelu poslať správu z príkazového riadku.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Po niekoľkých sekundách by ste mali vidieť prichádzajúcu odpoveď od modelu.

4. Ak sa chcete dozvedieť o rôznych technikách používaných s jazykovými modelmi, otvorte Python notebook [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) a spustite každý blok. Ak ste použili iný model ako 'phi3:mini', zmeňte `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` na začiatku súboru podľa potreby. Taktiež môžete upraviť systémovú správu alebo pridať príklady few-shot, ak je to žiaduce.

**Upozornenie**:  
Tento dokument bol preložený pomocou strojových AI prekladateľských služieb. Hoci sa snažíme o presnosť, upozorňujeme, že automatizované preklady môžu obsahovať chyby alebo nepresnosti. Pôvodný dokument v jeho pôvodnom jazyku by mal byť považovaný za autoritatívny zdroj. Pre kritické informácie sa odporúča profesionálny ľudský preklad. Nezodpovedáme za akékoľvek nedorozumenia alebo nesprávne interpretácie vyplývajúce z použitia tohto prekladu.