# **Korzystanie z rodziny Phi w Hugging Face**

[Hugging Face](https://huggingface.co/) to bardzo popularna społeczność AI z bogatymi zasobami danych i otwartymi modelami. Różni producenci publikują otwarte modele LLM i SLM za pośrednictwem Hugging Face, tacy jak Microsoft, Meta, Mistral, Apple, Google itp.

Microsoft udostępnił rodzinę Phi na platformie Hugging Face. Deweloperzy mogą pobrać odpowiedni model rodziny Phi w zależności od scenariuszy i potrzeb biznesowych. Oprócz wdrażania modeli Phi w formacie Pytorch na Hugging Face, udostępniliśmy również modele skwantowane w formatach GGUF i ONNX, dając użytkownikom końcowym możliwość wyboru.

## **Pobieranie modeli z Hugging Face**

Modele rodziny Phi można pobrać pod poniższymi linkami:

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

Modele można pobrać na różne sposoby, np. instalując ***Hugging Face CLI SDK*** lub korzystając z ***git clone***.

### **Pobieranie modeli rodziny Phi za pomocą Hugging Face CLI**

- Instalacja Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Logowanie za pomocą huggingface-cli

Zaloguj się do Hugging Face za pomocą [User Access Token](https://huggingface.co/docs/hub/security-tokens) dostępnego na [stronie ustawień](https://huggingface.co/settings/tokens).

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Pobieranie

Możesz pobrać model i zapisać go w pamięci podręcznej.

```bash

huggingface-cli download microsoft/phi-4

```

Możesz również ustawić lokalizację w wybranym przez siebie miejscu.

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **Pobieranie modeli rodziny Phi za pomocą git clone**

Modele można również pobrać za pomocą ***git clone***.

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Przykłady - Inference Microsoft Phi-4**

- **Instalacja biblioteki transformers**

```bash

pip install transformers -U

```

- **Uruchamianie kodu w VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Zastrzeżenie**:  
Niniejszy dokument został przetłumaczony za pomocą usług tłumaczeniowych opartych na sztucznej inteligencji. Chociaż staramy się zapewnić dokładność, prosimy mieć na uwadze, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za źródło autorytatywne. W przypadku informacji o krytycznym znaczeniu zaleca się skorzystanie z profesjonalnego tłumaczenia wykonanego przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z użycia tego tłumaczenia.