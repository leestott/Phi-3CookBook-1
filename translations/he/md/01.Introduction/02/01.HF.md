# **שימוש ב-Phi Family ב-Hugging Face**

[Hugging Face](https://huggingface.co/) היא קהילה פופולרית מאוד בתחום ה-AI, עם מאגרי מידע עשירים ומשאבים של מודלים בקוד פתוח. יצרנים שונים משחררים מודלים בקוד פתוח של LLM ו-SLM דרך Hugging Face, כמו Microsoft, Meta, Mistral, Apple, Google ועוד.

משפחת Microsoft Phi שוחררה ב-Hugging Face. מפתחים יכולים להוריד את המודל המתאים ממשפחת Phi בהתאם לתרחישים ולצרכים העסקיים שלהם. בנוסף לפריסת מודלים של Phi בפורמט Pytorch ב-Hugging Face, שוחררו גם מודלים מכווצים בפורמטים GGUF ו-ONNX, כדי להציע למשתמשי הקצה אפשרויות נוספות.

## **הורדת מודלים ב-Hugging Face**

ניתן להוריד את מודלי משפחת Phi דרך הקישורים הבאים:

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

ניתן להוריד את המודל בדרכים שונות, כמו התקנת ***Hugging Face CLI SDK*** או שימוש ב-***git clone***.

### **שימוש ב-Hugging Face CLI להורדת מודל ממשפחת Phi**

- התקנת Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- התחברות באמצעות huggingface-cli

התחברו ל-Hugging Face באמצעות [User Access Token](https://huggingface.co/docs/hub/security-tokens) שנמצא בדף [ההגדרות שלכם](https://huggingface.co/settings/tokens).

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- הורדה

ניתן להוריד את המודל ולשמור אותו במטמון.

```bash

huggingface-cli download microsoft/phi-4

```

ניתן גם להגדיר מיקום שמור במיוחד.

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **שימוש ב-git clone להורדת מודל ממשפחת Phi**

ניתן להשתמש ב-***git clone*** כדי להוריד את המודל.

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **דוגמאות - ביצוע Inference על Microsoft Phi-4**

- **התקנת ספריית transformers**

```bash

pip install transformers -U

```

- **הרצת הקוד ב-VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירותי תרגום מבוססי בינה מלאכותית. למרות שאנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עשויים לכלול שגיאות או אי-דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור הסמכותי. למידע קריטי, מומלץ להשתמש בתרגום מקצועי אנושי. אנו לא נושאים באחריות לכל אי-הבנה או פרשנות שגויה הנובעת משימוש בתרגום זה.