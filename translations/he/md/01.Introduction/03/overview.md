בהקשר של Phi-3-mini, הסקה מתייחסת לתהליך שבו משתמשים במודל כדי לבצע תחזיות או להפיק פלטים בהתבסס על נתוני קלט. הנה פרטים נוספים על Phi-3-mini ויכולות ההסקה שלו.

Phi-3-mini הוא חלק מסדרת המודלים Phi-3 שהושקה על ידי מיקרוסופט. מודלים אלו נועדו להגדיר מחדש את היכולות של מודלים לשוניים קטנים (SLMs).

להלן כמה נקודות מפתח על Phi-3-mini ויכולות ההסקה שלו:

## **סקירה כללית של Phi-3-mini:**
- ל-Phi-3-mini יש גודל פרמטרים של 3.8 מיליארד.
- הוא יכול לפעול לא רק על מכשירי מחשוב מסורתיים, אלא גם על מכשירי קצה כמו מכשירים ניידים ומכשירי IoT.
- השקת Phi-3-mini מאפשרת לאנשים ולארגונים לפרוס מודלים לשוניים קטנים (SLMs) על מגוון מכשירי חומרה, במיוחד בסביבות מוגבלות משאבים.
- הוא תומך בפורמטי מודל שונים, כולל פורמט PyTorch המסורתי, גרסה מקוונטת של פורמט gguf, וגרסה מקוונטת מבוססת ONNX.

## **גישה ל-Phi-3-mini:**
כדי לגשת ל-Phi-3-mini, ניתן להשתמש ב-[Semantic Kernel](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) באפליקציית Copilot. Semantic Kernel תואם בדרך כלל לשירות Azure OpenAI, מודלים בקוד פתוח מ-Hugging Face, ומודלים מקומיים.  
ניתן גם להשתמש ב-[Ollama](https://ollama.com) או [LlamaEdge](https://llamaedge.com) כדי להפעיל מודלים מקוונטיים. Ollama מאפשר למשתמשים פרטיים להפעיל מודלים מקוונטיים שונים, בעוד LlamaEdge מספק זמינות חוצת פלטפורמות למודלי GGUF.

## **מודלים מקוונטיים:**
משתמשים רבים מעדיפים להשתמש במודלים מקוונטיים לצורך הסקה מקומית. לדוגמה, ניתן להפעיל את Ollama run Phi-3 ישירות או להגדיר אותו במצב לא מקוון באמצעות Modelfile. קובץ ה-Modelfile מציין את נתיב קובץ ה-GGUF ואת פורמט ההנחיה.

## **אפשרויות בינה מלאכותית גנרטיבית:**
שילוב של מודלים לשוניים קטנים (SLMs) כמו Phi-3-mini פותח אפשרויות חדשות לבינה מלאכותית גנרטיבית. הסקה היא רק השלב הראשון; ניתן להשתמש במודלים אלו למשימות שונות בסביבות מוגבלות משאבים, עם דרישות נמוכות לזמן תגובה ועלויות.

## **שחרור הפוטנציאל של בינה מלאכותית גנרטיבית עם Phi-3-mini: מדריך להסקה ופריסה**  
למדו כיצד להשתמש ב-Semantic Kernel, Ollama/LlamaEdge ו-ONNX Runtime כדי לגשת למודלים של Phi-3-mini ולהסיק מהם, וגלו את האפשרויות של בינה מלאכותית גנרטיבית בתרחישי יישום שונים.

**תכונות**
הסקה ממודל phi3-mini ב:

- [Semantic Kernel](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo)
- [Ollama](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)
- [LlamaEdge WASM](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo)
- [ONNX Runtime](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/onnx?WT.mc_id=aiml-138114-kinfeylo)
- [iOS](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ios?WT.mc_id=aiml-138114-kinfeylo)

לסיכום, Phi-3-mini מאפשר למפתחים לחקור פורמטי מודל שונים ולנצל את הבינה המלאכותית הגנרטיבית בתרחישי יישום מגוונים.

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירותי תרגום מבוססי בינה מלאכותית. בעוד שאנו שואפים לדיוק, אנא היו מודעים לכך שתרגומים אוטומטיים עשויים להכיל טעויות או אי-דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור הסמכותי. למידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי-הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.