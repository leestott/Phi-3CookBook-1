**Aprimorando o Phi-3 com QLoRA**

Aprimorando o modelo de linguagem Phi-3 Mini da Microsoft utilizando [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

O QLoRA ajudará a melhorar a compreensão conversacional e a geração de respostas.

Para carregar modelos em 4 bits com transformers e bitsandbytes, é necessário instalar accelerate e transformers a partir do código-fonte e garantir que você tenha a versão mais recente da biblioteca bitsandbytes.

**Exemplos**
- [Saiba mais com este notebook de exemplo](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Exemplo de FineTuning em Python](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Exemplo de Fine Tuning no Hugging Face Hub com LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Exemplo de Fine Tuning no Hugging Face Hub com QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**Aviso Legal**:  
Este documento foi traduzido utilizando serviços de tradução baseados em IA. Embora nos esforcemos para alcançar a precisão, esteja ciente de que traduções automatizadas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informações críticas, recomenda-se a tradução profissional humana. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações equivocadas decorrentes do uso desta tradução.