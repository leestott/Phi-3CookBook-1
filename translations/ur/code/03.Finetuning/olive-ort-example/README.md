# اولیو کا استعمال کرتے ہوئے Phi3 کو فائن ٹیون کریں

اس مثال میں آپ اولیو کا استعمال کرتے ہوئے:

1. LoRA اڈاپٹر کو فائن ٹیون کریں گے تاکہ جملوں کو Sad, Joy, Fear, Surprise میں تقسیم کیا جا سکے۔
2. اڈاپٹر ویٹس کو بیس ماڈل میں ضم کریں گے۔
3. ماڈل کو `int4` میں آپٹمائز اور کوانٹائز کریں گے۔

ہم آپ کو یہ بھی دکھائیں گے کہ کس طرح فائن ٹیون شدہ ماڈل کو ONNX Runtime (ORT) Generate API کا استعمال کرتے ہوئے انفرنس کریں۔

> **⚠️ فائن ٹیوننگ کے لیے، آپ کے پاس ایک مناسب GPU ہونا ضروری ہے - مثال کے طور پر، A10, V100, A100۔**

## 💾 انسٹال کریں

ایک نیا Python ورچوئل ماحول بنائیں (مثال کے طور پر، `conda` کا استعمال کرتے ہوئے):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

پھر، اولیو اور فائن ٹیوننگ ورک فلو کے لیے ضروری ڈپینڈنسیز انسٹال کریں:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## 🧪 اولیو کا استعمال کرتے ہوئے Phi3 کو فائن ٹیون کریں
[اولیو کنفیگریشن فائل](../../../../../code/03.Finetuning/olive-ort-example/phrase-classification.json) ایک *ورک فلو* پر مشتمل ہے جس میں درج ذیل *پاسز* شامل ہیں:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

اعلی سطح پر، یہ ورک فلو درج ذیل کرے گا:

1. Phi3 کو [dataset/data-classification.json](../../../../../code/03.Finetuning/olive-ort-example/dataset/dataset-classification.json) ڈیٹا کا استعمال کرتے ہوئے 150 مراحل کے لیے (جسے آپ تبدیل کر سکتے ہیں) فائن ٹیون کرے گا۔
2. LoRA اڈاپٹر ویٹس کو بیس ماڈل میں ضم کرے گا۔ اس سے آپ کو ONNX فارمیٹ میں ایک واحد ماڈل آرٹیفیکٹ ملے گا۔
3. ماڈل بلڈر ماڈل کو ONNX رن ٹائم کے لیے آپٹمائز کرے گا *اور* ماڈل کو `int4` میں کوانٹائز کرے گا۔

ورک فلو چلانے کے لیے:

```bash
olive run --config phrase-classification.json
```

جب اولیو مکمل ہو جائے، تو آپ کا آپٹمائزڈ `int4` فائن ٹیون شدہ Phi3 ماڈل یہاں دستیاب ہوگا: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`۔

## 🧑‍💻 اپنی ایپلی کیشن میں فائن ٹیون شدہ Phi3 کو شامل کریں 

ایپ چلانے کے لیے:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

یہ رسپانس جملے کی ایک واحد لفظی درجہ بندی ہونی چاہیے (Sad/Joy/Fear/Surprise)۔

**اعلانِ لاتعلقی**:  
یہ دستاویز مشین پر مبنی AI ترجمہ خدمات کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی مقامی زبان میں مستند ماخذ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ورانہ انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔