# **ایپل MLX فریم ورک کے ساتھ Phi-3 کا انفیرنس**

## **MLX فریم ورک کیا ہے؟**

MLX ایک ایری فریم ورک ہے جو ایپل سلیکن پر مشین لرننگ ریسرچ کے لیے بنایا گیا ہے، اور یہ ایپل مشین لرننگ ریسرچ ٹیم کی جانب سے پیش کیا گیا ہے۔

MLX خاص طور پر مشین لرننگ محققین کے لیے ڈیزائن کیا گیا ہے۔ یہ فریم ورک استعمال میں آسان ہونے کے ساتھ ساتھ ماڈلز کو ٹرین اور ڈیپلائے کرنے میں بھی مؤثر ہے۔ اس کا ڈیزائن سادہ اور سمجھنے میں آسان ہے تاکہ محققین آسانی سے MLX کو بڑھا سکیں اور نئے آئیڈیاز کو تیزی سے آزما سکیں۔

ایپل سلیکن ڈیوائسز پر LLMs کو MLX کے ذریعے تیز کیا جا سکتا ہے، اور ماڈلز کو مقامی طور پر بڑی سہولت کے ساتھ چلایا جا سکتا ہے۔

## **MLX کا استعمال کرتے ہوئے Phi-3-mini کا انفیرنس کرنا**

### **1. MLX ماحول سیٹ اپ کریں**

1. Python 3.11.x  
2. MLX لائبریری انسٹال کریں  

```bash

pip install mlx-lm

```

### **2. MLX کے ساتھ ٹرمینل میں Phi-3-mini چلانا**

```bash

python -m mlx_lm.generate --model microsoft/Phi-3-mini-4k-instruct --max-token 2048 --prompt  "<|user|>\nCan you introduce yourself<|end|>\n<|assistant|>"

```

نتیجہ (میرا ماحول Apple M1 Max, 64GB ہے)

![Terminal](../../../../../translated_images/01.0d0f100b646a4e4c4f1cd36c1a05727cd27f1e696ed642c06cf6e2c9bbf425a4.ur.png)

### **3. ٹرمینل میں MLX کے ذریعے Phi-3-mini کو کوانٹائز کرنا**

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

***نوٹ:*** ماڈل کو mlx_lm.convert کے ذریعے کوانٹائز کیا جا سکتا ہے، اور ڈیفالٹ کوانٹائزیشن INT4 ہے۔ اس مثال میں Phi-3-mini کو INT4 میں کوانٹائز کیا گیا ہے۔

ماڈل کو mlx_lm.convert کے ذریعے کوانٹائز کیا جا سکتا ہے، اور ڈیفالٹ کوانٹائزیشن INT4 ہے۔ اس مثال میں Phi-3-mini کو INT4 میں کوانٹائز کیا گیا ہے۔ کوانٹائزیشن کے بعد، یہ ڈیفالٹ ڈائریکٹری ./mlx_model میں محفوظ ہو جائے گا۔

ہم MLX کے ساتھ کوانٹائز کیے گئے ماڈل کو ٹرمینل سے ٹیسٹ کر سکتے ہیں۔

```bash

python -m mlx_lm.generate --model ./mlx_model/ --max-token 2048 --prompt  "<|user|>\nCan you introduce yourself<|end|>\n<|assistant|>"

```

نتیجہ:

![INT4](../../../../../translated_images/02.04e0be1f18a90a58ad47e0c9d9084ac94d0f1a8c02fa707d04dd2dfc7e9117c6.ur.png)

### **4. Jupyter Notebook میں MLX کے ساتھ Phi-3-mini چلانا**

![Notebook](../../../../../translated_images/03.0cf0092fe143357656bb5a7bc6427c41d8528d772d38a82d0b2693e2a3eeb16e.ur.png)

***نوٹ:*** براہ کرم یہ نمونہ دیکھیں [اس لنک پر کلک کریں](../../../../../code/03.Inference/MLX/MLX_DEMO.ipynb)

## **وسائل**

1. ایپل MLX فریم ورک کے بارے میں جانیں [https://ml-explore.github.io](https://ml-explore.github.io/mlx/build/html/index.html)

2. ایپل MLX GitHub ریپو [https://github.com/ml-explore](https://github.com/ml-explore)

**ڈسکلیمر**:  
یہ دستاویز مشین پر مبنی اے آئی ترجمہ خدمات کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے پوری کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔