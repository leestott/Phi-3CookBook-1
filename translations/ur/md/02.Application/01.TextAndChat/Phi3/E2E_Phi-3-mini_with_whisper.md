# انٹرایکٹو Phi 3 Mini 4K انسٹرکٹ چیٹ بوٹ ود وِسپر

## جائزہ

انٹرایکٹو Phi 3 Mini 4K انسٹرکٹ چیٹ بوٹ ایک ایسا ٹول ہے جو صارفین کو مائیکروسافٹ Phi 3 Mini 4K انسٹرکٹ ڈیمو کے ساتھ ٹیکسٹ یا آڈیو ان پٹ کے ذریعے بات چیت کرنے کی سہولت دیتا ہے۔ یہ چیٹ بوٹ مختلف کاموں کے لیے استعمال کیا جا سکتا ہے، جیسے ترجمہ، موسم کی معلومات، اور عمومی معلومات حاصل کرنا۔

### شروعات کیسے کریں

اس چیٹ بوٹ کو استعمال کرنے کے لیے، نیچے دی گئی ہدایات پر عمل کریں:

1. ایک نیا [E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) کھولیں۔
2. نوٹ بک کی مین ونڈو میں، آپ کو ایک چیٹ باکس انٹرفیس نظر آئے گا جس میں ایک ٹیکسٹ ان پٹ باکس اور ایک "Send" بٹن ہوگا۔
3. ٹیکسٹ پر مبنی چیٹ بوٹ استعمال کرنے کے لیے، اپنے پیغام کو ٹیکسٹ ان پٹ باکس میں ٹائپ کریں اور "Send" بٹن پر کلک کریں۔ چیٹ بوٹ ایک آڈیو فائل کے ساتھ جواب دے گا جسے نوٹ بک کے اندر ہی چلایا جا سکتا ہے۔

**نوٹ**: اس ٹول کے لیے جی پی یو اور مائیکروسافٹ Phi-3 اور اوپن اے آئی وِسپر ماڈلز تک رسائی درکار ہے، جو تقریر کی شناخت اور ترجمے کے لیے استعمال ہوتا ہے۔

### جی پی یو کی ضروریات

اس ڈیمو کو چلانے کے لیے آپ کو 12 جی بی جی پی یو میموری کی ضرورت ہوگی۔

**Microsoft-Phi-3-Mini-4K انسٹرکٹ** ڈیمو کو جی پی یو پر چلانے کے لیے میموری کی ضروریات کئی عوامل پر منحصر ہوں گی، جیسے ان پٹ ڈیٹا (آڈیو یا ٹیکسٹ) کا سائز، ترجمے کے لیے استعمال ہونے والی زبان، ماڈل کی رفتار، اور جی پی یو پر دستیاب میموری۔

عمومی طور پر، وِسپر ماڈل جی پی یوز پر چلانے کے لیے ڈیزائن کیا گیا ہے۔ وِسپر ماڈل کو چلانے کے لیے کم از کم 8 جی بی جی پی یو میموری کی سفارش کی جاتی ہے، لیکن اگر ضرورت ہو تو یہ زیادہ میموری بھی ہینڈل کر سکتا ہے۔

یہ نوٹ کرنا ضروری ہے کہ اگر ماڈل پر بڑی مقدار میں ڈیٹا یا درخواستوں کا زیادہ حجم چلایا جائے تو زیادہ جی پی یو میموری کی ضرورت ہو سکتی ہے یا کارکردگی کے مسائل پیدا ہو سکتے ہیں۔ اپنی مخصوص ضروریات کے لیے مختلف کنفیگریشنز کے ساتھ ٹیسٹ کرنے اور میموری کے استعمال کی نگرانی کرنے کی سفارش کی جاتی ہے تاکہ بہترین سیٹنگز کا تعین کیا جا سکے۔

## انٹرایکٹو Phi 3 Mini 4K انسٹرکٹ چیٹ بوٹ ود وِسپر کے لیے E2E سیمپل

جیوپیٹر نوٹ بک [Interactive Phi 3 Mini 4K Instruct Chatbot with Whisper](https://github.com/microsoft/Phi-3CookBook/blob/main/code/06.E2E/E2E_Phi-3-mini-4k-instruct-Whispser_Demo.ipynb) یہ ظاہر کرتی ہے کہ مائیکروسافٹ Phi 3 Mini 4K انسٹرکٹ ڈیمو کو آڈیو یا لکھے گئے ٹیکسٹ ان پٹ سے ٹیکسٹ پیدا کرنے کے لیے کیسے استعمال کیا جائے۔ نوٹ بک میں کئی فنکشنز کی وضاحت کی گئی ہے:

1. `tts_file_name(text)`: یہ فنکشن ان پٹ ٹیکسٹ کی بنیاد پر ایک فائل نام بناتا ہے تاکہ پیدا ہونے والی آڈیو فائل کو محفوظ کیا جا سکے۔
2. `edge_free_tts(chunks_list,speed,voice_name,save_path)`: یہ فنکشن Edge TTS API کا استعمال کرتے ہوئے ان پٹ ٹیکسٹ کے چنکس کی ایک فہرست سے آڈیو فائل تیار کرتا ہے۔ ان پٹ پیرامیٹرز میں چنکس کی فہرست، تقریر کی رفتار، آواز کا نام، اور آؤٹ پٹ پاتھ شامل ہیں جہاں آڈیو فائل کو محفوظ کیا جائے گا۔
3. `talk(input_text)`: یہ فنکشن Edge TTS API کا استعمال کرتے ہوئے ایک آڈیو فائل تیار کرتا ہے اور اسے /content/audio ڈائریکٹری میں ایک رینڈم فائل نام کے ساتھ محفوظ کرتا ہے۔ ان پٹ پیرامیٹر وہ ٹیکسٹ ہے جسے تقریر میں تبدیل کیا جانا ہے۔
4. `run_text_prompt(message, chat_history)`: یہ فنکشن مائیکروسافٹ Phi 3 Mini 4K انسٹرکٹ ڈیمو کا استعمال کرتے ہوئے ایک آڈیو فائل تیار کرتا ہے اور اسے چیٹ ہسٹری میں شامل کرتا ہے۔
5. `run_audio_prompt(audio, chat_history)`: یہ فنکشن وِسپر ماڈل API کا استعمال کرتے ہوئے ایک آڈیو فائل کو ٹیکسٹ میں تبدیل کرتا ہے اور اسے `run_text_prompt()` فنکشن میں بھیجتا ہے۔
6. کوڈ ایک Gradio ایپ لانچ کرتا ہے جو صارفین کو Phi 3 Mini 4K انسٹرکٹ ڈیمو کے ساتھ بات چیت کرنے کی اجازت دیتا ہے، چاہے وہ پیغامات ٹائپ کریں یا آڈیو فائلز اپ لوڈ کریں۔ آؤٹ پٹ ایپ میں ایک ٹیکسٹ پیغام کے طور پر ظاہر ہوتا ہے۔

## مسائل حل کرنا

Cuda GPU ڈرائیورز انسٹال کرنا

1. یقینی بنائیں کہ آپ کے لینکس ایپلیکیشنز اپ ٹو ڈیٹ ہیں۔

    ```bash
    sudo apt update
    ```

2. Cuda ڈرائیورز انسٹال کریں۔

    ```bash
    sudo apt install nvidia-cuda-toolkit
    ```

3. Cuda ڈرائیور لوکیشن کو رجسٹر کریں۔

    ```bash
    echo /usr/lib64-nvidia/ >/etc/ld.so.conf.d/libcuda.conf; ldconfig
    ```

4. Nvidia GPU میموری سائز چیک کریں (12 جی بی جی پی یو میموری درکار ہے)۔

    ```bash
    nvidia-smi
    ```

5. کیش خالی کریں: اگر آپ PyTorch استعمال کر رہے ہیں تو آپ torch.cuda.empty_cache() کال کر سکتے ہیں تاکہ تمام غیر استعمال شدہ کیش میموری ریلیز ہو جائے تاکہ اسے دیگر جی پی یو ایپلیکیشنز استعمال کر سکیں۔

    ```python
    torch.cuda.empty_cache() 
    ```

6. Nvidia Cuda چیک کریں۔

    ```bash
    nvcc --version
    ```

7. Hugging Face ٹوکن بنانے کے لیے درج ذیل کام انجام دیں:

    - [Hugging Face Token Settings page](https://huggingface.co/settings/tokens?WT.mc_id=aiml-137032-kinfeylo) پر جائیں۔
    - **New token** کو منتخب کریں۔
    - وہ پروجیکٹ **Name** درج کریں جو آپ استعمال کرنا چاہتے ہیں۔
    - **Type** کو **Write** پر سیٹ کریں۔

> **نوٹ**
>
> اگر آپ کو درج ذیل ایرر کا سامنا ہو:
>
> ```bash
> /sbin/ldconfig.real: Can't create temporary cache file /etc/ld.so.cache~: Permission denied 
> ```
>
> اس مسئلے کو حل کرنے کے لیے، اپنے ٹرمینل میں درج ذیل کمانڈ ٹائپ کریں:
>
> ```bash
> sudo ldconfig
> ```

**ڈسکلیمر**:  
یہ دستاویز مشین پر مبنی AI ترجمہ خدمات کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ورانہ انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔