# ذکر کی گئی اہم ٹیکنالوجیز

1. [DirectML](https://learn.microsoft.com/windows/ai/directml/dml?WT.mc_id=aiml-138114-kinfeylo) - DirectX 12 کے اوپر بنائی گئی ہارڈویئر سے تیز رفتار مشین لرننگ کے لیے ایک لو لیول API۔
2. [CUDA](https://blogs.nvidia.com/blog/what-is-cuda-2/) - Nvidia کی تیار کردہ ایک متوازی کمپیوٹنگ پلیٹ فارم اور API ماڈل جو GPUs پر عمومی پروسیسنگ کی اجازت دیتا ہے۔
3. [ONNX](https://onnx.ai/) (اوپن نیورل نیٹ ورک ایکسچینج) - ایک اوپن فارمیٹ جو مشین لرننگ ماڈلز کو مختلف ML فریم ورک کے درمیان انٹرآپریبلٹی فراہم کرنے کے لیے ڈیزائن کیا گیا ہے۔
4. [GGUF](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md) (جنیرک گراف اپڈیٹ فارمیٹ) - ایک فارمیٹ جو خاص طور پر چھوٹے لینگویج ماڈلز کے لیے مفید ہے جو CPUs پر 4-8bit کوانٹائزیشن کے ساتھ مؤثر طریقے سے چل سکتے ہیں۔

## DirectML

DirectML ایک لو لیول API ہے جو ہارڈویئر سے تیز رفتار مشین لرننگ کو ممکن بناتا ہے۔ یہ DirectX 12 کے اوپر بنایا گیا ہے تاکہ GPU کی تیز رفتاری کا فائدہ اٹھایا جا سکے اور یہ وینڈر ایگناسٹک ہے، یعنی مختلف GPU وینڈرز کے ساتھ کام کرنے کے لیے کوڈ میں تبدیلی کی ضرورت نہیں ہوتی۔ یہ بنیادی طور پر ماڈل ٹریننگ اور انفرنسنگ کے لیے استعمال ہوتا ہے۔

ہارڈویئر سپورٹ کے لحاظ سے، DirectML کو مختلف GPUs کے ساتھ کام کرنے کے لیے ڈیزائن کیا گیا ہے، جن میں AMD کے انٹیگریٹڈ اور ڈسکریٹ GPUs، Intel کے انٹیگریٹڈ GPUs، اور NVIDIA کے ڈسکریٹ GPUs شامل ہیں۔ یہ Windows AI پلیٹ فارم کا حصہ ہے اور Windows 10 اور 11 پر سپورٹڈ ہے، جس سے کسی بھی ونڈوز ڈیوائس پر ماڈل ٹریننگ اور انفرنسنگ ممکن ہو جاتی ہے۔

DirectML کے حوالے سے اپڈیٹس اور مواقع بھی موجود ہیں، جیسے کہ 150 تک ONNX آپریٹرز کی سپورٹ اور اس کا ONNX رن ٹائم اور WinML کے ذریعے استعمال۔ یہ بڑے انٹیگریٹڈ ہارڈویئر وینڈرز (IHVs) کی حمایت یافتہ ہے، جو مختلف میٹاکمانڈز کو نافذ کرتے ہیں۔

## CUDA

CUDA، جس کا مطلب Compute Unified Device Architecture ہے، Nvidia کی تیار کردہ ایک متوازی کمپیوٹنگ پلیٹ فارم اور API ماڈل ہے۔ یہ سافٹ ویئر ڈویلپرز کو CUDA-ان ایبلڈ GPUs کو عمومی پروسیسنگ کے لیے استعمال کرنے کی اجازت دیتا ہے – اس طریقے کو GPGPU (جنرل پرپز کمپیوٹنگ آن گرافکس پروسیسنگ یونٹس) کہا جاتا ہے۔ CUDA Nvidia کے GPU ایکسلریشن کا ایک اہم عنصر ہے اور مختلف شعبوں میں بڑے پیمانے پر استعمال ہوتا ہے، جن میں مشین لرننگ، سائنسی کمپیوٹنگ، اور ویڈیو پروسیسنگ شامل ہیں۔

CUDA کی ہارڈویئر سپورٹ صرف Nvidia کے GPUs کے لیے مخصوص ہے، کیونکہ یہ Nvidia کی تیار کردہ ملکیتی ٹیکنالوجی ہے۔ ہر آرکیٹیکچر CUDA ٹول کٹ کے مخصوص ورژنز کو سپورٹ کرتا ہے، جو ڈویلپرز کو CUDA ایپلیکیشنز بنانے اور چلانے کے لیے ضروری لائبریریز اور ٹولز فراہم کرتا ہے۔

## ONNX

ONNX (اوپن نیورل نیٹ ورک ایکسچینج) ایک اوپن فارمیٹ ہے جو مشین لرننگ ماڈلز کو ظاہر کرنے کے لیے ڈیزائن کیا گیا ہے۔ یہ ایک ایکسٹینسیبل کمپیوٹیشن گراف ماڈل کی تعریف فراہم کرتا ہے، ساتھ ہی بلٹ ان آپریٹرز اور اسٹینڈرڈ ڈیٹا ٹائپس کی تعریف بھی۔ ONNX ڈویلپرز کو مختلف ML فریم ورک کے درمیان ماڈلز منتقل کرنے کی اجازت دیتا ہے، جس سے انٹرآپریبلٹی ممکن ہوتی ہے اور AI ایپلیکیشنز بنانا اور ڈیپلائے کرنا آسان ہو جاتا ہے۔

Phi3 mini ONNX رن ٹائم کے ساتھ CPU اور GPU پر مختلف ڈیوائسز پر چل سکتا ہے، جن میں سرور پلیٹ فارمز، Windows، Linux اور Mac ڈیسک ٹاپس، اور موبائل CPUs شامل ہیں۔ ہم نے جو آپٹمائزڈ کنفیگریشنز شامل کی ہیں وہ ہیں:

- ONNX ماڈلز کے لیے int4 DML: AWQ کے ذریعے int4 میں کوانٹائزڈ
- fp16 CUDA کے لیے ONNX ماڈل
- int4 CUDA کے لیے ONNX ماڈل: RTN کے ذریعے int4 میں کوانٹائزڈ
- int4 CPU اور موبائل کے لیے ONNX ماڈل: RTN کے ذریعے int4 میں کوانٹائزڈ

## Llama.cpp

Llama.cpp ایک اوپن سورس سافٹ ویئر لائبریری ہے جو C++ میں لکھی گئی ہے۔ یہ مختلف بڑے لینگویج ماڈلز (LLMs)، بشمول Llama، پر انفرنس انجام دیتی ہے۔ ggml لائبریری (ایک جنرل پرپز ٹینسر لائبریری) کے ساتھ تیار کردہ، Llama.cpp اصل Python امپلیمنٹیشن کے مقابلے میں تیز انفرنس اور کم میموری کے استعمال کی پیشکش کرتا ہے۔ یہ ہارڈویئر آپٹمائزیشن، کوانٹائزیشن، اور ایک سادہ API اور مثالیں فراہم کرتا ہے۔ اگر آپ مؤثر LLM انفرنس میں دلچسپی رکھتے ہیں، تو Llama.cpp قابل غور ہے کیونکہ Phi3 Llama.cpp چلا سکتا ہے۔

## GGUF

GGUF (جنیرک گراف اپڈیٹ فارمیٹ) ایک فارمیٹ ہے جو مشین لرننگ ماڈلز کو ظاہر کرنے اور اپڈیٹ کرنے کے لیے استعمال ہوتا ہے۔ یہ خاص طور پر چھوٹے لینگویج ماڈلز (SLMs) کے لیے مفید ہے جو CPUs پر 4-8bit کوانٹائزیشن کے ساتھ مؤثر طریقے سے چل سکتے ہیں۔ GGUF تیز پروٹوٹائپنگ اور ایج ڈیوائسز یا CI/CD پائپ لائنز جیسے بیچ جابز پر ماڈلز چلانے کے لیے فائدہ مند ہے۔

**ڈس کلیمر**:  
یہ دستاویز مشین پر مبنی اے آئی ترجمہ سروسز کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی مقامی زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ورانہ انسانی ترجمہ تجویز کیا جاتا ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔