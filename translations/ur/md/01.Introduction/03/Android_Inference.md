# **اینڈرائیڈ میں Phi-3 پر انفرنس**

آئیے دیکھتے ہیں کہ آپ اینڈرائیڈ ڈیوائسز پر Phi-3-mini کے ساتھ انفرنس کیسے کر سکتے ہیں۔ Phi-3-mini مائیکروسافٹ کے نئے ماڈلز کی سیریز ہے جو بڑے لینگویج ماڈلز (LLMs) کو ایج ڈیوائسز اور آئی او ٹی ڈیوائسز پر ڈیپلائے کرنے کے قابل بناتی ہے۔

## سیمینٹک کرنل اور انفرنس

[Semantic Kernel](https://github.com/microsoft/semantic-kernel) ایک ایپلیکیشن فریم ورک ہے جو آپ کو ایسی ایپلیکیشنز بنانے کی اجازت دیتا ہے جو Azure OpenAI Service، OpenAI ماڈلز، اور حتیٰ کہ لوکل ماڈلز کے ساتھ ہم آہنگ ہوں۔ اگر آپ سیمینٹک کرنل کے لیے نئے ہیں تو ہم تجویز کرتے ہیں کہ آپ [Semantic Kernel Cookbook](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) کو دیکھیں۔

### سیمینٹک کرنل کے ذریعے Phi-3-mini تک رسائی حاصل کرنا

آپ اسے سیمینٹک کرنل میں Hugging Face کنیکٹر کے ساتھ ملا سکتے ہیں۔ اس [نمونہ کوڈ](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo) کو دیکھیں۔

ڈیفالٹ طور پر، یہ Hugging Face پر ماڈل آئی ڈی کے مطابق ہوتا ہے۔ تاہم، آپ اسے ایک لوکل طور پر بنائے گئے Phi-3-mini ماڈل سرور سے بھی جوڑ سکتے ہیں۔

### Quantized ماڈلز کو Ollama یا LlamaEdge کے ذریعے کال کرنا

بہت سے صارفین لوکل ماڈلز چلانے کے لیے Quantized ماڈلز کو ترجیح دیتے ہیں۔ [Ollama](https://ollama.com/) اور [LlamaEdge](https://llamaedge.com) انفرادی صارفین کو مختلف Quantized ماڈلز کو کال کرنے کی اجازت دیتے ہیں:

#### Ollama

آپ `ollama run Phi-3` کو براہ راست چلا سکتے ہیں یا اسے آف لائن کنفیگر کر سکتے ہیں `Modelfile` بناتے ہوئے، جس میں آپ کے `.gguf` فائل کا راستہ ہوگا۔

```gguf
FROM {Add your gguf file path}
TEMPLATE \"\"\"<|user|> .Prompt<|end|> <|assistant|>\"\"\"
PARAMETER stop <|end|>
PARAMETER num_ctx 4096
```

[نمونہ کوڈ](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)

#### LlamaEdge

اگر آپ `.gguf` فائلز کو بیک وقت کلاؤڈ اور ایج ڈیوائسز پر استعمال کرنا چاہتے ہیں تو LlamaEdge ایک بہترین انتخاب ہے۔ شروع کرنے کے لیے آپ اس [نمونہ کوڈ](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo) کو دیکھ سکتے ہیں۔

### اینڈرائیڈ فونز پر انسٹال کریں اور چلائیں

1. **MLC Chat ایپ ڈاؤنلوڈ کریں** (مفت) اینڈرائیڈ فونز کے لیے۔
2. APK فائل (148MB) ڈاؤنلوڈ کریں اور اپنے ڈیوائس پر انسٹال کریں۔
3. MLC Chat ایپ لانچ کریں۔ آپ کو AI ماڈلز کی ایک فہرست نظر آئے گی، جن میں Phi-3-mini بھی شامل ہے۔

خلاصہ یہ کہ، Phi-3-mini ایج ڈیوائسز پر جنریٹو AI کے لیے دلچسپ امکانات فراہم کرتا ہے، اور آپ اینڈرائیڈ پر اس کی صلاحیتوں کو دریافت کرنا شروع کر سکتے ہیں۔

**اعلانِ لاتعلقی**:  
یہ دستاویز مشین پر مبنی AI ترجمہ خدمات کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کی بھرپور کوشش کرتے ہیں، براہِ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غلط بیانی شامل ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔