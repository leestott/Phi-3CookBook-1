فی-3-منی کے سیاق و سباق میں، انفرینس کا مطلب ہے ماڈل کو استعمال کرتے ہوئے پیشگوئیاں کرنا یا ان پٹ ڈیٹا کی بنیاد پر آؤٹ پٹ پیدا کرنا۔ آئیے میں آپ کو فی-3-منی اور اس کی انفرینس صلاحیتوں کے بارے میں مزید تفصیلات فراہم کرتا ہوں۔

فی-3-منی مائیکروسافٹ کی فی-3 سیریز کے ماڈلز کا حصہ ہے۔ یہ ماڈلز چھوٹے لینگویج ماڈلز (SLMs) کے ساتھ ممکنہ امکانات کو دوبارہ متعین کرنے کے لیے ڈیزائن کیے گئے ہیں۔

یہاں فی-3-منی اور اس کی انفرینس صلاحیتوں کے بارے میں کچھ اہم نکات ہیں:

## **فی-3-منی کا جائزہ:**
- فی-3-منی کے پیرامیٹرز کا سائز 3.8 بلین ہے۔
- یہ نہ صرف روایتی کمپیوٹنگ ڈیوائسز پر چل سکتا ہے بلکہ موبائل ڈیوائسز اور آئی او ٹی ڈیوائسز جیسے ایج ڈیوائسز پر بھی چل سکتا ہے۔
- فی-3-منی کی ریلیز افراد اور اداروں کو مختلف ہارڈویئر ڈیوائسز، خاص طور پر محدود وسائل والے ماحول میں، SLMs کو تعینات کرنے کے قابل بناتی ہے۔
- یہ مختلف ماڈل فارمیٹس کا احاطہ کرتا ہے، جن میں روایتی پائی ٹورچ فارمیٹ، جی جی یو ایف فارمیٹ کا کوانٹائزڈ ورژن، اور او این این ایکس پر مبنی کوانٹائزڈ ورژن شامل ہیں۔

## **فی-3-منی تک رسائی:**
فی-3-منی تک رسائی حاصل کرنے کے لیے، آپ [سیمینٹک کرنل](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) کو کوپائلٹ ایپلیکیشن میں استعمال کر سکتے ہیں۔ سیمینٹک کرنل عام طور پر Azure OpenAI Service، Hugging Face پر اوپن سورس ماڈلز، اور لوکل ماڈلز کے ساتھ مطابقت رکھتا ہے۔  
آپ [Ollama](https://ollama.com) یا [LlamaEdge](https://llamaedge.com) کو کوانٹائزڈ ماڈلز کال کرنے کے لیے بھی استعمال کر سکتے ہیں۔ Ollama انفرادی صارفین کو مختلف کوانٹائزڈ ماڈلز کال کرنے کی اجازت دیتا ہے، جبکہ LlamaEdge GGUF ماڈلز کے لیے کراس پلیٹ فارم دستیابی فراہم کرتا ہے۔

## **کوانٹائزڈ ماڈلز:**
بہت سے صارفین لوکل انفرینس کے لیے کوانٹائزڈ ماڈلز کو ترجیح دیتے ہیں۔ مثال کے طور پر، آپ براہ راست Ollama run Phi-3 چلا سکتے ہیں یا اسے آف لائن Modelfile کا استعمال کرتے ہوئے ترتیب دے سکتے ہیں۔ Modelfile GGUF فائل کے راستے اور پرامپٹ فارمیٹ کو بیان کرتا ہے۔

## **جنریٹو اے آئی کے امکانات:**
فی-3-منی جیسے SLMs کو ملا کر جنریٹو اے آئی کے نئے امکانات کھلتے ہیں۔ انفرینس پہلا قدم ہے؛ یہ ماڈلز محدود وسائل، کم لیٹینسی، اور کم لاگت والے منظرناموں میں مختلف کاموں کے لیے استعمال کیے جا سکتے ہیں۔

## **فی-3-منی کے ساتھ جنریٹو اے آئی کو کھولنا: انفرینس اور ڈیپلائمنٹ کے لیے ایک گائیڈ**  
سیمینٹک کرنل، Ollama/LlamaEdge، اور ONNX Runtime کو استعمال کرکے فی-3-منی ماڈلز تک رسائی اور انفرینس کرنے کا طریقہ سیکھیں، اور مختلف ایپلیکیشن منظرناموں میں جنریٹو اے آئی کے امکانات کو دریافت کریں۔

**خصوصیات**  
فی-3-منی ماڈل کی انفرینس ان پلیٹ فارمز پر:

- [سیمینٹک کرنل](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo)  
- [Ollama](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)  
- [LlamaEdge WASM](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo)  
- [ONNX Runtime](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/onnx?WT.mc_id=aiml-138114-kinfeylo)  
- [iOS](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ios?WT.mc_id=aiml-138114-kinfeylo)  

مختصراً، فی-3-منی ڈویلپرز کو مختلف ماڈل فارمیٹس کو دریافت کرنے اور مختلف ایپلیکیشن منظرناموں میں جنریٹو اے آئی کا فائدہ اٹھانے کی اجازت دیتا ہے۔

**اعلانِ لاتعلقی**:  
یہ دستاویز مشین پر مبنی AI ترجمہ خدمات کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہِ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا خامیاں ہوسکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ورانہ انسانی ترجمہ تجویز کیا جاتا ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔