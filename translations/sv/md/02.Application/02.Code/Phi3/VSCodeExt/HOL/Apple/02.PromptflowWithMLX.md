# **Lab 2 - Kör Prompt flow med Phi-3-mini i AIPC**

## **Vad är Prompt flow**

Prompt flow är en uppsättning utvecklingsverktyg som är utformade för att förenkla hela utvecklingscykeln för AI-applikationer baserade på LLM, från idé och prototyp till testning, utvärdering, produktionsdrift och övervakning. Det gör prompt engineering mycket enklare och låter dig bygga LLM-appar med produktionskvalitet.

Med Prompt flow kan du:

- Skapa flöden som kopplar samman LLM:er, prompts, Python-kod och andra verktyg i en körbar arbetsprocess.

- Debugga och iterera dina flöden, särskilt interaktionen med LLM:er, på ett smidigt sätt.

- Utvärdera dina flöden och beräkna kvalitets- och prestandamått med större dataset.

- Integrera testning och utvärdering i ditt CI/CD-system för att säkerställa kvaliteten på ditt flöde.

- Distribuera dina flöden till den tjänsteplattform du väljer eller integrera dem enkelt i din apps kodbas.

- (Valfritt men starkt rekommenderat) Samarbeta med ditt team genom att använda molnversionen av Prompt flow i Azure AI.



## **Bygga kodgenereringsflöden på Apple Silicon**

***Notera***: Om du inte har slutfört miljöinstallationen, besök [Lab 0 - Installations](./01.Installations.md)

1. Öppna Prompt flow-tillägget i Visual Studio Code och skapa ett tomt flödessprojekt.

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.sv.png)

2. Lägg till indata- och utdataparametrar och lägg till Python-kod som ett nytt flöde.

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.sv.png)

Du kan hänvisa till denna struktur (flow.dag.yaml) för att konstruera ditt flöde.

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. Kvantifiera phi-3-mini

Vi strävar efter att bättre köra SLM på lokala enheter. Vanligtvis kvantifierar vi modellen (INT4, FP16, FP32).

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**Notera:** standardmappen är mlx_model 

4. Lägg till kod i ***Chat_With_Phi3.py***

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. Du kan testa flödet genom att debugga eller köra det för att kontrollera om kodgenereringen fungerar korrekt.

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.sv.png)

5. Kör flödet som en utvecklings-API i terminalen.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Du kan testa det i Postman / Thunder Client.


### **Notera**

1. Den första körningen tar lång tid. Det rekommenderas att ladda ner phi-3-modellen från Hugging Face CLI.

2. Med tanke på den begränsade beräkningskraften hos Intel NPU rekommenderas det att använda Phi-3-mini-4k-instruct.

3. Vi använder Intel NPU Acceleration för att kvantifiera INT4-konvertering, men om du kör tjänsten igen måste du ta bort cache- och nc_workshop-mapparna.



## **Resurser**

1. Lär dig Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Lär dig Intel NPU Acceleration [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Exempelkod, ladda ner [Local NPU Agent Sample Code](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**Ansvarsfriskrivning**:  
Detta dokument har översatts med hjälp av maskinbaserade AI-översättningstjänster. Även om vi strävar efter noggrannhet, bör du vara medveten om att automatiska översättningar kan innehålla fel eller felaktigheter. Det ursprungliga dokumentet på dess originalspråk bör betraktas som den auktoritativa källan. För kritisk information rekommenderas professionell mänsklig översättning. Vi ansvarar inte för eventuella missförstånd eller feltolkningar som uppstår vid användning av denna översättning.