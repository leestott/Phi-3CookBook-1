**Finjustering av Phi-3 med QLoRA**

Finjustering av Microsofts Phi-3 Mini-språkmodell med hjälp av [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA kommer att hjälpa till att förbättra förståelsen av samtal och genereringen av svar.

För att ladda modeller i 4 bitar med transformers och bitsandbytes behöver du installera accelerate och transformers från källkod och se till att du har den senaste versionen av bitsandbytes-biblioteket.

**Exempel**
- [Lär dig mer med detta exempelblock](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Exempel på Python FineTuning](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Exempel på finjustering med Hugging Face Hub och LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Exempel på finjustering med Hugging Face Hub och QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**Ansvarsfriskrivning**:  
Detta dokument har översatts med hjälp av maskinbaserade AI-översättningstjänster. Även om vi strävar efter noggrannhet, bör det noteras att automatiserade översättningar kan innehålla fel eller felaktigheter. Det ursprungliga dokumentet på dess originalspråk bör betraktas som den auktoritativa källan. För kritisk information rekommenderas professionell mänsklig översättning. Vi tar inget ansvar för eventuella missförstånd eller feltolkningar som uppstår vid användning av denna översättning.