# **Använda Phi-familjen i Hugging Face**

[Hugging Face](https://huggingface.co/) är en mycket populär AI-gemenskap med rik data och resurser för öppen källkod. Olika tillverkare släpper öppna LLM- och SLM-modeller via Hugging Face, som Microsoft, Meta, Mistral, Apple, Google, etc.

Microsofts Phi-familj har släppts på Hugging Face. Utvecklare kan ladda ner motsvarande modell från Phi-familjen baserat på scenarier och verksamhetsbehov. Förutom att distribuera Phi Pytorch-modeller på Hugging Face har vi också släppt kvantiserade modeller, med formaten GGUF och ONNX för att ge slutanvändare fler valmöjligheter.

## **Ladda ner modeller på Hugging Face**

Du kan ladda ner Phi-familjens modeller via denna länk:

-  **Phi-1 / 1.5** https://huggingface.co/collections/microsoft/phi-1-6626e29134744e94e222d572

-  **Phi-3 / 3.5** https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3

-  **Phi-4** https://huggingface.co/collections/microsoft/phi-4-677e9380e514feb5577a40e4

Du kan ladda ner modeller på olika sätt, till exempel genom att installera ***Hugging Face CLI SDK*** eller använda ***git clone***.

### **Använda Hugging Face CLI för att ladda ner Phi-familjens modeller**

- Installera Hugging Face CLI

```bash

pip install -U "huggingface_hub[cli]"

```

- Logga in med huggingface-cli

Logga in på Hugging Face med en [User Access Token](https://huggingface.co/docs/hub/security-tokens) från din [inställningssida](https://huggingface.co/settings/tokens).

```bash

huggingface-cli login --token $HF_TOKEN --add-to-git-credential

```

- Ladda ner

Du kan ladda ner en modell och spara den i cacheminnet.

```bash

huggingface-cli download microsoft/phi-4

```

Du kan också ange en specifik plats för nedladdningen.

```bash

huggingface-cli download microsoft/phi-4 --local-dir $YOUR_PATH

```

### **Använda git clone för att ladda ner Phi-familjens modeller**

Du kan också använda ***git clone*** för att ladda ner modeller.

```bash

git lfs install

git clone https://huggingface.co/microsoft/phi-4

```

## **Exempel - Inference med Microsoft Phi-4**

- **Installera transformers-biblioteket**

```bash

pip install transformers -U

```

- **Kör koden i VSCode**

```python

import transformers

pipeline = transformers.pipeline(
    "text-generation",
    model="microsoft/phi-4",
    model_kwargs={"torch_dtype": "auto"},
    device_map="auto",
)

messages = [
    {"role": "user", "content": "I have $20,000 in my savings account, where I receive a 4% profit per year and payments twice a year. Can you please tell me how long it will take for me to become a millionaire? Also, can you please explain the math step by step as if you were explaining it to an uneducated person?"},
]

outputs = pipeline(messages, max_new_tokens=2048)
print(outputs[0]["generated_text"][-1])

```

**Ansvarsfriskrivning**:  
Detta dokument har översatts med hjälp av maskinbaserade AI-översättningstjänster. Även om vi strävar efter noggrannhet, vänligen notera att automatiserade översättningar kan innehålla fel eller brister. Det ursprungliga dokumentet på dess ursprungsspråk bör betraktas som den auktoritativa källan. För kritisk information rekommenderas professionell human översättning. Vi ansvarar inte för eventuella missförstånd eller feltolkningar som uppstår vid användning av denna översättning.