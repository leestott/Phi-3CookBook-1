**Тонкая настройка Phi-3 с использованием QLoRA**

Тонкая настройка языковой модели Microsoft Phi-3 Mini с использованием [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA поможет улучшить понимание диалогов и генерацию ответов.

Чтобы загружать модели в 4-битном формате с помощью transformers и bitsandbytes, необходимо установить accelerate и transformers из исходного кода, а также убедиться, что у вас установлена последняя версия библиотеки bitsandbytes.

**Примеры**
- [Узнайте больше с этим примером в блокноте](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Пример настройки на Python](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Пример тонкой настройки на Hugging Face Hub с использованием LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Пример тонкой настройки на Hugging Face Hub с использованием QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**Отказ от ответственности**:  
Этот документ был переведен с использованием автоматических сервисов машинного перевода на основе искусственного интеллекта. Несмотря на наши усилия обеспечить точность, имейте в виду, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для критически важной информации рекомендуется использовать профессиональный перевод, выполненный человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.