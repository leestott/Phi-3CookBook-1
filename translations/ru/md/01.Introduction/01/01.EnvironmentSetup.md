# Начало работы с Phi-3 локально

Это руководство поможет вам настроить локальную среду для запуска модели Phi-3 с использованием Ollama. Вы можете запускать модель несколькими способами, включая GitHub Codespaces, контейнеры разработки VS Code или вашу локальную среду.

## Настройка среды

### GitHub Codespaces

Вы можете запустить этот шаблон виртуально, используя GitHub Codespaces. Кнопка откроет веб-версию VS Code в вашем браузере:

1. Откройте шаблон (это может занять несколько минут):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Откройте окно терминала.

### Контейнеры разработки VS Code

⚠️ Этот вариант будет работать только в том случае, если для Docker Desktop выделено не менее 16 ГБ оперативной памяти. Если у вас меньше 16 ГБ оперативной памяти, вы можете попробовать [вариант с GitHub Codespaces](../../../../../md/01.Introduction/01) или [настроить локально](../../../../../md/01.Introduction/01).

Альтернативный вариант — использование контейнеров разработки VS Code, которые откроют проект в вашем локальном VS Code с помощью [расширения Dev Containers](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Запустите Docker Desktop (установите его, если он еще не установлен).
2. Откройте проект:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. В открывшемся окне VS Code, как только появятся файлы проекта (это может занять несколько минут), откройте окно терминала.
4. Продолжите с [шагов развертывания](../../../../../md/01.Introduction/01).

### Локальная среда

1. Убедитесь, что установлены следующие инструменты:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Тестирование модели

1. Попросите Ollama загрузить и запустить модель phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Это займет несколько минут для загрузки модели.

2. Как только в выводе появится "success", вы сможете отправить сообщение этой модели из терминала.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Через несколько секунд вы должны увидеть поток ответа от модели.

4. Чтобы узнать о различных техниках, используемых с языковыми моделями, откройте Python-ноутбук [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) и выполните каждую ячейку. Если вы использовали модель, отличную от 'phi3:mini', измените `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` в верхней части файла по мере необходимости, а также можете модифицировать системное сообщение или добавить примеры few-shot, если это требуется.

**Отказ от ответственности**:  
Этот документ был переведен с использованием автоматических сервисов перевода на основе ИИ. Хотя мы стремимся к точности, имейте в виду, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за недоразумения или неправильные интерпретации, возникшие в результате использования данного перевода.