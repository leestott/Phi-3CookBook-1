# کلیدی ټیکنالوژۍ چې ذکر شوې دي

1. [DirectML](https://learn.microsoft.com/windows/ai/directml/dml?WT.mc_id=aiml-138114-kinfeylo) - یو ټیټ کچې API چې د ماشین زده کړې لپاره د DirectX 12 په سر جوړ شوی، د هارډویر ګړندیتوب چمتو کوي.
2. [CUDA](https://blogs.nvidia.com/blog/what-is-cuda-2/) - د موازي کمپیوټینګ پلیټفارم او API ماډل چې د Nvidia لخوا جوړ شوی، د ګرافیک پروسس کولو واحدونو (GPUs) لپاره عمومي موخې پروسس کولو ته وړتیا ورکوي.
3. [ONNX](https://onnx.ai/) (Open Neural Network Exchange) - یو خلاص فورمټ چې د ماشین زده کړې ماډلونه استازیتوب کوي او د مختلف ML چوکاټونو ترمنځ همغږي چمتو کوي.
4. [GGUF](https://github.com/ggerganov/ggml/blob/master/docs/gguf.md) (Generic Graph Update Format) - یو فورمټ چې د ماشین زده کړې ماډلونو استازیتوب او تازه کولو لپاره کارول کیږي، په ځانګړي توګه د کوچنیو ژبنیو ماډلونو لپاره چې په CPU کې د 4-8bit کوانټیزیشن سره اغېزمن کار کوي.

## DirectML

DirectML یو ټیټ کچې API دی چې د هارډویر ګړندیتوب ماشین زده کړه چمتو کوي. دا د DirectX 12 په سر جوړ شوی ترڅو د GPU ګړندیتوب څخه ګټه واخلي او د پلورونکي څخه خپلواک دی، یعنې دا د مختلف GPU پلورونکو ترمنځ د کار کولو لپاره د کوډ بدلون ته اړتیا نلري. دا په عمده توګه د ماډل روزنې او inferencing لپاره په GPUs کې کارول کیږي.

د هارډویر ملاتړ په اړه، DirectML د GPUs پراخه لړۍ سره کار کولو لپاره ډیزاین شوی، په شمول د AMD مدغم او جلا GPUs، Intel مدغم GPUs، او NVIDIA جلا GPUs. دا د Windows AI Platform برخه ده او په Windows 10 او 11 کې ملاتړ کیږي، چې په هر Windows وسیله کې د ماډل روزنې او inferencing ته اجازه ورکوي.

د DirectML اړوند تازه معلومات او فرصتونه شتون لري، لکه د 150 ONNX اپریټرانو ملاتړ کول او د ONNX runtime او WinML لخوا کارول کېدل. دا د لویو Integrated Hardware Vendors (IHVs) لخوا ملاتړ کیږي، چې هر یو یې بیلابیل میټاکمانډونه پلي کړي دي.

## CUDA

CUDA، چې د Compute Unified Device Architecture لپاره ولاړه ده، د موازي کمپیوټینګ پلیټفارم او API ماډل دی چې د Nvidia لخوا جوړ شوی. دا سافټویر پراختیا ورکوونکو ته اجازه ورکوي چې د CUDA وړتیا لرونکي ګرافیک پروسس کولو واحد (GPU) د عمومي موخې پروسس کولو لپاره وکاروي – یو چلند چې GPGPU (د ګرافیک پروسس کولو واحدونو کې عمومي موخې کمپیوټینګ) په نوم یادیږي. CUDA د Nvidia د GPU ګړندیتوب یو مهم فعالونکی دی او په مختلفو برخو کې پراخه کارول کیږي، په شمول د ماشین زده کړې، علمي کمپیوټینګ، او ویډیو پروسس کولو.

د CUDA لپاره د هارډویر ملاتړ د Nvidia GPUs ته ځانګړی دی، ځکه چې دا د Nvidia لخوا جوړ شوی خصوصي ټیکنالوژي ده. هره معمار د CUDA ټول کټ ځانګړي نسخې ملاتړ کوي، چې پراختیا ورکوونکو ته اړین کتابتونونه او وسایل چمتو کوي ترڅو د CUDA غوښتنلیکونه جوړ او پرمخ بوځي.

## ONNX

ONNX (Open Neural Network Exchange) یو خلاص فورمټ دی چې د ماشین زده کړې ماډلونه استازیتوب کوي. دا د پراخېدونکي محاسبې ګراف ماډل تعریف چمتو کوي، د جوړ شوي اپریټرانو او معیاري ډیټا ډولونو تعریفونو سره. ONNX پراختیا ورکوونکو ته اجازه ورکوي چې ماډلونه د مختلف ML چوکاټونو ترمنځ حرکت ورکړي، د همغږۍ وړتیا چمتو کوي او د AI غوښتنلیکونو جوړول او ځای پرځای کول اسانه کوي.

Phi3 mini کولی شي د ONNX Runtime سره په CPU او GPU کې د وسیلو په اوږدو کې کار وکړي، په شمول د سرور پلیټفارمونه، Windows، Linux او Mac ډیسټاپونه، او ګرځنده CPUs.
موږ لاندې مطلوب تنظیمات اضافه کړي دي:

- د int4 DML لپاره ONNX ماډلونه: د AWQ له لارې کوانټیز شوي
- د fp16 CUDA لپاره ONNX ماډل
- د int4 CUDA لپاره ONNX ماډل: د RTN له لارې کوانټیز شوي
- د int4 CPU او Mobile لپاره ONNX ماډل: د RTN له لارې کوانټیز شوي

## Llama.cpp

Llama.cpp یو خلاصې سرچینې سافټویر کتابتون دی چې په C++ کې لیکل شوی. دا د مختلفو لویو ژبنیو ماډلونو (LLMs)، په شمول د Llama، په اړه inferencing ترسره کوي. دا د ggml کتابتون (یو عمومي موخې ټینسر کتابتون) سره یوځای جوړ شوی، Llama.cpp موخه لري چې د اصلي Python پلي کولو په پرتله ګړندۍ inferencing او ټیټه حافظه مصرف چمتو کړي. دا د هارډویر اصلاحات، کوانټیزیشن ملاتړ کوي او یو ساده API او بیلګې وړاندې کوي. که تاسو د اغیزمن LLM inferencing سره علاقه لرئ، Llama.cpp د سپړلو ارزښت لري ځکه چې Phi3 کولی شي Llama.cpp پرمخ بوځي.

## GGUF

GGUF (Generic Graph Update Format) یو فورمټ دی چې د ماشین زده کړې ماډلونو استازیتوب او تازه کولو لپاره کارول کیږي. دا په ځانګړي توګه د کوچنیو ژبنیو ماډلونو (SLMs) لپاره ګټور دی چې په CPUs کې د 4-8bit کوانټیزیشن سره اغیزمن کار کوي. GGUF د چټک پروټوټایپ کولو او د ماډلونو د ځای پرځای کولو لپاره ګټور دی، لکه د CI/CD پایپ لاینونو کې د ډله ایزو دندو لپاره.

It seems like "mo" could refer to a specific language or shorthand, but it's unclear which language you're referring to. Could you clarify what "mo" stands for? For example, is it Maori, Mongolian, or something else? Let me know so I can assist you accurately!