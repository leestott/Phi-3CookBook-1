**Phi-3 ကို QLoRA ဖြင့် Fine-tuning ပြုလုပ်ခြင်း**

Microsoft ၏ Phi-3 Mini ဘာသာစကားမော်ဒယ်ကို [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora) ကို အသုံးပြု၍ Fine-tuning ပြုလုပ်ခြင်း။

QLoRA သည် စကားပြောနားလည်မှုနှင့် အဖြေထုတ်ပေးမှုကို တိုးတက်စေရန် ကူညီပေးပါမည်။

transformers နှင့် bitsandbytes ကို အသုံးပြု၍ မော်ဒယ်များကို 4bits ဖြင့် Load လုပ်ရန် accelerate နှင့် transformers ကို source မှ ထည့်သွင်းရမည်ဖြစ်ပြီး bitsandbytes စာကြည့်တိုက်၏ နောက်ဆုံးဗားရှင်းရှိရန် သေချာစေရန် လိုအပ်ပါသည်။

**နမူနာများ**
- [ဤနမူနာ notebook ဖြင့် ပိုမိုလေ့လာရန်](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python FineTuning နမူနာ၏ ဥပမာ](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Hugging Face Hub တွင် LORA ဖြင့် Fine Tuning ဥပမာ](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Hugging Face Hub တွင် QLORA ဖြင့် Fine Tuning ဥပမာ](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

It seems like "mo" might refer to a specific language or abbreviation. Could you please clarify which language you mean by "mo"? For example, are you referring to Maori, Mongolian, or something else? Let me know so I can assist you accurately!