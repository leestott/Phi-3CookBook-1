# Phi-3 をローカルで始める

このガイドでは、Ollama を使用して Phi-3 モデルをローカル環境で実行するためのセットアップ手順を説明します。モデルを実行する方法はいくつかあり、GitHub Codespaces、VS Code Dev Containers、またはローカル環境を使用できます。

## 環境セットアップ

### GitHub Codespaces

GitHub Codespaces を使用すると、このテンプレートを仮想的に実行できます。このボタンをクリックすると、ブラウザ内で Web ベースの VS Code インスタンスが開きます:

1. テンプレートを開きます（数分かかる場合があります）:

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. ターミナルウィンドウを開きます

### VS Code Dev Containers

⚠️ このオプションを使用するには、Docker Desktop に少なくとも 16 GB の RAM が割り当てられている必要があります。16 GB 未満の場合は、[GitHub Codespaces オプション](../../../../../md/01.Introduction/01)を試すか、[ローカルでセットアップ](../../../../../md/01.Introduction/01)してください。

関連するオプションとして、VS Code Dev Containers を使用すると、[Dev Containers 拡張機能](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)を利用してローカルの VS Code でプロジェクトを開くことができます:

1. Docker Desktop を起動します（未インストールの場合はインストールしてください）
2. プロジェクトを開きます:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. 開いた VS Code ウィンドウで、プロジェクトファイルが表示されたら（数分かかる場合があります）、ターミナルウィンドウを開きます。
4. [デプロイ手順](../../../../../md/01.Introduction/01)に進みます

### ローカル環境

1. 以下のツールがインストールされていることを確認してください:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## モデルのテスト

1. Ollama に phi3:mini モデルをダウンロードして実行するよう依頼します:

    ```shell
    ollama run phi3:mini
    ```

    モデルのダウンロードには数分かかります。

2. 出力に「success」と表示されたら、プロンプトからそのモデルにメッセージを送信できます。

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. 数秒後、モデルからの応答がストリームとして表示されるはずです。

4. 言語モデルで使用されるさまざまな技術について学ぶには、Python ノートブック [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) を開き、各セルを実行してください。'phi3:mini' 以外のモデルを使用した場合は、ファイルの冒頭で `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` を必要に応じて変更できます。また、システムメッセージを修正したり、few-shot の例を追加することも可能です。

**免責事項**:  
本書類は、機械翻訳AIサービスを使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確さが含まれる場合があります。元の言語で作成された原文が正式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用に起因する誤解や解釈の相違について、当方は一切の責任を負いかねます。