### Guidance-AI and Phi Models as a Service (MaaS)
We are integrating [Guidance](https://github.com/guidance-ai/guidance) with the Phi-3.5-mini serverless endpoint offering in Azure AI Foundry to enhance output predictability by defining structures tailored to specific applications. With Guidance, you can avoid costly retries and, for example, constrain the model to select from predefined lists (e.g., medical codes), limit outputs to direct quotes from a given context, or adhere to a specific regex. Guidance directs the model token by token during the inference process, reducing cost and latency by 30-50%, making it a distinctive and valuable addition to the [Phi-3-mini serverless endpoint](https://aka.ms/try-phi3.5mini).

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) is a framework designed to assist developers in efficiently creating and deploying AI models. It provides tools and best practices for building robust AI applications.

When paired with **Phi Models as a Service (MaaS)**, it becomes a powerful solution for deploying small language models (SLMs) that balance cost-effectiveness with high performance.

**Guidance-AI** is a programming framework created to help developers better control and direct large language models (LLMs). It enables precise output structuring, reducing latency and costs compared to traditional prompting or fine-tuning approaches.

### Key Features of Guidance-AI:
- **Efficient Control**: Allows developers to manage how the language model generates text, ensuring outputs are high-quality and relevant.
- **Cost and Latency Reduction**: Optimizes the generation process for greater cost efficiency and speed.
- **Flexible Integration**: Compatible with various backends, including Transformers, llama.cpp, AzureAI, VertexAI, and OpenAI.
- **Rich Output Structures**: Supports advanced output structures like conditionals, loops, and tool use, simplifying the generation of clear and parseable results.
- **Compatibility**: A single Guidance program can run on multiple backends, offering flexibility and convenience.

### Example Use Cases:
- **Constrained Generation**: Using regular expressions and context-free grammars to guide the model's output.
- **Tool Integration**: Seamlessly combining control and generation, such as incorporating a calculator into a text generation task.

For more detailed information and examples, visit the [Guidance-AI GitHub repository](https://github.com/guidance-ai/guidance).

[Check out the Phi-3.5 Sample](../../../../../code/01.Introduce/guidance.ipynb)

### Key Features of Phi Models:
1. **Cost-Effective**: Designed to be budget-friendly while delivering high performance.
2. **Low Latency**: Perfect for real-time applications that demand quick responses.
3. **Flexibility**: Deployable in various environments, including cloud, edge, and offline scenarios.
4. **Customization**: Can be fine-tuned with domain-specific data for improved performance.
5. **Security and Compliance**: Built in alignment with Microsoft's AI principles, ensuring accountability, transparency, fairness, reliability, safety, privacy, and inclusiveness.

### Phi Models as a Service (MaaS):
Phi models are available via a pay-as-you-go billing model through inference APIs, enabling seamless integration into your applications without substantial upfront investments.

### Getting Started with Phi-3:
To begin using Phi models, explore the [Azure AI model catalog](https://ai.azure.com/explore/models) or the [GitHub Marketplace Models](https://github.com/marketplace/models), which offer prebuilt and customizable models. You can also leverage tools like [Azure AI Foundry](https://ai.azure.com) to develop and deploy your AI applications.

### Resources
[Sample Notebook on getting started with Guidance](../../../../../code/01.Introduce/guidance.ipynb)

**Disclaimer**:  
This document has been translated using machine-based AI translation services. While we strive for accuracy, please be aware that automated translations may contain errors or inaccuracies. The original document in its native language should be considered the authoritative source. For critical information, professional human translation is recommended. We are not liable for any misunderstandings or misinterpretations arising from the use of this translation.