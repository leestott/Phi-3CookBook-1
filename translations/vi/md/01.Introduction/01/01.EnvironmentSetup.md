# Bắt đầu với Phi-3 trên máy cục bộ

Hướng dẫn này sẽ giúp bạn thiết lập môi trường cục bộ để chạy mô hình Phi-3 bằng Ollama. Bạn có thể chạy mô hình theo một số cách khác nhau, bao gồm sử dụng GitHub Codespaces, VS Code Dev Containers hoặc môi trường cục bộ của bạn.

## Thiết lập môi trường

### GitHub Codespaces

Bạn có thể chạy mẫu này trực tuyến bằng cách sử dụng GitHub Codespaces. Nút dưới đây sẽ mở một phiên bản VS Code dựa trên trình duyệt:

1. Mở mẫu (quá trình này có thể mất vài phút):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Mở cửa sổ terminal.

### VS Code Dev Containers

⚠️ Tùy chọn này chỉ hoạt động nếu Docker Desktop của bạn được phân bổ ít nhất 16 GB RAM. Nếu bạn có ít hơn 16 GB RAM, bạn có thể thử [GitHub Codespaces](../../../../../md/01.Introduction/01) hoặc [thiết lập cục bộ](../../../../../md/01.Introduction/01).

Một tùy chọn liên quan là VS Code Dev Containers, cho phép mở dự án trong VS Code cục bộ của bạn bằng cách sử dụng [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Khởi động Docker Desktop (cài đặt nếu chưa có).
2. Mở dự án:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Trong cửa sổ VS Code được mở, sau khi các tệp dự án xuất hiện (có thể mất vài phút), mở một cửa sổ terminal.
4. Tiếp tục với các [bước triển khai](../../../../../md/01.Introduction/01).

### Môi trường cục bộ

1. Đảm bảo các công cụ sau được cài đặt:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Kiểm tra mô hình

1. Yêu cầu Ollama tải xuống và chạy mô hình phi3:mini:

    ```shell
    ollama run phi3:mini
    ```

    Quá trình này sẽ mất vài phút để tải mô hình.

2. Khi bạn thấy "success" trong đầu ra, bạn có thể gửi một tin nhắn đến mô hình từ dòng lệnh.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Sau vài giây, bạn sẽ thấy một phản hồi từ mô hình được truyền về.

4. Để tìm hiểu về các kỹ thuật khác nhau được sử dụng với các mô hình ngôn ngữ, mở tệp notebook Python [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) và chạy từng cell. Nếu bạn sử dụng một mô hình khác ngoài 'phi3:mini', hãy thay đổi `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` ở đầu tệp nếu cần, và bạn cũng có thể chỉnh sửa thông điệp hệ thống hoặc thêm ví dụ few-shot nếu muốn.

**Tuyên bố miễn trừ trách nhiệm**:  
Tài liệu này đã được dịch bằng các dịch vụ dịch thuật AI tự động. Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn đáng tin cậy nhất. Đối với thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm về bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.