# Paano Magsimula sa Phi-3 nang Lokal

Ang gabay na ito ay tutulong sa iyo na i-set up ang iyong lokal na environment upang magpatakbo ng Phi-3 model gamit ang Ollama. Maaari mong patakbuhin ang model sa iba't ibang paraan, kabilang ang paggamit ng GitHub Codespaces, VS Code Dev Containers, o ang iyong lokal na environment.

## Pag-set up ng Environment

### GitHub Codespaces

Maaari mong patakbuhin ang template na ito nang virtual gamit ang GitHub Codespaces. Ang button ay magbubukas ng web-based na VS Code instance sa iyong browser:

1. Buksan ang template (maaari itong tumagal ng ilang minuto):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Buksan ang terminal window

### VS Code Dev Containers

⚠️ Gagana lang ang opsyong ito kung ang iyong Docker Desktop ay may nakalaang hindi bababa sa 16 GB ng RAM. Kung mas mababa sa 16 GB ang iyong RAM, maaari mong subukan ang [GitHub Codespaces na opsyon](../../../../../md/01.Introduction/01) o [i-set up ito nang lokal](../../../../../md/01.Introduction/01).

Ang isa pang opsyon ay ang VS Code Dev Containers, na magbubukas ng proyekto sa iyong lokal na VS Code gamit ang [Dev Containers extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. I-start ang Docker Desktop (i-install ito kung hindi pa naka-install)
2. Buksan ang proyekto:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. Sa VS Code window na magbubukas, kapag lumitaw na ang mga file ng proyekto (maaari itong tumagal ng ilang minuto), buksan ang terminal window.
4. Ipagpatuloy ang [mga hakbang sa deployment](../../../../../md/01.Introduction/01)

### Lokal na Environment

1. Siguraduhing naka-install ang mga sumusunod na tools:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Subukan ang Model

1. Utusan ang Ollama na i-download at patakbuhin ang phi3:mini model:

    ```shell
    ollama run phi3:mini
    ```

    Aabutin ito ng ilang minuto upang ma-download ang model.

2. Kapag nakita mo na ang "success" sa output, maaari kang magpadala ng mensahe sa model mula sa prompt.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Pagkalipas ng ilang segundo, dapat kang makakita ng tugon mula sa model.

4. Upang matutunan ang iba't ibang teknik na ginagamit sa mga language model, buksan ang Python notebook [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) at patakbuhin ang bawat cell. Kung gumamit ka ng model na iba sa 'phi3:mini', baguhin ang `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` sa itaas ng file kung kinakailangan. Maaari mo ring baguhin ang system message o magdagdag ng mga halimbawa ng few-shot kung nais.

**Paunawa**:  
Ang dokumentong ito ay isinalin gamit ang mga serbisyong AI na nakabatay sa makina. Bagama't sinisikap naming maging tumpak, pakitandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi pagiging wasto. Ang orihinal na dokumento sa sariling wika nito ang dapat ituring na mapagkakatiwalaang pinagmulan. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaintindihan o maling interpretasyon na dulot ng paggamit ng pagsasaling ito.