**Fine-tuning Phi-3 cu QLoRA**

Fine-tuning al modelului lingvistic Phi-3 Mini de la Microsoft folosind [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA va ajuta la îmbunătățirea înțelegerii conversaționale și a generării de răspunsuri.

Pentru a încărca modele în 4 biți folosind transformers și bitsandbytes, trebuie să instalați accelerate și transformers din sursă și să vă asigurați că aveți cea mai recentă versiune a bibliotecii bitsandbytes.

**Exemple**
- [Aflați mai multe cu acest notebook de exemplu](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Exemplu de FineTuning în Python](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Exemplu de Fine Tuning pe Hugging Face Hub cu LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Exemplu de Fine Tuning pe Hugging Face Hub cu QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind servicii de traducere automate bazate pe inteligență artificială. Deși depunem eforturi pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original, în limba sa maternă, ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă o traducere profesională realizată de un specialist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea în urma utilizării acestei traduceri.