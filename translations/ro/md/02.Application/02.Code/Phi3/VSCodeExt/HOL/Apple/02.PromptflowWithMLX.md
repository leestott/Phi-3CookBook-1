# **Lab 2 - Rulează Prompt flow cu Phi-3-mini în AIPC**

## **Ce este Prompt flow**

Prompt flow este un set de instrumente de dezvoltare concepute pentru a simplifica ciclul complet de dezvoltare al aplicațiilor AI bazate pe LLM, de la ideare, prototipare, testare, evaluare, până la implementarea în producție și monitorizare. Acesta facilitează ingineria prompturilor și îți permite să construiești aplicații LLM de calitate pentru producție.

Cu Prompt flow, vei putea:

- Crea fluxuri care conectează LLM-uri, prompturi, cod Python și alte instrumente într-un flux de lucru executabil.

- Depana și itera fluxurile tale, în special interacțiunile cu LLM-uri, cu ușurință.

- Evalua fluxurile tale, calcula metrici de calitate și performanță folosind seturi de date mai mari.

- Integra testarea și evaluarea în sistemul tău CI/CD pentru a asigura calitatea fluxului.

- Implementa fluxurile pe platforma de servire aleasă sau le poți integra ușor în baza de cod a aplicației tale.

- (Opțional, dar foarte recomandat) Colabora cu echipa ta utilizând versiunea cloud a Prompt flow în Azure AI.



## **Construirea fluxurilor de generare a codului pe Apple Silicon**

***Notă*** ：Dacă nu ai finalizat instalarea mediului, te rugăm să vizitezi [Lab 0 -Instalări](./01.Installations.md)

1. Deschide extensia Prompt flow în Visual Studio Code și creează un proiect de flux gol.

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.ro.png)

2. Adaugă parametrii de Intrare și Ieșire și adaugă cod Python ca un nou flux.

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.ro.png)

Poți consulta această structură (flow.dag.yaml) pentru a construi fluxul tău:

```yaml

inputs:
  prompt:
    type: string
    default: Write python code for Fibonacci serie. Please use markdown as output
outputs:
  result:
    type: string
    reference: ${gen_code_by_phi3.output}
nodes:
- name: gen_code_by_phi3
  type: python
  source:
    type: code
    path: gen_code_by_phi3.py
  inputs:
    prompt: ${inputs.prompt}


```

3. Cuantifică phi-3-mini

Ne dorim să rulăm mai bine SLM pe dispozitive locale. În general, cuantificăm modelul (INT4, FP16, FP32).

```bash

python -m mlx_lm.convert --hf-path microsoft/Phi-3-mini-4k-instruct

```

**Notă:** folderul implicit este mlx_model.

4. Adaugă cod în ***Chat_With_Phi3.py***.

```python


from promptflow import tool

from mlx_lm import load, generate


# The inputs section will change based on the arguments of the tool function, after you save the code
# Adding type to arguments and return value will help the system show the types properly
# Please update the function name/signature per need
@tool
def my_python_tool(prompt: str) -> str:

    model_id = './mlx_model_phi3_mini'

    model, tokenizer = load(model_id)

    # <|user|>\nWrite python code for Fibonacci serie. Please use markdown as output<|end|>\n<|assistant|>

    response = generate(model, tokenizer, prompt="<|user|>\n" + prompt  + "<|end|>\n<|assistant|>", max_tokens=2048, verbose=True)

    return response


```

4. Poți testa fluxul din Debug sau Run pentru a verifica dacă generarea codului funcționează corect.

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.ro.png)

5. Rulează fluxul ca API de dezvoltare în terminal.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Poți să-l testezi în Postman / Thunder Client.


### **Notă**

1. Prima rulare durează mult timp. Este recomandat să descarci modelul phi-3 de pe Hugging Face CLI.

2. Având în vedere puterea de calcul limitată a NPU-urilor Intel, este recomandat să folosești Phi-3-mini-4k-instruct.

3. Folosim Intel NPU Acceleration pentru conversia cuantificată INT4, dar dacă re-rulezi serviciul, trebuie să ștergi folderele cache și nc_workshop.



## **Resurse**

1. Învață Promptflow [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Învață Intel NPU Acceleration [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Cod exemplu, descarcă [Cod exemplu Local NPU Agent](../../../../../../../../../code/07.Lab/01/AIPC/local-npu-agent)

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind servicii de traducere automată bazate pe inteligență artificială. Deși ne străduim să asigurăm acuratețea, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original, în limba sa nativă, ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea realizată de un profesionist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.