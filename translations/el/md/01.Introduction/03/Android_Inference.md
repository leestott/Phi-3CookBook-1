# **Υλοποίηση του Phi-3 σε Android**

Ας δούμε πώς μπορείτε να εκτελέσετε inference με το Phi-3-mini σε συσκευές Android. Το Phi-3-mini είναι μια νέα σειρά μοντέλων της Microsoft που επιτρέπει την ανάπτυξη Μεγάλων Γλωσσικών Μοντέλων (LLMs) σε συσκευές edge και IoT.

## Semantic Kernel και Υλοποίηση

[Semantic Kernel](https://github.com/microsoft/semantic-kernel) είναι ένα πλαίσιο εφαρμογών που σας επιτρέπει να δημιουργείτε εφαρμογές συμβατές με το Azure OpenAI Service, τα μοντέλα OpenAI και ακόμη και τοπικά μοντέλα. Αν είστε νέοι στο Semantic Kernel, προτείνουμε να ρίξετε μια ματιά στο [Semantic Kernel Cookbook](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo).

### Πρόσβαση στο Phi-3-mini μέσω του Semantic Kernel

Μπορείτε να το συνδυάσετε με το Hugging Face Connector στο Semantic Kernel. Ανατρέξτε σε αυτόν τον [Κώδικα Παράδειγματος](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo).

Από προεπιλογή, αντιστοιχεί στο ID του μοντέλου στο Hugging Face. Ωστόσο, μπορείτε επίσης να συνδεθείτε σε έναν τοπικό server μοντέλου Phi-3-mini.

### Κλήση Κβαντισμένων Μοντέλων με Ollama ή LlamaEdge

Πολλοί χρήστες προτιμούν τη χρήση κβαντισμένων μοντέλων για τοπική εκτέλεση. Το [Ollama](https://ollama.com/) και το [LlamaEdge](https://llamaedge.com) επιτρέπουν στους χρήστες να καλούν διάφορα κβαντισμένα μοντέλα:

#### Ollama

Μπορείτε να εκτελέσετε απευθείας `ollama run Phi-3` ή να το διαμορφώσετε offline δημιουργώντας ένα `Modelfile` με τη διαδρομή προς το αρχείο `.gguf`.

```gguf
FROM {Add your gguf file path}
TEMPLATE \"\"\"<|user|> .Prompt<|end|> <|assistant|>\"\"\"
PARAMETER stop <|end|>
PARAMETER num_ctx 4096
```

[Κώδικας Παράδειγματος](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)

#### LlamaEdge

Αν θέλετε να χρησιμοποιήσετε αρχεία `.gguf` τόσο στο cloud όσο και σε συσκευές edge, το LlamaEdge είναι μια εξαιρετική επιλογή. Μπορείτε να ανατρέξετε σε αυτόν τον [κώδικα παράδειγματος](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo) για να ξεκινήσετε.

### Εγκατάσταση και Εκτέλεση σε Τηλέφωνα Android

1. **Κατεβάστε την εφαρμογή MLC Chat** (Δωρεάν) για τηλέφωνα Android.
2. Κατεβάστε το αρχείο APK (148MB) και εγκαταστήστε το στη συσκευή σας.
3. Εκκινήστε την εφαρμογή MLC Chat. Θα δείτε μια λίστα με AI μοντέλα, συμπεριλαμβανομένου του Phi-3-mini.

Συνοψίζοντας, το Phi-3-mini ανοίγει συναρπαστικές δυνατότητες για τη δημιουργική τεχνητή νοημοσύνη σε συσκευές edge, και μπορείτε να ξεκινήσετε να εξερευνάτε τις δυνατότητές του στο Android.

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας υπηρεσίες μηχανικής μετάφρασης με τεχνητή νοημοσύνη. Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να γνωρίζετε ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν σφάλματα ή ανακρίβειες. Το πρωτότυπο έγγραφο στη γλώσσα του θα πρέπει να θεωρείται η έγκυρη πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.