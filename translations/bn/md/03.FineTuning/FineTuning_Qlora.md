**Phi-3 কে QLoRA দিয়ে ফাইন-টিউন করা**

Microsoft-এর Phi-3 Mini ভাষা মডেলকে [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora) ব্যবহার করে ফাইন-টিউন করা। 

QLoRA কথোপকথনের বোঝাপড়া এবং প্রতিক্রিয়া তৈরির ক্ষমতা উন্নত করতে সাহায্য করবে। 

4bits-এ মডেল লোড করার জন্য transformers এবং bitsandbytes ব্যবহার করতে, আপনাকে source থেকে accelerate এবং transformers ইন্সটল করতে হবে এবং bitsandbytes লাইব্রেরির সর্বশেষ সংস্করণটি নিশ্চিত করতে হবে।

**নমুনা**
- [এই নমুনা নোটবুক থেকে আরও জানুন](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Python ফাইন-টিউনিং এর একটি উদাহরণ](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Hugging Face Hub-এ LORA দিয়ে ফাইন-টিউনিং এর উদাহরণ](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Hugging Face Hub-এ QLORA দিয়ে ফাইন-টিউনিং এর উদাহরণ](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**অস্বীকৃতি**:  
এই নথিটি মেশিন-ভিত্তিক এআই অনুবাদ পরিষেবা ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসাধ্য সঠিকতা বজায় রাখার চেষ্টা করি, তবে দয়া করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। নথিটির মূল ভাষায় লেখা সংস্করণকেই প্রামাণিক হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের ক্ষেত্রে পেশাদার মানব অনুবাদ সুপারিশ করা হয়। এই অনুবাদ ব্যবহারের ফলে কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যা ঘটলে আমরা তার জন্য দায়ী থাকব না।