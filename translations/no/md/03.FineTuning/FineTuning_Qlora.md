**Finjustering av Phi-3 med QLoRA**

Finjustering av Microsofts Phi-3 Mini-språkmodell ved hjelp av [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).  

QLoRA vil bidra til å forbedre forståelsen av samtaler og generering av svar.  

For å laste inn modeller i 4bits med transformers og bitsandbytes, må du installere accelerate og transformers fra kildekoden og sørge for at du har den nyeste versjonen av bitsandbytes-biblioteket.  

**Eksempler**  
- [Lær mer med denne eksempelsnotatboken](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)  
- [Eksempel på Python Finjusteringsskript](../../../../code/03.Finetuning/FineTrainingScript.py)  
- [Eksempel på finjustering med Hugging Face Hub og LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)  
- [Eksempel på finjustering med Hugging Face Hub og QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)  

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av maskinbaserte AI-oversettelsestjenester. Selv om vi streber etter nøyaktighet, vær oppmerksom på at automatiserte oversettelser kan inneholde feil eller unøyaktigheter. Det originale dokumentet på sitt opprinnelige språk bør anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.