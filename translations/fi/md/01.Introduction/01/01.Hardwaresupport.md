# Phi-laitteistotuki

Microsoft Phi on optimoitu ONNX Runtimea varten ja tukee Windows DirectML:ää. Se toimii hyvin erilaisilla laitteistoilla, mukaan lukien GPU:t, CPU:t ja jopa mobiililaitteet.

## Laitteistotuki
Tuettu laitteisto sisältää erityisesti:

- GPU SKU: RTX 4090 (DirectML)
- GPU SKU: 1 A100 80GB (CUDA)
- CPU SKU: Standard F64s v2 (64 vCPU:ta, 128 GiB muistia)

## Mobiililaitteet

- Android - Samsung Galaxy S21
- Apple iPhone 14 tai uudempi A16/A17-prosessori

## Phi-laitteistovaatimukset

- Vähimmäiskokoonpano.
- Windows: DirectX 12 -yhteensopiva GPU ja vähintään 4 Gt yhdistettyä RAM-muistia

CUDA: NVIDIA GPU, jonka laskentakyky on >= 7.02

![HardwareSupport](../../../../../translated_images/01.phihardware.925db5699da7752cf486314e6db087580583cfbcd548970f8a257e31a8aa862c.fi.png)

## Onnxruntime useilla GPU:illa

Tällä hetkellä saatavilla olevat Phi ONNX -mallit on tarkoitettu vain yhdelle GPU:lle. Phi-mallille on mahdollista tukea useampaa GPU:ta, mutta ORT kahdella GPU:lla ei takaa suurempaa läpimenoa verrattuna kahteen ORT-instanssiin. Katso [ONNX Runtime](https://onnxruntime.ai/) saadaksesi uusimmat päivitykset.

[Build 2024 -tapahtumassa GenAI ONNX -tiimi](https://youtu.be/WLW4SE8M9i8?si=EtG04UwDvcjunyfC) ilmoitti, että he ovat mahdollistaneet usean instanssin käytön usean GPU:n sijaan Phi-malleille.

Tällä hetkellä tämä mahdollistaa yhden onnxruntime- tai onnxruntime-genai-instanssin ajamisen CUDA_VISIBLE_DEVICES-ympäristömuuttujan avulla, kuten alla:

```Python
CUDA_VISIBLE_DEVICES=0 python infer.py
CUDA_VISIBLE_DEVICES=1 python infer.py
```

Tutustu Phi:hin tarkemmin [Azure AI Foundry](https://ai.azure.com) -sivustolla.

**Vastuuvapauslauseke**:  
Tämä asiakirja on käännetty konepohjaisten tekoälykäännöspalvelujen avulla. Pyrimme tarkkuuteen, mutta huomioithan, että automaattiset käännökset voivat sisältää virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäisellä kielellä tulisi pitää ensisijaisena lähteenä. Kriittistä tietoa varten suositellaan ammattimaista ihmisen tekemää käännöstä. Emme ole vastuussa tämän käännöksen käytöstä johtuvista väärinkäsityksistä tai virhetulkinnoista.