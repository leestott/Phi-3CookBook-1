# Počnite sa Phi-3 lokalno

Ovaj vodič će vam pomoći da postavite svoje lokalno okruženje za pokretanje modela Phi-3 koristeći Ollama. Model možete pokrenuti na nekoliko različitih načina, uključujući GitHub Codespaces, VS Code Dev Containers ili vaše lokalno okruženje.

## Postavljanje okruženja

### GitHub Codespaces

Možete pokrenuti ovaj šablon virtuelno koristeći GitHub Codespaces. Dugme će otvoriti VS Code instancu u vašem pretraživaču:

1. Otvorite šablon (ovo može potrajati nekoliko minuta):

    [![Open in GitHub Codespaces](https://github.com/codespaces/badge.svg)](https://codespaces.new/microsoft/phi-3cookbook)

2. Otvorite terminal prozor

### VS Code Dev Containers

⚠️ Ova opcija će raditi samo ako vaš Docker Desktop ima dodeljeno najmanje 16 GB RAM-a. Ako imate manje od 16 GB RAM-a, možete probati opciju [GitHub Codespaces](../../../../../md/01.Introduction/01) ili [postaviti lokalno](../../../../../md/01.Introduction/01).

Povezana opcija je VS Code Dev Containers, koja će otvoriti projekat u vašem lokalnom VS Code koristeći [Dev Containers ekstenziju](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers):

1. Pokrenite Docker Desktop (instalirajte ga ako već nije instaliran)
2. Otvorite projekat:

    [![Open in Dev Containers](https://img.shields.io/static/v1?style=for-the-badge&label=Dev%20Containers&message=Open&color=blue&logo=visualstudiocode)](https://vscode.dev/redirect?url=vscode://ms-vscode-remote.remote-containers/cloneInVolume?url=https://github.com/microsoft/phi-3cookbook)

3. U VS Code prozoru koji se otvori, kada se projektni fajlovi prikažu (ovo može potrajati nekoliko minuta), otvorite terminal prozor.
4. Nastavite sa [koracima za implementaciju](../../../../../md/01.Introduction/01)

### Lokalno okruženje

1. Uverite se da su sledeći alati instalirani:

    * [Ollama](https://ollama.com/)
    * [Python 3.10+](https://www.python.org/downloads/)
    * [OpenAI Python SDK](https://pypi.org/project/openai/)

## Testiranje modela

1. Zatražite od Ollama da preuzme i pokrene phi3:mini model:

    ```shell
    ollama run phi3:mini
    ```

    Ovo će potrajati nekoliko minuta dok se model preuzme.

2. Kada vidite "success" u izlazu, možete poslati poruku tom modelu iz prompta.

    ```shell
    >>> Write a haiku about hungry hippos
    ```

3. Nakon nekoliko sekundi, trebalo bi da vidite odgovor koji model počinje da generiše.

4. Da biste saznali više o različitim tehnikama koje se koriste sa jezičkim modelima, otvorite Python beležnicu [ollama.ipynb](../../../../../code/01.Introduce/ollama.ipynb) i pokrenite svaku ćeliju. Ako ste koristili model drugačiji od 'phi3:mini', promenite `MODEL_NAME` in the first cell.

5. To have a conversation with the phi3:mini model from Python, open the Python file [chat.py](../../../../../code/01.Introduce/chat.py) and run it. You can change the `MODEL_NAME` na vrhu fajla po potrebi, a možete takođe izmeniti sistemsku poruku ili dodati primere sa nekoliko koraka ako želite.

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуга машинског превођења заснованог на вештачкој интелигенцији. Иако се трудимо да обезбедимо тачност, молимо вас да будете свесни да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на свом изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални превод од стране људи. Не сносимо одговорност за било каква погрешна тумачења или неразумевања која могу произаћи из употребе овог превода.