**تنظیم دقیق Phi-3 با QLoRA**

تنظیم دقیق مدل زبان Phi-3 Mini مایکروسافت با استفاده از [QLoRA (تطبیق کم‌رتبه کوانتومی)](https://github.com/artidoro/qlora).

QLoRA به بهبود درک مکالمات و تولید پاسخ‌ها کمک خواهد کرد.

برای بارگذاری مدل‌ها در حالت ۴ بیت با transformers و bitsandbytes، باید کتابخانه‌های accelerate و transformers را از منبع نصب کنید و مطمئن شوید که آخرین نسخه از کتابخانه bitsandbytes را دارید.

**نمونه‌ها**
- [اطلاعات بیشتر با این دفترچه نمونه](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [نمونه‌ای از اسکریپت تنظیم دقیق در پایتون](../../../../code/03.Finetuning/FineTrainingScript.py)
- [نمونه‌ای از تنظیم دقیق Hugging Face Hub با LORA](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [نمونه‌ای از تنظیم دقیق Hugging Face Hub با QLORA](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**سلب مسئولیت**:  
این سند با استفاده از خدمات ترجمه ماشینی مبتنی بر هوش مصنوعی ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادقتی‌هایی باشند. سند اصلی به زبان بومی خود باید به‌عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه انسانی حرفه‌ای توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم‌ها یا تفسیرهای نادرست ناشی از استفاده از این ترجمه نداریم.