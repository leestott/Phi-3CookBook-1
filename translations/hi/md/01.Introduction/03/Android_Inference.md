# **Android में Phi-3 का इंफरेंस**

आइए देखें कि आप Android डिवाइस पर Phi-3-mini के साथ इंफरेंस कैसे कर सकते हैं। Phi-3-mini Microsoft की नई मॉडल श्रृंखला है जो बड़े भाषा मॉडल (LLMs) को एज डिवाइस और IoT डिवाइस पर तैनात करने में सक्षम बनाती है।

## सेमांटिक कर्नल और इंफरेंस

[सेमांटिक कर्नल](https://github.com/microsoft/semantic-kernel) एक एप्लिकेशन फ्रेमवर्क है जो आपको Azure OpenAI Service, OpenAI मॉडल्स और यहां तक कि लोकल मॉडल्स के साथ संगत एप्लिकेशन बनाने की अनुमति देता है। यदि आप सेमांटिक कर्नल में नए हैं, तो हम आपको [सेमांटिक कर्नल कुकबुक](https://github.com/microsoft/SemanticKernelCookBook?WT.mc_id=aiml-138114-kinfeylo) देखने की सलाह देते हैं।

### सेमांटिक कर्नल का उपयोग करके Phi-3-mini तक पहुंच

आप इसे सेमांटिक कर्नल में Hugging Face Connector के साथ मिला सकते हैं। इस [उदाहरण कोड](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/semantickernel?WT.mc_id=aiml-138114-kinfeylo) को देखें।

डिफॉल्ट रूप से, यह Hugging Face पर मॉडल ID से मेल खाता है। हालांकि, आप इसे लोकल रूप से बनाए गए Phi-3-mini मॉडल सर्वर से भी कनेक्ट कर सकते हैं।

### Ollama या LlamaEdge के साथ क्वांटाइज़्ड मॉडल्स कॉल करना

कई उपयोगकर्ता मॉडल्स को लोकल रूप से चलाने के लिए क्वांटाइज़्ड मॉडल्स का उपयोग करना पसंद करते हैं। [Ollama](https://ollama.com/) और [LlamaEdge](https://llamaedge.com) व्यक्तिगत उपयोगकर्ताओं को विभिन्न क्वांटाइज़्ड मॉडल्स कॉल करने की अनुमति देते हैं:

#### Ollama

आप सीधे `ollama run Phi-3` चला सकते हैं या इसे ऑफ़लाइन कॉन्फ़िगर कर सकते हैं `Modelfile` बनाकर, जिसमें आपके `.gguf` फ़ाइल का पथ हो।

```gguf
FROM {Add your gguf file path}
TEMPLATE \"\"\"<|user|> .Prompt<|end|> <|assistant|>\"\"\"
PARAMETER stop <|end|>
PARAMETER num_ctx 4096
```

[उदाहरण कोड](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/ollama?WT.mc_id=aiml-138114-kinfeylo)

#### LlamaEdge

यदि आप `.gguf` फाइलों का क्लाउड और एज डिवाइस पर एक साथ उपयोग करना चाहते हैं, तो LlamaEdge एक बेहतरीन विकल्प है। शुरू करने के लिए आप इस [उदाहरण कोड](https://github.com/Azure-Samples/Phi-3MiniSamples/tree/main/wasm?WT.mc_id=aiml-138114-kinfeylo) का संदर्भ ले सकते हैं।

### Android फोन पर इंस्टॉल और रन करें

1. **MLC Chat ऐप डाउनलोड करें** (फ्री) Android फोन के लिए।
2. APK फाइल (148MB) डाउनलोड करें और अपने डिवाइस पर इंस्टॉल करें।
3. MLC Chat ऐप लॉन्च करें। आपको AI मॉडल्स की एक सूची दिखाई देगी, जिसमें Phi-3-mini शामिल है।

सारांश में, Phi-3-mini एज डिवाइस पर जनरेटिव AI के लिए रोमांचक संभावनाएं खोलता है, और आप Android पर इसकी क्षमताओं का पता लगाना शुरू कर सकते हैं।

**अस्वीकरण**:  
यह दस्तावेज़ मशीन-आधारित एआई अनुवाद सेवाओं का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल भाषा में लिखा गया मूल दस्तावेज़ ही प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।