**Phi-3 को QLoRA के साथ फाइन-ट्यून करना**

Microsoft के Phi-3 Mini भाषा मॉडल को [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora) का उपयोग करके फाइन-ट्यून करना।  

QLoRA संवादात्मक समझ और उत्तर निर्माण को बेहतर बनाने में मदद करेगा।  

4 बिट्स में मॉडल्स को transformers और bitsandbytes के साथ लोड करने के लिए, आपको accelerate और transformers को स्रोत से इंस्टॉल करना होगा और यह सुनिश्चित करना होगा कि आपके पास bitsandbytes लाइब्रेरी का नवीनतम संस्करण हो।  

**उदाहरण**
- [इस सैंपल नोटबुक के साथ अधिक जानें](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)  
- [Python फाइन-ट्यूनिंग सैंपल का उदाहरण](../../../../code/03.Finetuning/FineTrainingScript.py)  
- [LORA के साथ Hugging Face Hub फाइन-ट्यूनिंग का उदाहरण](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)  
- [QLORA के साथ Hugging Face Hub फाइन-ट्यूनिंग का उदाहरण](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)  

**अस्वीकरण**:  
यह दस्तावेज़ मशीन-आधारित एआई अनुवाद सेवाओं का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयास करते हैं, कृपया ध्यान दें कि स्वचालित अनुवाद में त्रुटियां या अशुद्धियां हो सकती हैं। मूल दस्तावेज़, जो इसकी मूल भाषा में है, को आधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।