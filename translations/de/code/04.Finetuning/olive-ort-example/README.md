# Feinabstimmung von Phi3 mit Olive

In diesem Beispiel verwenden Sie Olive, um:

1. Einen LoRA-Adapter zu trainieren, der Phrasen in die Kategorien Traurigkeit, Freude, Angst und √úberraschung einordnet.
2. Die Adapter-Gewichte in das Basismodell zu integrieren.
3. Das Modell zu optimieren und in `int4` zu quantisieren.

Wir zeigen Ihnen au√üerdem, wie Sie das feinabgestimmte Modell mithilfe der ONNX Runtime (ORT) Generate API zur Inferenz nutzen k√∂nnen.

> **‚ö†Ô∏è F√ºr das Fein-Tuning ben√∂tigen Sie eine geeignete GPU - zum Beispiel eine A10, V100, A100.**

## üíæ Installation

Erstellen Sie eine neue Python-Umgebung (zum Beispiel mit `conda`):

```bash
conda create -n olive-ai python=3.11
conda activate olive-ai
```

Installieren Sie anschlie√üend Olive und die Abh√§ngigkeiten f√ºr den Fein-Tuning-Workflow:

```bash
cd Phi-3CookBook/code/04.Finetuning/olive-ort-example
pip install olive-ai[gpu]
pip install -r requirements.txt
```

## üß™ Feinabstimmung von Phi3 mit Olive
Die [Olive-Konfigurationsdatei](../../../../../code/04.Finetuning/olive-ort-example/phrase-classification.json) enth√§lt einen *Workflow* mit den folgenden *Passes*:

Phi3 -> LoRA -> MergeAdapterWeights -> ModelBuilder

Auf hoher Ebene f√ºhrt dieser Workflow die folgenden Schritte aus:

1. Feinabstimmung von Phi3 (f√ºr 150 Schritte, dies k√∂nnen Sie anpassen) mit den Daten aus [dataset/data-classification.json](../../../../../code/04.Finetuning/olive-ort-example/dataset/dataset-classification.json).
2. Zusammenf√ºhren der LoRA-Adapter-Gewichte mit dem Basismodell. Dadurch erhalten Sie ein einzelnes Modellartefakt im ONNX-Format.
3. Der Model Builder optimiert das Modell f√ºr die ONNX Runtime *und* quantisiert es in `int4`.

Um den Workflow auszuf√ºhren, verwenden Sie:

```bash
olive run --config phrase-classification.json
```

Nach Abschluss durch Olive steht Ihr optimiertes `int4` feinabgestimmtes Phi3-Modell unter folgendem Pfad bereit: `code/04.Finetuning/olive-ort-example/models/lora-merge-mb/gpu-cuda_model`.

## üßë‚Äçüíª Feinabgestimmtes Phi3 in Ihre Anwendung integrieren

Um die Anwendung auszuf√ºhren:

```bash
python app/app.py --phrase "cricket is a wonderful sport!" --model-path models/lora-merge-mb/gpu-cuda_model
```

Die Antwort sollte eine einzelne Wortklassifikation der Phrase sein (Traurigkeit/Freude/Angst/√úberraschung).

**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe KI-gest√ºtzter maschineller √úbersetzungsdienste √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.