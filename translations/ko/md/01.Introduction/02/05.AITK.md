# AITK의 Phi 패밀리

[AI Toolkit for VS Code](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)는 Azure AI Foundry Catalog 및 Hugging Face와 같은 다른 카탈로그에서 제공하는 최첨단 AI 개발 도구와 모델을 통합하여 생성 AI 애플리케이션 개발을 간소화합니다. GitHub Models 및 Azure AI Foundry Model Catalogs를 통해 제공되는 AI 모델 카탈로그를 탐색하고, 이를 로컬 또는 원격으로 다운로드하고, 미세 조정, 테스트 및 애플리케이션에서 사용할 수 있습니다.

AI Toolkit Preview는 로컬에서 실행됩니다. 선택한 모델에 따라 로컬 추론 또는 미세 조정이 가능하며, NVIDIA CUDA GPU와 같은 GPU가 필요할 수 있습니다. 또한 AITK를 사용하여 GitHub Models를 직접 실행할 수도 있습니다.

## 시작하기

[Windows Subsystem for Linux 설치 방법 알아보기](https://learn.microsoft.com/windows/wsl/install?WT.mc_id=aiml-137032-kinfeylo)

및 [기본 배포판 변경](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed).

[AI Toolkit GitHub 리포지토리](https://github.com/microsoft/vscode-ai-toolkit/)

- Windows, Linux, macOS
  
- Windows와 Linux에서 미세 조정을 수행하려면 Nvidia GPU가 필요합니다. 추가적으로, **Windows**에서는 Ubuntu 18.4 이상의 배포판을 포함한 Windows Subsystem for Linux가 필요합니다. [Windows Subsystem for Linux 설치 방법 알아보기](https://learn.microsoft.com/windows/wsl/install) 및 [기본 배포판 변경](https://learn.microsoft.com/windows/wsl/install#change-the-default-linux-distribution-installed).

### AI Toolkit 설치

AI Toolkit은 [Visual Studio Code 확장](https://code.visualstudio.com/docs/setup/additional-components#_vs-code-extensions)으로 제공되므로, 먼저 [VS Code](https://code.visualstudio.com/docs/setup/windows?WT.mc_id=aiml-137032-kinfeylo)를 설치하고 [VS Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio)에서 AI Toolkit을 다운로드해야 합니다.  
[AI Toolkit은 Visual Studio Marketplace에서 제공됩니다](https://marketplace.visualstudio.com/items?itemName=ms-windows-ai-studio.windows-ai-studio) 및 다른 VS Code 확장과 마찬가지로 설치할 수 있습니다.

VS Code 확장 설치에 익숙하지 않다면 다음 단계를 따라주세요:

### 로그인

1. VS Code의 활동 표시줄에서 **확장**을 선택합니다.  
2. 확장 검색창에 "AI Toolkit"을 입력합니다.  
3. "AI Toolkit for Visual Studio code"를 선택합니다.  
4. **설치**를 선택합니다.  

이제 확장을 사용할 준비가 되었습니다!

GitHub에 로그인하라는 메시지가 표시되므로 계속 진행하려면 "허용"을 클릭하세요. GitHub 로그인 페이지로 리디렉션됩니다.

로그인하고 프로세스 단계를 따르세요. 성공적으로 완료되면 VS Code로 리디렉션됩니다.

확장이 설치되면 활동 표시줄에 AI Toolkit 아이콘이 표시됩니다.

이제 사용할 수 있는 작업들을 탐색해 봅시다!

### 사용 가능한 작업

AI Toolkit의 주요 사이드바는 다음으로 구성됩니다:

- **모델**
- **리소스**
- **플레이그라운드**  
- **미세 조정**
- **평가**

리소스 섹션에서 사용할 수 있습니다. 시작하려면 **모델 카탈로그**를 선택하세요.

### 카탈로그에서 모델 다운로드

VS Code 사이드바에서 AI Toolkit을 실행하면 다음 옵션 중에서 선택할 수 있습니다:

![AI toolkit 모델 카탈로그](../../../../../translated_images/AItoolkitmodel_catalog.eee6b38a71f628501d730ffe9c2ae69b8f18706e7492ac2371423b045485996e.ko.png)

- **모델 카탈로그**에서 지원되는 모델을 찾아 로컬에 다운로드  
- **모델 플레이그라운드**에서 모델 추론 테스트  
- **모델 미세 조정**에서 로컬 또는 원격으로 모델 미세 조정  
- AI Toolkit 명령 팔레트를 통해 클라우드에 미세 조정된 모델 배포  
- 모델 평가  

> [!NOTE]
>
> **GPU와 CPU**
>
> 모델 카드에는 모델 크기, 플랫폼 및 가속기 유형(CPU, GPU)이 표시됩니다. **최소 한 개의 GPU를 포함한 Windows 장치**에서 최적의 성능을 얻으려면 Windows만 타겟팅하는 모델 버전을 선택하세요.
>
> 이를 통해 DirectML 가속기에 최적화된 모델을 사용할 수 있습니다.
>
> 모델 이름 형식은 다음과 같습니다:
>
> - `{model_name}-{accelerator}-{quantization}-{format}`.
>
> Windows 장치에 GPU가 있는지 확인하려면 **작업 관리자**를 열고 **성능** 탭을 선택하세요. GPU가 있는 경우 "GPU 0" 또는 "GPU 1"과 같은 이름으로 나열됩니다.

### 플레이그라운드에서 모델 실행

모든 매개변수를 설정한 후 **프로젝트 생성**을 클릭하세요.

모델 다운로드가 완료되면 카탈로그의 모델 카드에서 **플레이그라운드에서 로드**를 선택하세요:

- 모델 다운로드 시작  
- 모든 필수 구성 요소 및 종속성 설치  
- VS Code 작업 공간 생성  

![플레이그라운드에서 모델 로드](../../../../../translated_images/AItoolkitload_model_into_playground.e442d8013c65406e69471fb4f8e4e3800505255fe1bd7aa9422f02ee715bad57.ko.png)

### 애플리케이션에서 REST API 사용

AI Toolkit은 [OpenAI 채팅 완료 형식](https://platform.openai.com/docs/api-reference/chat/create)을 사용하는 **포트 5272**의 로컬 REST API 웹 서버와 함께 제공됩니다.

이를 통해 클라우드 AI 모델 서비스에 의존하지 않고 애플리케이션을 로컬에서 테스트할 수 있습니다. 예를 들어, 다음 JSON 파일은 요청 본문을 구성하는 방법을 보여줍니다:

```json
{
    "model": "Phi-4",
    "messages": [
        {
            "role": "user",
            "content": "what is the golden ratio?"
        }
    ],
    "temperature": 0.7,
    "top_p": 1,
    "top_k": 10,
    "max_tokens": 100,
    "stream": true
}
```

[Postman](https://www.postman.com/) 또는 CURL(Client URL) 유틸리티를 사용하여 REST API를 테스트할 수 있습니다:

```bash
curl -vX POST http://127.0.0.1:5272/v1/chat/completions -H 'Content-Type: application/json' -d @body.json
```

### Python용 OpenAI 클라이언트 라이브러리 사용

```python
from openai import OpenAI

client = OpenAI(
    base_url="http://127.0.0.1:5272/v1/", 
    api_key="x" # required for the API but not used
)

chat_completion = client.chat.completions.create(
    messages=[
        {
            "role": "user",
            "content": "what is the golden ratio?",
        }
    ],
    model="Phi-4",
)

print(chat_completion.choices[0].message.content)
```

### .NET용 Azure OpenAI 클라이언트 라이브러리 사용

[Azure OpenAI 클라이언트 라이브러리 for .NET](https://www.nuget.org/packages/Azure.AI.OpenAI/)을 NuGet을 사용하여 프로젝트에 추가하세요:

```bash
dotnet add {project_name} package Azure.AI.OpenAI --version 1.0.0-beta.17
```

**OverridePolicy.cs**라는 이름의 C# 파일을 프로젝트에 추가하고 다음 코드를 붙여넣으세요:

```csharp
// OverridePolicy.cs
using Azure.Core.Pipeline;
using Azure.Core;

internal partial class OverrideRequestUriPolicy(Uri overrideUri)
    : HttpPipelineSynchronousPolicy
{
    private readonly Uri _overrideUri = overrideUri;

    public override void OnSendingRequest(HttpMessage message)
    {
        message.Request.Uri.Reset(_overrideUri);
    }
}
```

그런 다음, **Program.cs** 파일에 다음 코드를 붙여넣으세요:

```csharp
// Program.cs
using Azure.AI.OpenAI;

Uri localhostUri = new("http://localhost:5272/v1/chat/completions");

OpenAIClientOptions clientOptions = new();
clientOptions.AddPolicy(
    new OverrideRequestUriPolicy(localhostUri),
    Azure.Core.HttpPipelinePosition.BeforeTransport);
OpenAIClient client = new(openAIApiKey: "unused", clientOptions);

ChatCompletionsOptions options = new()
{
    DeploymentName = "Phi-4",
    Messages =
    {
        new ChatRequestSystemMessage("You are a helpful assistant. Be brief and succinct."),
        new ChatRequestUserMessage("What is the golden ratio?"),
    }
};

StreamingResponse<StreamingChatCompletionsUpdate> streamingChatResponse
    = await client.GetChatCompletionsStreamingAsync(options);

await foreach (StreamingChatCompletionsUpdate chatChunk in streamingChatResponse)
{
    Console.Write(chatChunk.ContentUpdate);
}
```

## AI Toolkit을 사용한 미세 조정

- 모델 검색 및 플레이그라운드 시작하기  
- 로컬 컴퓨팅 리소스를 사용한 모델 미세 조정 및 추론  
- Azure 리소스를 사용한 원격 미세 조정 및 추론  

[AI Toolkit을 사용한 미세 조정](../../03.FineTuning/Finetuning_VSCodeaitoolkit.md)

## AI Toolkit Q&A 리소스

가장 일반적인 문제와 해결 방법에 대해서는 [Q&A 페이지](https://github.com/microsoft/vscode-ai-toolkit/blob/main/archive/QA.md)를 참조하세요.

**면책 조항**:  
이 문서는 AI 기반 기계 번역 서비스를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있지만, 자동 번역에는 오류나 부정확성이 포함될 수 있음을 유의하시기 바랍니다. 원본 문서의 원어 버전이 권위 있는 자료로 간주되어야 합니다. 중요한 정보의 경우, 전문적인 인간 번역을 권장합니다. 이 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.