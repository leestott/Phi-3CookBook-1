**Ottimizzazione di Phi-3 con QLoRA**

Ottimizzazione del modello linguistico Phi-3 Mini di Microsoft utilizzando [QLoRA (Quantum Low-Rank Adaptation)](https://github.com/artidoro/qlora).

QLoRA aiuterà a migliorare la comprensione conversazionale e la generazione di risposte.

Per caricare modelli in 4 bit con transformers e bitsandbytes, è necessario installare accelerate e transformers dalla sorgente e assicurarsi di avere l'ultima versione della libreria bitsandbytes.

**Esempi**
- [Scopri di più con questo notebook di esempio](../../../../code/03.Finetuning/Phi_3_Inference_Finetuning.ipynb)
- [Esempio di script Python per FineTuning](../../../../code/03.Finetuning/FineTrainingScript.py)
- [Esempio di Fine Tuning con LORA su Hugging Face Hub](../../../../code/03.Finetuning/Phi-3-finetune-lora-python.ipynb)
- [Esempio di Fine Tuning con QLORA su Hugging Face Hub](../../../../code/03.Finetuning/Phi-3-finetune-qlora-python.ipynb)

**Disclaimer**:  
Questo documento è stato tradotto utilizzando servizi di traduzione automatizzati basati sull'intelligenza artificiale. Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa deve essere considerato la fonte autorevole. Per informazioni critiche, si consiglia una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali malintesi o interpretazioni errate derivanti dall'uso di questa traduzione.