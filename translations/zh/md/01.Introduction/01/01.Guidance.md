### Guidance-AI 和 Phi 模型即服务 (MaaS)
我们将 [Guidance](https://github.com/guidance-ai/guidance) 引入 Azure AI Foundry 中的 Phi-3.5-mini 无服务器端点服务，通过定义针对特定应用的结构，使输出更可预测。借助 Guidance，你可以消除昂贵的重试操作，例如，将模型限制为只能从预定义列表中选择（如医疗代码），将输出限制为提供的上下文中的直接引用，或遵循任意正则表达式。Guidance 在推理堆栈中逐个令牌地引导模型运行，降低 30%-50% 的成本和延迟，使其成为 [Phi-3-mini 无服务器端点](https://aka.ms/try-phi3.5mini) 的独特且有价值的附加功能。

## [**Guidance-AI**](https://github.com/guidance-ai/guidance) 是一个旨在帮助开发者高效创建和部署 AI 模型的框架。它专注于提供构建稳健 AI 应用的工具和最佳实践。

结合 **Phi 模型即服务 (MaaS)** 后，它为部署既经济高效又性能卓越的小型语言模型 (SLM) 提供了强大的解决方案。

**Guidance-AI** 是一个编程框架，旨在帮助开发者更有效地控制和引导大型语言模型 (LLM)。它允许对输出进行精确结构化，与传统的提示或微调方法相比，降低了延迟和成本。

### Guidance-AI 的关键特性：
- **高效控制**：使开发者能够控制语言模型生成文本的方式，确保输出高质量且相关性强。
- **成本和延迟优化**：优化生成过程，更具成本效益且速度更快。
- **灵活集成**：兼容多种后端，包括 Transformers、llama.cpp、AzureAI、VertexAI 和 OpenAI。
- **丰富的输出结构**：支持复杂的输出结构，如条件语句、循环和工具使用，使生成的结果更加清晰且易于解析。
- **兼容性**：一个 Guidance 程序可以在多个后端上执行，增强了灵活性和易用性。

### 示例用例：
- **受限生成**：使用正则表达式和上下文无关语法引导模型的输出。
- **工具集成**：在文本生成任务中自动交替控制和生成，例如使用计算器。

更多详细信息和示例，请访问 [Guidance-AI GitHub 仓库](https://github.com/guidance-ai/guidance)。

[查看 Phi-3.5 示例](../../../../../code/01.Introduce/guidance.ipynb)

### Phi 模型的关键特性：
1. **经济高效**：在保持高性能的同时设计为成本低廉。
2. **低延迟**：适用于需要快速响应的实时应用。
3. **灵活性**：可部署在各种环境中，包括云端、边缘和离线场景。
4. **定制化**：模型可通过领域特定数据进行微调以提升性能。
5. **安全与合规**：基于微软的 AI 原则构建，确保责任、透明性、公平性、可靠性、安全性、隐私性和包容性。

### Phi 模型即服务 (MaaS):
Phi 模型通过基于使用量的计费系统提供推理 API，让你可以轻松地将它们集成到你的应用中，而无需高额的前期成本。

### 开始使用 Phi-3：
要开始使用 Phi 模型，你可以探索 [Azure AI 模型目录](https://ai.azure.com/explore/models) 或 [GitHub Marketplace 模型](https://github.com/marketplace/models)，这些平台提供预构建和可定制的模型。此外，你还可以使用 [Azure AI Foundry](https://ai.azure.com) 等工具开发和部署你的 AI 应用。

### 资源
[关于 Guidance 的入门示例笔记本](../../../../../code/01.Introduce/guidance.ipynb)

**免责声明**：  
本文件使用基于机器的AI翻译服务进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。应以原始语言的文件为权威来源。对于关键信息，建议寻求专业人工翻译。因使用此翻译而引起的任何误解或误读，我们概不负责。