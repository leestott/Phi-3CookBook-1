# **Lab 2 - AIPC'de Phi-3-mini ile Prompt flow Çalıştırma**

## **Prompt flow Nedir**

Prompt flow, fikir üretiminden prototipleme, test etme, değerlendirme, üretime geçiş ve izlemeye kadar, LLM tabanlı yapay zeka uygulamalarının uçtan uca geliştirme döngüsünü kolaylaştırmak için tasarlanmış bir geliştirme araçları setidir. Prompt mühendisliğini çok daha kolay hale getirir ve üretim kalitesinde LLM uygulamaları oluşturmanıza olanak tanır.

Prompt flow ile şunları yapabilirsiniz:

- LLM'leri, promptları, Python kodunu ve diğer araçları bir araya getiren çalıştırılabilir iş akışları oluşturabilirsiniz.

- Özellikle LLM'lerle olan etkileşimlerinizi kolayca hata ayıklayıp yineleyebilirsiniz.

- İş akışlarınızı değerlendirebilir, daha büyük veri setleriyle kalite ve performans metriklerini hesaplayabilirsiniz.

- Test ve değerlendirmeyi CI/CD sisteminize entegre ederek iş akışınızın kalitesini garanti altına alabilirsiniz.

- İş akışlarınızı seçtiğiniz sunucu platformuna dağıtabilir veya uygulamanızın kod tabanına kolayca entegre edebilirsiniz.

- (Opsiyonel ancak şiddetle tavsiye edilir) Azure AI'daki bulut versiyonunu kullanarak ekibinizle iş birliği yapabilirsiniz.

## **AIPC Nedir**

Bir AI PC'de, her biri belirli yapay zeka hızlandırma yeteneklerine sahip bir CPU, bir GPU ve bir NPU bulunur. NPU, yani sinir işleme birimi, yapay zeka (AI) ve makine öğrenimi (ML) görevlerini doğrudan bilgisayarınızda işleyen özel bir hızlandırıcıdır; verileri buluta göndermek yerine yerel olarak işler. GPU ve CPU da bu iş yüklerini işleyebilir, ancak NPU özellikle düşük güçlü yapay zeka hesaplamalarında çok iyidir. AI PC, bilgisayarlarımızın çalışma şeklinde temel bir değişikliği temsil eder. Daha önce var olmayan bir problemi çözmek için değil, günlük PC kullanımları için büyük bir gelişme vaat ediyor.

Peki nasıl çalışır? Jeneratif yapay zeka ve tonlarca genel veriyle eğitilmiş büyük dil modelleri (LLM'ler) ile karşılaştırıldığında, PC'nizde gerçekleşecek yapay zeka, hemen hemen her seviyede daha erişilebilirdir. Kavram daha kolay anlaşılır ve buluta erişim gerektirmediği için, kendi verilerinizle eğitildiğinden, faydalar daha geniş bir kitle için daha hemen cazip hale gelir.

Kısa vadede, AI PC dünyası, kişisel asistanlar ve daha küçük AI modellerinin doğrudan bilgisayarınızda çalıştırılmasını içerir. Bu modeller, toplantı notları almak, bir fantezi futbol ligi düzenlemek, fotoğraf ve video düzenleme için otomatik iyileştirmeler yapmak ya da herkesin varış ve ayrılış saatlerine göre bir aile buluşması için mükemmel bir program oluşturmak gibi günlük yaptığınız şeyler için kişisel, özel ve daha güvenli yapay zeka geliştirmeleri sunar.

## **AIPC Üzerinde Kod Üretim Akışları Oluşturma**

***Not*** ：Eğer ortam kurulumunu tamamlamadıysanız, lütfen [Lab 0 -Kurulumlar](./01.Installations.md) bağlantısını ziyaret edin.

1. Visual Studio Code'da Prompt flow Uzantısını açın ve boş bir akış projesi oluşturun.

![create](../../../../../../../../../translated_images/pf_create.d6172d8277a78a7fa82cd6ff727ed44e037fa78b662f1f62d5963f36d712d229.tr.png)

2. Giriş ve Çıkış parametreleri ekleyin ve yeni bir akış olarak Python Kodu ekleyin.

![flow](../../../../../../../../../translated_images/pf_flow.d5646a323fb7f444c0b98b4521057a592325c583e7ba18bc31500bc0415e9ef3.tr.png)

Akışınızı oluşturmak için bu yapıyı (flow.dag.yaml) referans alabilirsiniz.

```yaml

inputs:
  question:
    type: string
    default: how to write Bubble Algorithm
outputs:
  answer:
    type: string
    reference: ${Chat_With_Phi3.output}
nodes:
- name: Chat_With_Phi3
  type: python
  source:
    type: code
    path: Chat_With_Phi3.py
  inputs:
    question: ${inputs.question}


```

3. ***Chat_With_Phi3.py*** dosyasına kod ekleyin.

```python


from promptflow.core import tool

# import torch
from transformers import AutoTokenizer, pipeline,TextStreamer
import intel_npu_acceleration_library as npu_lib

import warnings

import asyncio
import platform

class Phi3CodeAgent:
    
    model = None
    tokenizer = None
    text_streamer = None
    
    model_id = "microsoft/Phi-3-mini-4k-instruct"

    @staticmethod
    def init_phi3():
        
        if Phi3CodeAgent.model is None or Phi3CodeAgent.tokenizer is None or Phi3CodeAgent.text_streamer is None:
            Phi3CodeAgent.model = npu_lib.NPUModelForCausalLM.from_pretrained(
                                    Phi3CodeAgent.model_id,
                                    torch_dtype="auto",
                                    dtype=npu_lib.int4,
                                    trust_remote_code=True
                                )
            Phi3CodeAgent.tokenizer = AutoTokenizer.from_pretrained(Phi3CodeAgent.model_id)
            Phi3CodeAgent.text_streamer = TextStreamer(Phi3CodeAgent.tokenizer, skip_prompt=True)

    

    @staticmethod
    def chat_with_phi3(prompt):
        
        Phi3CodeAgent.init_phi3()

        messages = "<|system|>You are a AI Python coding assistant. Please help me to generate code in Python.The answer only genertated Python code, but any comments and instructions do not need to be generated<|end|><|user|>" + prompt +"<|end|><|assistant|>"



        generation_args = {
            "max_new_tokens": 1024,
            "return_full_text": False,
            "temperature": 0.3,
            "do_sample": False,
            "streamer": Phi3CodeAgent.text_streamer,
        }

        pipe = pipeline(
            "text-generation",
            model=Phi3CodeAgent.model,
            tokenizer=Phi3CodeAgent.tokenizer,
            # **generation_args
        )

        result = ''

        with warnings.catch_warnings():
            warnings.simplefilter("ignore")
            response = pipe(messages, **generation_args)
            result =response[0]['generated_text']
            return result


@tool
def my_python_tool(question: str) -> str:
    if platform.system() == 'Windows':
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())
    return Phi3CodeAgent.chat_with_phi3(question)


```

4. Kod üretiminin doğru çalışıp çalışmadığını kontrol etmek için akışı Hata Ayıklama veya Çalıştırma seçenekleriyle test edebilirsiniz.

![RUN](../../../../../../../../../translated_images/pf_run.d918637dc00f61e9bdeec37d4cc9646f77d270ac9203bcce13569f3157202b6e.tr.png)

5. Akışı terminalde geliştirme API'si olarak çalıştırın.

```

pf flow serve --source ./ --port 8080 --host localhost   

```

Postman / Thunder Client ile test edebilirsiniz.

### **Not**

1. İlk çalıştırma uzun zaman alır. Phi-3 modelini Hugging Face CLI üzerinden indirmeniz önerilir.

2. Intel NPU'nun sınırlı işlem gücünü göz önünde bulundurarak, Phi-3-mini-4k-instruct kullanmanız tavsiye edilir.

3. INT4 dönüşümünü kuantize etmek için Intel NPU Hızlandırma kullanıyoruz, ancak hizmeti yeniden çalıştırırsanız önbelleği ve nc_workshop klasörlerini silmeniz gerekir.

## **Kaynaklar**

1. Promptflow Öğrenin [https://microsoft.github.io/promptflow/](https://microsoft.github.io/promptflow/)

2. Intel NPU Hızlandırmayı Öğrenin [https://github.com/intel/intel-npu-acceleration-library](https://github.com/intel/intel-npu-acceleration-library)

3. Örnek Kod, indirin [Yerel NPU Agent Örnek Kodu](../../../../../../../../../code/07.Lab/01/AIPC)

**Feragatname**:  
Bu belge, yapay zeka tabanlı makine çeviri hizmetleri kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hata veya yanlışlıklar içerebileceğini lütfen unutmayın. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımından kaynaklanan yanlış anlamalar veya yanlış yorumlamalar için sorumluluk kabul etmiyoruz.